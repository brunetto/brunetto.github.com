<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Post It!</title>
    <link>http://brunettoziosi.eu/tags/python/</link>
    <description>Recent content in Python on Post It!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Dec 2014 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://brunettoziosi.eu/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Padding</title>
      <link>http://brunettoziosi.eu/posts/padding/</link>
      <pubDate>Fri, 12 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/padding/</guid>
      <description>&lt;p&gt;Ok, it&amp;rsquo;s the n-th time I search how to pad numbers in bash.&lt;br /&gt;
I&amp;rsquo;ll take a note here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;i=5
printf &amp;quot;%03d\n&amp;quot; $i
005
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Something similar in Python and Go:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;t = &amp;quot;test-&amp;quot;
t.ljust(10, &#39;0&#39;) # rjust for right padding

&#39;test-00000&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// LeftPad returns the string padded filling remaining left spaces to `length` with `pad`.
import &amp;quot;log&amp;quot;
import &amp;quot;strings&amp;quot;

func LeftPad(str, pad string, length int) string {
	var repeat int
	if (length-len(str))%len(pad) != 0 {
		log.Fatal(&amp;quot;Can&#39;t pad &amp;quot;, str, &amp;quot; with &amp;quot;, pad, &amp;quot; to length &amp;quot;, length)
	} else {
		repeat = (length - len(str)) / len(pad)
	}
	return strings.Repeat(pad, repeat) + str
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is also possible to do this with &lt;code&gt;fmt&lt;/code&gt; but you still need to compute the number
of char if you want to maintain the total number of printed char.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python plot examples</title>
      <link>http://brunettoziosi.eu/posts/python-plot-examples/</link>
      <pubDate>Mon, 29 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/python-plot-examples/</guid>
      <description>&lt;p&gt;Two examples on how to make plots with &lt;a href=&#34;http://home.gna.org/veusz&#34;&gt;Veusz&lt;/a&gt; and
&lt;a href=&#34;http://matplotlib.org&#34;&gt;Matplotlib&lt;/a&gt;.&lt;br /&gt;
I prefer Veusz because it&amp;rsquo;s easier to configure, modify and it produces
perfect &lt;code&gt;pdf&lt;/code&gt; plots, but sometimes Matplotlib it&amp;rsquo;s faster for producing just
a draft plot to inspect data!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# -*- coding: utf8 -*- 

from __future__ import division # no more &amp;quot;zero&amp;quot; integer division bugs!:P
import time
import numpy as np
import veusz.embed as ve

def sm_hist(data, delta=5, n_bin=None, range_=None):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta)
	range_ = (dataMin, dataMin + n_bin * delta)
	counts, bin_edges = np.histogram(data, n_bin, range_, density = False)
	return counts, bin_edges
	
def sm_hist2(data, delta=5):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta) + 1
	idxs = ((data  - dataMin) / delta).astype(int)
	counts = np.zeros(n_bin) 
	bin_edges = np.arange(dataMin, dataMax+2, delta)
	for idx in idxs:
		counts[idx] += 1
	counts = np.hstack((np.array([0]), counts, np.array([0])))
	bin_edges = np.hstack((bin_edges[0], bin_edges, bin_edges[-1]))
	return counts, bin_edges

def plotFunc(inpath=&amp;quot;./&amp;quot;, outpath=&amp;quot;./&amp;quot;):
	font = &amp;quot;Times New Roman&amp;quot;
	colors = [u&#39;blue&#39;, u&#39;green&#39;]
	xmin = [&amp;quot;auto&amp;quot;, &amp;quot;auto&amp;quot;]
	xmax = [&amp;quot;auto&amp;quot;, &amp;quot;auto&amp;quot;]
	ymin = [&amp;quot;auto&amp;quot;, 0]
	ymax = [&amp;quot;auto&amp;quot;, &amp;quot;auto&amp;quot;]
	
	xData = np.arange(100) 
	yData = np.random.randint(0, 100, size=100) + np.sin(np.arange(100))
	
	figure = ve.Embedded(&amp;quot;Window_1&amp;quot;)
	page = figure.Root.Add(&#39;page&#39;, width = &#39;30cm&#39;, height=&#39;15cm&#39;)
	grid = page.Add(&#39;grid&#39;, autoadd = False, rows = 1, columns = 2,
						scaleRows=[0.2],
						topMargin=&#39;1cm&#39;,
						bottomMargin=&#39;1cm&#39;
						)
	graphList = []
	
	graphList.append(grid.Add(&#39;graph&#39;, name=&amp;quot;scatter&amp;quot;, autoadd=False, 
							hide = False, 
							Border__width = &#39;2pt&#39;,
							leftMargin = &#39;0.6cm&#39;,
							rightMargin = &#39;0.4cm&#39;,
							topMargin = &#39;0.5cm&#39;,
							bottomMargin = &#39;1cm&#39;,
							))
	
	graphList.append(grid.Add(&#39;graph&#39;, name=&amp;quot;hist&amp;quot;, autoadd=False, 
							hide = False, 
							Border__width = &#39;2pt&#39;,
							leftMargin = &#39;2cm&#39;,
							rightMargin = &#39;0.4cm&#39;,
							topMargin = &#39;0.5cm&#39;,
							bottomMargin = &#39;1cm&#39;,
							))
	
	for i in range(len(graphList)):
		graphList[i].Add(&#39;axis&#39;, name=&#39;x&#39;, label = &amp;quot;x&amp;quot;,
								min = xmin[i],
								max = xmax[i],
								log = False,
								Label__size = &#39;25pt&#39;,
								Label__font = font,
								TickLabels__size = &#39;17pt&#39;,
								TickLabels__format = u&#39;Auto&#39;,
								MajorTicks__width = &#39;2pt&#39;,
								MajorTicks__length = &#39;10pt&#39;,
								MinorTicks__width = &#39;1pt&#39;,
								MinorTicks__length = &#39;6pt&#39;
							)
		graphList[i].Add(&#39;axis&#39;, name=&#39;y&#39;, label = &amp;quot;y&amp;quot;, 
								direction = &#39;vertical&#39;,
								min = ymin[i],
								max = ymax[i],
								log = False,
								autoRange = u&#39;+5%&#39;,
								Label__size = &#39;25pt&#39;,
								Label__font = font,
								TickLabels__size = &#39;20pt&#39;,
								TickLabels__format = u&#39;Auto&#39;,
								MajorTicks__width = &#39;2pt&#39;,
								MajorTicks__length = &#39;10pt&#39;,
								MinorTicks__width = &#39;1pt&#39;,
								MinorTicks__length = &#39;6pt&#39;
							)
	
	graphList[0].Add(&#39;xy&#39;, key=&amp;quot;scatterPlotKey&amp;quot;, name=&#39;scatterPlotName&#39;,
						marker = u&#39;circle&#39;,
						MarkerFill__color = colors[0],
						markerSize = u&#39;3pt&#39;, 
						)

	xDataName = &amp;quot;xScatterData&amp;quot;
	yDataName = &amp;quot;yScatterData&amp;quot;
	figure.SetData(xDataName, xData)
	figure.SetData(yDataName, yData)
	graphList[0].scatterPlotName.xData.val = xDataName
	graphList[0].scatterPlotName.yData.val = yDataName
	
	
	counts, bin_edges = sm_hist2(yData, delta=5)
	
	graphList[1].Add(&#39;xy&#39;, key=&amp;quot;histPlotKey&amp;quot;, name=&#39;histPlotName&#39;,
						xData = bin_edges,
						yData = counts,
						marker = &#39;none&#39;,
						PlotLine__steps = u&#39;left&#39;,
						PlotLine__color = colors[1],
						PlotLine__style = u&amp;quot;solid&amp;quot;,
						PlotLine__width = u&#39;3&#39;,
						FillBelow__color = colors[1],
						FillBelow__style = &amp;quot;forward 2&amp;quot;,
						FillBelow__hide = False,
						FillBelow__transparency = 70,
						#FillBelow__backtransparency = 50,
						FillBelow__linewidth = &#39;1pt&#39;,
						FillBelow__linestyle = &#39;solid&#39;,
						FillBelow__backcolor = &amp;quot;white&amp;quot;,
						FillBelow__backhide = True,
						Label__posnHorz = &#39;right&#39;,
						Label__size = &#39;14pt&#39;, 
						Label__color = &#39;black&#39;
						)

	histKey = graphList[1].Add(&#39;key&#39;, autoadd=False, 
						horzPosn = &#39;left&#39;,
						vertPosn = &#39;top&#39;,
						Text__font = font,
						Text__size = &#39;15&#39;,
						Border__width = &#39;1.5pt&#39;
						)
	
	end = raw_input(&amp;quot;Press any key to finish...&amp;quot;)
	
	figure.Save(&amp;quot;example.vsz&amp;quot;)
	figure.Export(&amp;quot;example.png&amp;quot;, backcolor=&#39;#ffffff&#39;)
	figure.Export(&amp;quot;example.pdf&amp;quot;)

if __name__ == &amp;quot;__main__&amp;quot;:
	inpath = &amp;quot;./&amp;quot;
	outpath = &#39;./&#39;
	tt = time.time()
	plotFunc(inpath, outpath)
	print &amp;quot;Done in &amp;quot;, time.time()-tt, &amp;quot; seconds.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../../files/example.png&#34; alt=&#34;Veusz plot&#34; title=&#34;Veusz plot&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# -*- coding: utf8 -*- 

from __future__ import division # no more &amp;quot;zero&amp;quot; integer division bugs!:P
import time
import numpy as np
import matplotlib.pylab as plt
import matplotlib.font_manager as font_manager

# SM like style
params = {&#39;backend&#39;: &#39;png&#39;,
		&#39;font.family&#39;: &amp;quot;serif&amp;quot;,
		&#39;font.size&#39;: 25,
		&#39;axes.labelsize&#39;: 35,
		#&#39;text.fontsize&#39;: 30,
		&#39;legend.fontsize&#39;: 30,
		&#39;xtick.labelsize&#39;: 28,
		&#39;xtick.major.size&#39;: 20.0,
		&#39;xtick.major.width&#39;: 3.0,
		&#39;xtick.minor.size&#39;: 12.0,
		&#39;xtick.minor.width&#39;: 2,
		&#39;ytick.labelsize&#39;: 28,
		&#39;ytick.major.size&#39;: 20.0,
		&#39;ytick.major.width&#39;: 3.0,
		&#39;ytick.minor.size&#39;: 12.0,
		&#39;ytick.minor.width&#39;: 2,
		#&#39;text.usetex&#39;: True,
		&#39;axes.linewidth&#39;: 3.0,
		&#39;lines.linewidth&#39;: 2,
		&#39;lines.markersize&#39;: 15,
		&#39;axes.grid&#39;: False,
		&#39;grid&#39;: {&#39;color&#39;:&#39;gray&#39;, &#39;linestyle&#39;:&#39;-&#39;, &#39;linewidth&#39;:1},
		&#39;figure.figsize&#39;: (10,10),
		&#39;figure.subplot.left&#39;: 0.15,  # the left side of the subplots of the figure
		&#39;figure.subplot.right&#39;   : 0.95,    # the right side of the subplots of the figure
		&#39;figure.subplot.bottom&#39;  : 0.12,   # the bottom of the subplots of the figure
		&#39;figure.subplot.top&#39;     : 0.92,    # the top of the subplots of the figure
		&#39;figure.subplot.wspace&#39;  : 0.2,    # the amount of width reserved for blank space between subplots
		&#39;figure.subplot.hspace&#39;  : 0.2,    # the amount of height reserved for white space between subplots
		&#39;figure.figsize&#39;: (12, 12)
           }
plt.rcParams.update(params)
	
def sm_hist(data, delta=5, n_bin=None, range_=None):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta)
	range_ = (dataMin, dataMin + n_bin * delta)
	counts, bin_edges = np.histogram(data, n_bin, range_, density = False)
	# These two lines double the points let you make the histogram
	counts = np.ravel(zip(counts,counts)) 
	bin_edges = np.ravel(zip(bin_edges,bin_edges))
	counts = np.hstack((np.array([0]), counts, np.array([0])))
	return counts, bin_edges
	
	
def sm_hist2(data, delta=5):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta) + 1
	idxs = ((data  - dataMin) / delta).astype(int)
	counts = np.zeros(n_bin) 
	bin_edges = np.arange(dataMin, dataMax+delta, delta)
	for idx in idxs:
		counts[idx] += 1
	print counts
	# These two lines double the points let you make the histogram
	counts = np.ravel(zip(counts,counts)) 
	bin_edges = np.ravel(zip(bin_edges,bin_edges))
	counts = np.hstack((np.array([0]), counts))
	bin_edges = np.hstack((bin_edges, bin_edges[-1]))
	return counts, bin_edges

def singlePlotScatter(xData, yData, nRows, nCols, x0, y0, rowspan, colspan):
	ax = plt.subplot2grid((nRows,nCols), (x0,y0), rowspan, colspan)
	ax.set_xlabel(&amp;quot;x label&amp;quot;)
	ax.set_ylabel(&amp;quot;y label&amp;quot;)
	ax.set_xscale(&amp;quot;linear&amp;quot;)
	ax.set_yscale(&amp;quot;linear&amp;quot;)
	ax.set_title(&amp;quot;Plot title&amp;quot;)
	ax.title.set_y(1.02) # adjust title position
	ax.xaxis.grid(True, which=&amp;quot;both&amp;quot;)
	ax.yaxis.grid(True, which=&amp;quot;major&amp;quot;)
	ax.plot(xData, yData, 
			color = &amp;quot;green&amp;quot;, 
			markeredgewidth = 0.8, 
			linestyle = &#39;-&#39;, 
			linewidth = 2,
			marker = &#39;o&#39;, 
			markersize = 1, 
			label = &amp;quot;label&amp;quot;)
	return ax

def singlePlotHist(yData, nRows, nCols, x0, y0, rowspan, colspan):
	ax = plt.subplot2grid((nRows,nCols), (x0,y0), rowspan, colspan)
	ax.set_xlabel(&amp;quot;x label&amp;quot;)
	ax.set_ylabel(&amp;quot;y label&amp;quot;)
	ax.set_xscale(&amp;quot;linear&amp;quot;)
	ax.set_yscale(&amp;quot;linear&amp;quot;)
	ax.set_title(&amp;quot;Plot title&amp;quot;)
	ax.title.set_y(1.02) # adjust title position
	ax.xaxis.grid(True, which=&amp;quot;both&amp;quot;)
	ax.yaxis.grid(True, which=&amp;quot;major&amp;quot;)
	counts, bin_edges = sm_hist2(yData, delta = 10)
	ax.set_ylim((0, 1.2*counts.max()))
	
	ax.plot(bin_edges, counts, 
				color = &amp;quot;blue&amp;quot;,
				alpha = 0.8,
				linewidth = 2,
				antialiased = True,
				zorder = 3 
				)
	ax.fill(bin_edges, counts, 
				alpha = 0.5,
				hatch = &amp;quot;/&amp;quot;,
				edgecolor = &amp;quot;blue&amp;quot;,
				facecolor = &amp;quot;white&amp;quot;,
				antialiased = True, 
				label = &amp;quot;whatever you want&amp;quot;
				)
	ax.legend(loc=&#39;upper left&#39;, numpoints = 1, prop=font_manager.FontProperties(size=18)).draw_frame(False)

	return ax

if __name__ == &amp;quot;__main__&amp;quot;:
	tt = time.time()
	xData = np.arange(100) 
	yData = np.random.randint(0, 100, size=100) + np.sin(np.arange(100))
	
	fig = plt.figure()
	fig.suptitle(&amp;quot;Figure title&amp;quot;)
	axs = []
	nPlots = 2
	
	axs.append(singlePlotScatter(xData, yData, nRows=1, nCols=2, x0=0, y0=0, rowspan=1, colspan=1))
	axs.append(singlePlotHist(yData, nRows=1, nCols=2, x0=0, y0=1, rowspan=1, colspan=1))
	
	fig.set_size_inches(20, 10)
	plt.savefig(&amp;quot;./grid.png&amp;quot;, dpi=100)
	plt.close(fig)
	
	print &amp;quot;Done in &amp;quot;, time.time()-tt, &amp;quot; seconds.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../../files/grid.png&#34; alt=&#34;Matplotlib plot&#34; title=&#34;Mathplotlib plot&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Check external ip</title>
      <link>http://brunettoziosi.eu/posts/check-external-ip/</link>
      <pubDate>Tue, 03 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/check-external-ip/</guid>
      <description>

&lt;p&gt;This is the first attempt to check the external ip of a linux box.
This means, for example, the public ip address of our modem if we are connected
to the home Wi-Fi.&lt;br /&gt;
I will try to do this in Python and Go. Of course these are raw attempts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; new version &lt;a href=&#34;https://github.com/brunetto/fip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;python:31&#34;&gt;Python&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
import re, os, time

# In internet they say that
# ^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$
# is better but I find this useful

print &amp;quot;Check external ip&amp;quot;
print &amp;quot;This script need curl and the Python modules re, os and time&amp;quot;

# Compile regex
reg = re.compile(&#39;\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}&#39;)

# Query until stop, hoping the site won&#39;t stop us
while True:
	# Ask the site for ip
	string = os.popen(&amp;quot;curl -s &#39;http://checkip.dyndns.org&#39;&amp;quot;).read()
	res = reg.search(string)
	if res == None:
		print &amp;quot;Error, ip not found, continue, ...&amp;quot;
	else:
		print ip
		ip = res.group(0)
		# Recreate the ip file and write the ip
		ipFile = open(&amp;quot;ip.dat&amp;quot;, &#39;w&#39;)
		ipFile.write(ip)
		ipFile.flush()
		ipFile.close()
	# Wait
	time.sleep(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;go:31&#34;&gt;Go&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	//&amp;quot;io/ioutil&amp;quot;
    &amp;quot;os&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;time&amp;quot;
    &amp;quot;os/exec&amp;quot;
    &amp;quot;regexp&amp;quot;
)

// check the errors
func check(e error) {
    if e != nil {
        panic(e)
    }
}

func main() {

	// set ip download command
	
	command := &amp;quot;/usr/bin/curl&amp;quot;
	args := &amp;quot;http://checkip.dyndns.org&amp;quot;
	
	// compile regexp
	var digitsRegexp = regexp.MustCompile(`\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}`)
	
	// infinite loop to update the ip
    for ;;{
		// download ip string
		out, err := exec.Command(command, args).Output()
		if err != nil {
			log.Fatal(err)
		}
		
		// out is a binary buffer, convert into string
		ipString := string(out)
		
		// search for ip
		ipRes := digitsRegexp.FindString(ipString)
		fmt.Println(ipRes)
		
		// convert string to byte (found a better method)
		//ipByte := []byte(ipRes)
		//ioutil.WriteFile(&amp;quot;ip.dat&amp;quot;, ipByte, 0644)
		
		// create a file, it implements the Writer interface
		f, err := os.Create(&amp;quot;ip.dat&amp;quot;)
		
		// check for errors
		check(err)
		
		// close file before exit in case of problems
		defer f.Close()
		
		// write the string, discard (_) the number of bytes written
		_, err = f.WriteString(ipRes)
		// flush 
		f.Sync()
		f.Close()
		// wait
		time.Sleep(5 * time.Second)
    }
}

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Python references</title>
      <link>http://brunettoziosi.eu/pages/tech/python-references/</link>
      <pubDate>Wed, 21 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/pages/tech/python-references/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kirang89/pycrumbs/blob/master/pycrumbs.md&#34;&gt;Super Python Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.astropy.org/&#34;&gt;Astropy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://astrocompute.wordpress.com/&#34;&gt;Astrocompute&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.astropython.org/&#34;&gt;Astropython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://python4astronomers.github.io/&#34;&gt;Python4astronomers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.astrobetter.com/wiki/tiki-index.php?page=Python+Setup+for+Astronomy&#34;&gt;Astrobetter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://astlib.sourceforge.net/&#34;&gt;AstroLib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://oneau.wordpress.com/2010/10/02/python-for-astronomy/&#34;&gt;Python for Astronomy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.astroml.org/&#34;&gt;AstroML&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://bellm.org/blog/2011/05/27/why-astronomers-should-program-in-python/&#34;&gt;Why Astronomers Should Program in Python&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://damianavila.github.io/scipy2013_talks/index.html#/&#34;&gt;Ipython presentations&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://nbviewer.ipython.org/urls/raw.github.com/ipython/ipython/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb&#34;&gt;Examples notebooks&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://scipy-lectures.github.io/&#34;&gt;Scipy lectures&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://slendrmeans.wordpress.com/2012/12/05/better-typography-for-ipython-notebooks/&#34;&gt;Better ipython typography&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/jrjohansson/scientific-python-lectures&#34;&gt;Scientific computing in Python&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Second Pelican attempt: creating a blog on GitHub with Pelican</title>
      <link>http://brunettoziosi.eu/posts/second-pelican-attempt-creating-a-blog-on-github-with-pelican/</link>
      <pubDate>Fri, 08 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/second-pelican-attempt-creating-a-blog-on-github-with-pelican/</guid>
      <description>

&lt;h1 id=&#34;how-to-create-a-blog-with-github-and-pelican-python:84&#34;&gt;How to create a blog with GitHub and Pelican (Python)&lt;/h1&gt;

&lt;p&gt;###Suppose that you are curios about GitHub pages&amp;hellip; but I don&amp;rsquo;t understand their guide.&lt;br /&gt;
###And suppose that you don&amp;rsquo;t like Ruby but prefer Python&amp;hellip;&lt;/p&gt;

&lt;p&gt;First of all create a repo named &lt;code&gt;youname.github.com&lt;/code&gt; on your GitHub account
(ok, maybe, before this, you have to create a GitHub account!).&lt;br /&gt;
&lt;!--TEASER_END--&gt;
Then set the remote origin locally with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    # I use ssh because I can log in without a password saving my key at https://github.com/settings/ssh    
    git remote add origin ssh://git@github.com/yourname/yourname.github.com.git    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can follow the excellent guide by &lt;a href=&#34;http://martinbrochhaus.com/2012/02/pelican.html&#34;&gt;Martin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Maybe you need to change&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    mkvirtualenv -p python2.7 blog    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with something like&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    mkvirtualenv -p /usr/bin/python blog    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you need to write equation, use &lt;a href=&#34;http://www.mathjax.org/&#34;&gt;MathJax&lt;/a&gt; is straightforward.
Following &lt;a href=&#34;http://www.ceremade.dauphine.fr/~amic/en/blog/mathjax-and-pelican.html&#34;&gt;this post&lt;/a&gt;
you only need to add few lines to the &lt;code&gt;base.html&lt;/code&gt; of your theme and write latex-style equation like
&lt;code&gt;$$\frac{x_n}{x_{n+1}}$$&lt;/code&gt; to obtain&lt;/p&gt;

&lt;p&gt;$$\frac{x&lt;em&gt;n}{x&lt;/em&gt;{n+1}}$$&lt;/p&gt;

&lt;p&gt;If you want to show code you only need to indent it with four spaces and put the
languade identifier (&lt;code&gt;:::python&lt;/code&gt;) on the top, indented in the same way (.=space):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;....:::python    
....def print_python():    
........print &amp;quot;Python:)&amp;quot;    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;produces&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def print_python():
    print &amp;quot;Python:)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, if can also blog from the &lt;a href=&#34;http://ipython.org/notebook.html&#34;&gt;IPython Notebook&lt;/a&gt;
following the &lt;a href=&#34;http://danielfrg.github.com/blog/2013/03/08/pelican-ipython-notebook-plugin/&#34;&gt;guide by Daniel&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;And That&amp;rsquo;s all Folks!:P&lt;/p&gt;

&lt;p&gt;PS: see also &lt;a href=&#34;http://blog.xlarrakoetxea.org/posts/2012/10/creating-a-blog-with-pelican/&#34;&gt;this&lt;/a&gt; great guide&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Latex together with matplotlib!</title>
      <link>http://brunettoziosi.eu/posts/latex-together-with-matplotlib/</link>
      <pubDate>Fri, 01 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/latex-together-with-matplotlib/</guid>
      <description>&lt;p&gt;Sometimes you need to label your plot with math expression or Greek letters and ASCII is not enough.&lt;br /&gt;
Everything you need is to add to your script&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from matplotlib import rc
rc(&#39;font&#39;,**{&#39;family&#39;:&#39;sans-serif&#39;,&#39;sans-serif&#39;:[&#39;Helvetica&#39;]})
## for Palatino and other serif fonts use:
#rc(&#39;font&#39;,**{&#39;family&#39;:&#39;serif&#39;,&#39;serif&#39;:[&#39;Palatino&#39;]))
rc(&#39;text&#39;, usetex=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and write you text label like&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;label = r&#39;theoretical $f(nu)$&#39;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Essential guide to binning</title>
      <link>http://brunettoziosi.eu/posts/essential-guide-to-binning/</link>
      <pubDate>Fri, 25 May 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/essential-guide-to-binning/</guid>
      <description>

&lt;p&gt;Often I found myself fighting against data binning, trying to understand the relation between linear and logarithmic bins and how to create the bin starting from the bins number or the bins spacing.&lt;br /&gt;
It&amp;rsquo;s time to write down some consideration and snippet!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To be updated&amp;hellip;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;linear-vs-logarithmic:89&#34;&gt;Linear vs logarithmic&lt;/h2&gt;

&lt;p&gt;I live in a linear space. My advisor and a lot of other scientists live in a logarithmic space. It&amp;rsquo;s quite difficult to easily communicate, but trying to &amp;ldquo;mask&amp;rdquo; this difference life can be more peaceful.&lt;br /&gt;
Hereafter I would like to thing about &amp;ldquo;equally spaced bins&amp;rdquo;. It&amp;rsquo;s not important if they are linearly or logarithmically equally spaced because you can take the same snippet of code and pass to it a logarithmic array, or logarithmic boundaries.&lt;/p&gt;

&lt;h2 id=&#34;from-one-to-the-other:89&#34;&gt;From one to the other&lt;/h2&gt;

&lt;p&gt;Suppose you have an array.  How much will be the bin spacing to obtain &lt;code&gt;n_bin&lt;/code&gt; bins?&lt;br /&gt;
It can be easily computed as&lt;br /&gt;
&lt;code&gt;$\delta_{bin} = (sup-inf)/n_{bin}$&lt;/code&gt;&lt;br /&gt;
From this it&amp;rsquo;s also straightforward to obtain the number of bins from the spacing:&lt;br /&gt;
&lt;code&gt;$n_{bin} = \lfloor(sup-inf)/\delta_{bin}\rfloor$&lt;/code&gt;&lt;br /&gt;
Note that we choose the number of bins to be integer.&lt;/p&gt;

&lt;h2 id=&#34;code:89&#34;&gt;Code&lt;/h2&gt;

&lt;p&gt;Here some code to bin your arrays:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
import sys
import numpy as np

def binning(inf, sup, n_bin=None, delta_bin=None):
	&amp;quot;&amp;quot;&amp;quot;Given the inf and sup limits of an array and the number of equally spaced
	bins, it returns the bin centers, the bin limits and the bin spacing.
	It&#39;s possible to have a linear or a logarithmic spacing passing linear or
	logarithmic inf and sup, and searchsorting on a linear or logarithmic array, 
	or you can use a linear array and logarithmically spaced bins as
	new_bins = pow(10, logbins)
	&amp;quot;&amp;quot;&amp;quot;
	if (n_bin == 0) or (n_bin == 0):
		print &amp;quot;Error, n_bin and/or delta_bin are/is zero, exit!&amp;quot;
		sys.exit()    
	elif (n_bin == None) and (delta_bin != None):
		n_bin = (sup-inf)/delta_bin
		elif (n_bin == None) and (delta_bin == None):
		print &amp;quot;Error, n_bin and delta_bin are both None, exit!&amp;quot;
		sys.exit()
	temp, half_step = np.linspace(inf, sup, 2*n_bin+1, endpoint = True, retstep = True)
	xrange_limit = int(np.floor(temp.size / 2))
	bin_pos = np.zeros(xrange_limit)
	bin_limits = np.zeros(xrange_limit+1)
	for i in xrange(xrange_limit):
		bin_pos[i] = temp[2*i+1]
		bin_limits[i] = temp[2*i]
		bin_limits[-1] = temp[-1]
	del temp
	return [bin_pos, bin_limits, 2*half_step]

def base_binning(inf, sup, n_bin=None, delta_bin=None):
	&amp;quot;&amp;quot;&amp;quot;More C-like...
	&amp;quot;&amp;quot;&amp;quot;
	if (n_bin == 0) or (n_bin == 0):
		print &amp;quot;Error, n_bin and/or delta_bin are/is zero, exit!&amp;quot;
		sys.exit()    
	elif (n_bin == None) and (delta_bin != None):
		n_bin = int((sup-inf)/(1.*delta_bin))
	elif (n_bin != None) and (delta_bin == None):
		delta_bin = (sup-inf)/(1.*n_bin)
	elif (n_bin == None) and (delta_bin == None):
		print &amp;quot;Error, n_bin and delta_bin are both None, exit!&amp;quot;
		sys.exit()
	bin_pos = np.zeros(n_bin)
	bin_limits = np.zeros(n_bin+1)
	for i in range(n_bin):
		if i%2 == 0:
			bin_limits[i] = inf + i * delta_bin
			bin_limits[i+1] = bin_limits[i] + delta_bin
	bin_pos[i] = bin_limits[i] + delta_bin/2.
	bin_limits[n_bin] = inf + n_bin * delta_bin
	return [bin_pos, bin_limits, delta_bin]
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>HDF5 in Python: PyTables</title>
      <link>http://brunettoziosi.eu/posts/hdf5-in-python-pytables/</link>
      <pubDate>Fri, 25 May 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/hdf5-in-python-pytables/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.hdfgroup.org/HDF5/&#34; target=&#34;_blank&#34; title=&#34;HDF5 Group homepage&#34;&gt;HDF5&lt;/a&gt; is a wonderful file format you can use to put into tons of data with easy, without the need to think about endianess, binary formats and so on.&lt;br /&gt;
Pytables is an extremely optimized library built on top of HDF5 capabilities to make even simpler the use of this type of file.&lt;br /&gt;
It&amp;rsquo;s also possible to navigate into a file graphically with &lt;a href=&#34;http://vitables.org/&#34; target=&#34;_blank&#34; title=&#34;ViTables homepage&#34;&gt;ViTables&lt;/a&gt;.&lt;br /&gt;
Here I would like to present some of the features I use more often.&lt;br /&gt;
&lt;!--TEASER_END--&gt;&lt;br /&gt;
Open, flush and close a file&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tables as tb

h5 = tb.openfile(&amp;quot;filename.h5&amp;quot;, &#39;r&#39;)
...
h5.flush()
h5.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;&#39;r&#39;&lt;/code&gt; means &amp;ldquo;open the file in read-only mode&amp;rdquo;. It&amp;rsquo;s also possible to open it as &lt;code&gt;&#39;w&#39;&lt;/code&gt; (create a new file: it overwrites the file if it still exists) and &lt;code&gt;&#39;a&#39;&lt;/code&gt; (append: create if it does not exist, if it exists, read and modify it).&lt;/p&gt;

&lt;p&gt;Create a group to contain some data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;group = h5.createGroup(h5.root, &amp;quot;group&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;h5.root&lt;/code&gt; is the location of the new object created (where we want to create the group) and can also be passe as string (&amp;ldquo;/&amp;rdquo;) and &lt;code&gt;&amp;quot;group&amp;quot;&lt;/code&gt; is the string with the name.&lt;/p&gt;

&lt;p&gt;Store an array&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a = np.array([....])
array = h5.createArray(h5.root.group, &#39;name&#39;, array_to_store, &#39;title&#39;)
array = h5.createArray(&amp;quot;/group&amp;quot;, &#39;name&#39;, array_to_store, &#39;title&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a table (from &lt;a href=&#34;create-recreate-and-remove-duplicates-in-array-manipulation-obviously-in-python.html&#34;&gt;Create, recreate and remove duplicates in array manipulation, obviously in Python!:)&lt;/a&gt; or &lt;a href=&#34;from-csv-to-hdf5-in-python.html&#34;&gt;From .csv to HDF5 in Python&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = open(&amp;quot;filename.csv&amp;quot;, &#39;r&#39;)
line = f.readline()
values = np.genfromtxt(StringIO(line), dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, &#39;f4&#39;)]), delimiter=&#39;,&#39;)
values.shape = 1

# or in an equivalent way, if the file dimensions permit to lad the entire file:
# values = np.genfromtxt(&amp;quot;filename.csv&amp;quot;, dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, # &#39;f4&#39;)]), delimiter=&#39;,&#39;)

h5 = tb.openFile(&#39;filename.h5&#39;, &#39;w&#39;)
table = h5.createTable(h5.root, description=values, name=&#39;table_name&#39;, title=&amp;quot;table_description&amp;quot;, expectedrows=12158536)
table.flush()

for line in f:
	values = np.genfromtxt(StringIO(line), dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, &#39;f4&#39;)]), delimiter=&#39;,&#39;)
	values.shape = 1
	table.append(values)
	
table.flush()
h5.flush()
h5.close()
f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s also possible to walk all the nodes under a group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i in h5.walkNodes(h5.root.group):
	print i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and to delete a node/array/table:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h5.removeNode(h5.root.group, &#39;name&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the nodes are available through their path:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h5.getNode(&amp;quot;/group&amp;quot;, &amp;quot;name&amp;quot;)
h5.root.group.name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to read a table or an array, you can use the function &lt;code&gt;read()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h5.getNode(&amp;quot;/group&amp;quot;, &amp;quot;name&amp;quot;).read()
h5.root.group.name.read()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Create, recreate and remove duplicates in array manipulation, obviously in Python!:)</title>
      <link>http://brunettoziosi.eu/posts/create-recreate-and-remove-duplicates-in-array-manipulation-obviously-in-python/</link>
      <pubDate>Mon, 14 May 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/create-recreate-and-remove-duplicates-in-array-manipulation-obviously-in-python/</guid>
      <description>

&lt;p&gt;I would like to &amp;ldquo;pin&amp;rdquo; here a pair of quick solution to everyday problems I encounter manipulating arrays.&lt;/p&gt;

&lt;h2 id=&#34;create:91&#34;&gt;Create&lt;/h2&gt;

&lt;p&gt;First, the creation of a structured array (an array composed of records made by different data types) array from a file too big to be read at once with &lt;code&gt;np.genfromtxt&lt;/code&gt;. The new array will be stored in an HDF5 file, so this is a conversion from .csv to .h5 file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import tables as tb
from StringIO import StringIO

f = open(&amp;quot;filename.csv&amp;quot;, &#39;r&#39;)
line = f.readline()
values = np.genfromtxt(StringIO(line), dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, &#39;f4&#39;)]), delimiter=&#39;,&#39;)
values.shape = 1
h5 = tb.openFile(&#39;filename.h5&#39;, &#39;w&#39;)
table = h5.createTable(h5.root, description=values, name=table_name&#39;, title=&amp;quot;table_description&amp;quot;, expectedrows=12158536)
table.flush()

for line in f:
	values = np.genfromtxt(StringIO(line), dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, &#39;f4&#39;)]), delimiter=&#39;,&#39;)
	values.shape = 1
	table.append(values)
	
table.flush()
h5.flush()
h5.close()
f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The use of &lt;code&gt;StringIO&lt;/code&gt; is necessary to convert the string containing the line read in a &amp;ldquo;I/O&amp;rdquo; object that &lt;code&gt;np.genfromtxt&lt;/code&gt; can eat.&lt;/p&gt;

&lt;h2 id=&#34;remove-duplicates:91&#34;&gt;Remove duplicates&lt;/h2&gt;

&lt;p&gt;Consider the previous file, if there are duplicates row, &lt;code&gt;np.unique&lt;/code&gt; can help in removing them. Note that we use the first column to identify the duplicates and that the result will be sorted respect to this column.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;new_indexes = np.unique(table[&#39;column_1&#39;], return_index=True, return_inverse=False)[1]
new_array = np.transpose(table[new_indexes])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In general, &lt;code&gt;numpy.unique(array, return_index=True, return_inverse=True)&lt;/code&gt;&lt;br /&gt;
returns an array sorted and without duplicates, the indexes of the original array to create the new array and the indexes of the new one to recreate the old one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;In: a = np.array([5,3,3,7,2,9,1])
In: np.unique(a, return_index=True, return_inverse=True)
Out: 
(array([1, 2, 3, 5, 7, 9]),
	array([6, 4, 1, 0, 3, 5]),
	array([3, 2, 2, 4, 1, 5, 0]))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;recreate:91&#34;&gt;Recreate&lt;/h2&gt;

&lt;p&gt;Sometimes it&amp;rsquo;s useful to split a structured array in different arrays, manipulate them and recreate the structured array, or maybe you need to create a structured array from different arrays to fill a Pytables table.&lt;br /&gt;
To do this a possible solution is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;values = np.array(zip([column_1[0]], [column_2[0]]))
print &amp;quot;Creating table...&amp;quot;
table = h5.createTable(h5.root, description=values, name=&#39;fof_data_snap67&#39;, title=&amp;quot;fof_data_snap67&amp;quot;, expectedrows=11697806)

for i in xrange(1, fof.size):
	values = np.array(zip([column_1[i]], [column_2[i]]))
	table.append(values)

table.flush()
h5.flush()
h5.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s also possible to zip the entire arrays if they fit into memory:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;values = np.array(zip(column_1, column_2))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Parameter space parallel exploration in Python</title>
      <link>http://brunettoziosi.eu/posts/parameter-space-parallel-exploration-in-python/</link>
      <pubDate>Thu, 03 May 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/parameter-space-parallel-exploration-in-python/</guid>
      <description>&lt;p&gt;Today a friend of mine ask me how to quickly and easily parallelize a parameter space exploration in his code. &amp;ldquo;Quickly and easily&amp;rdquo; means &amp;ldquo;do not try to use &lt;a href=&#34;http://www.brunettoziosi.eu/blog/wordpress/phd-question-3-monte-carlo-markov-chain/&#34; target=&#34;_blank&#34; title=&#34;PhD question #3: Monte Carlo Markov chain&#34;&gt;MCMC&lt;/a&gt; or something similar!!!&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;I think a good solution could be use something like &lt;a href=&#34;http://www.brunettoziosi.eu/blog/wordpress/python-parallel-job-manager/&#34; target=&#34;_blank&#34; title=&#34;Python parallel job manager&#34;&gt;this&lt;/a&gt; defining objects to contain parameters combinations and result, like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    class parameter(object):
      &amp;quot;&amp;quot;&amp;quot;Object to handle all the information about a parameter combination.
      &amp;quot;&amp;quot;&amp;quot;
      def __init__(self, a = None, b = None, c= None, d = None):
        &amp;quot;&amp;quot;&amp;quot;Construct parameters object.&amp;quot;&amp;quot;&amp;quot;
        self.name = str(self.a)+&amp;quot;-&amp;quot;+str(self.b)+&amp;quot;-&amp;quot;+str(self.c)+&amp;quot;-&amp;quot;+str(self.d)
        self.a = None
        self.b = None
        self.c = None
        self.d = None
        self.res_a = None
        self.res_b = None
        self.res_c = None
      def __repr__(self):
        return &amp;quot;&amp;quot; % self.name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and filling the queue in this way:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def fill_queue(input_queue):
      &amp;quot;&amp;quot;&amp;quot;Fill the queue&amp;quot;&amp;quot;&amp;quot;
      parameter_set = [xrange(a_limit),xrange(b_limit), xrange(c_limit), xrange(d_limit)]
      # Create all possible combination of the parameters values and from these 
      # generate and put in the queue the objects
      for i in itertools.product(\*l):
        input_queue.put(parameter(i[0], i[1], i[2], i[3]))
      return input_queue
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I think it&amp;rsquo;s not optimal for a huge amount of combinations, because of the huge amount of objects, but in this case you can change the code to use lists or arrays. Anyway it should be better than four nested loops!:P&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The initial condition saga</title>
      <link>http://brunettoziosi.eu/posts/the-initial-condition-saga/</link>
      <pubDate>Tue, 31 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/the-initial-condition-saga/</guid>
      <description>

&lt;p&gt;If reading the previous posts on N-body simulations you have though that initial conditions are a little and easy task, you were wrong! And me with you!&lt;br /&gt;
The first things I have understood banging against them were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Gadget requires initial conditions (ICs) generate by (for example) N-GenIC&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;N-GenIC requires an initial power spectrum from CMBFast that is no longer used&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CMBeasy should substitute CMBFast but it doesn&amp;rsquo;t, it only works for CMB anisotropies&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CAMB should substitute CMBFast&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;the &lt;a href=&#34;http://lambda.gsfc.nasa.gov/toolbox/tb_camb_form.cfm&#34;&gt;CAMB interface&lt;/a&gt; is terrible and not very well documentated&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;camb:103&#34;&gt;CAMB&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with the
&lt;a href=&#34;http://lambda.gsfc.nasa.gov/toolbox/tb_camb_form.cfm&amp;quot; target&#34;&gt;main CAMB interface&lt;/a&gt;.
If you, like me, need an initial power spectrum as input for your ICs generator
you are interested in just few options of the interface. First, you should select
&amp;ldquo;Transfer functions&amp;rdquo; from the &amp;ldquo;Actions to Perform&amp;rdquo; section. You can leave the
default selection on &amp;ldquo;Scalar Cl&amp;rsquo;s&amp;rdquo; and &amp;ldquo;Linear&amp;rdquo;. After that, check the
&amp;ldquo;Cosmological Parameters&amp;rdquo; section if it&amp;rsquo;s ok for you and maybe, leave the
default &amp;ldquo;Initial Scalar Perturbation Mode&amp;rdquo; that is &amp;ldquo;Adiabatic&amp;rdquo;. The last
things you should be interested in are the maximum &lt;code&gt;$k$&lt;/code&gt;, for me it is &lt;code&gt;$10^4$&lt;/code&gt;,
&amp;ldquo;k per logint&amp;rdquo; (it should be something like the k-sampling, for me, 50), the
number of redshift (1) and the (transfer) redshift (0). Now select between
&amp;ldquo;Interpolated Grid&amp;rdquo; or &amp;ldquo;Calculated Values&amp;rdquo; (this parameter switch between and
interpolated regular grid in log k or array at actual computed values that are
better for later re-interpolation, according with the CAMB README) and choose
if you want high precision computation. When you have finished you can click
on &amp;ldquo;Go!&amp;rdquo;. What you obtain is a page with some links to download:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;camb_*.ini&lt;/code&gt;: the configuration file to run the standalone CAMB code on your own&lt;/li&gt;
&lt;li&gt;&lt;code&gt;camb_*.log&lt;/code&gt;: the calculation log&lt;/li&gt;
&lt;li&gt;&lt;code&gt;camb_*_scalcls.dat&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;camb_*_scalcls.fits&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;camb_*_transfer_out_z0.dat&lt;/code&gt;: this is the file containing the transfer
functions for CDM, baryon, photon, massless neutrino, massive neutrinos,
and total (massive) respectively as function of &lt;code&gt;$k$&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;camb_*_matterpower_z0.dat&lt;/code&gt;: it contains the conventionally normalized
matter power spectrum (for baryons+cdm+massive neutrinos), in h/Mpc units&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;where &lt;code&gt;*&lt;/code&gt; is a number that identifies the computation and z0 can be different
if you choose to use a different redshift.&lt;br /&gt;
You can use &lt;code&gt;camb_*_matterpower_z0.dat&lt;/code&gt; as normalized input power spectrum or
you can calculate (also as a check) it on you own using the first and the last
column of &lt;code&gt;camb_*_transfer_out_z0.dat&lt;/code&gt;. You should use the last column because
DM simulations represents with DM particles all the mass, included that of the
baryons, so the initial power spectrum should be the total power spectrum.&lt;br /&gt;
If you want to understand better how CAMB works you can try to read the
&lt;a href=&#34;http://camb.info/readme.html&#34;&gt;CAMB README&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Initial power spectrum theory&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here some theory if you want to understand how to calculate the power spectrum
on your own. Maybe it is well-known and trivial, but for me it wasn&amp;rsquo;t and,
like many of the trivial and well-known things in (not only) cosmology,
it&amp;rsquo;s not easy to find anywhere.&lt;br /&gt;
So, the spectrum is defined as &lt;code&gt;$P(k) = A k^n T(k)^2$&lt;/code&gt;, where k
&lt;code&gt;$n$&lt;/code&gt; is the
&amp;ldquo;primordial spectral index&amp;rdquo; and is taken near the unity. This is a
&amp;ldquo;scale-fee&amp;rdquo; spectrum. &lt;code&gt;$T(k)$&lt;/code&gt; is the transfer function that give a
synthetic and parametric description of how the initial spectrum survive
to the microphysic. &lt;code&gt;$A=\left[\frac{D(z_{\rm fin})}{D(z_{\rm in})}\right]^2$&lt;/code&gt; is the amplitude.&lt;br /&gt;
The normalization of the spectrum is given by the value of &lt;code&gt;$\sigma_8$&lt;/code&gt;,
that is the mean square amplitude of the density field filtered on the scale
of 8 Mpc/h. This values comes from the &amp;lsquo;80s, when Peebles and others
(Davis &amp;amp; Peebles 1983) measured &lt;code&gt;$\sigma_{\rm galaxies}$&lt;/code&gt; and &lt;code&gt;$\sigma_{\rm gal}(R=8)\sim1$&lt;/code&gt;
so they took that values as reference.&lt;br /&gt;
&lt;code&gt;$\sigma_8$&lt;/code&gt; is defined by
&lt;code&gt;$\sigma^2(R) = \frac{1}{(2\pi)^3}\int \mathrm{d}^3kP(k)\tilde W(kR)$&lt;/code&gt; with &lt;code&gt;$R=8\mathrm{Mpc/h}$&lt;/code&gt; and
&lt;code&gt;$\tilde W(kR)$&lt;/code&gt; the Fourier transform of the window (filter) function, usually a top-hat in the positions space.&lt;br /&gt;
The last thing we need to know to obtain the spectrum is the value of the amplitude,
and it can be find by imposing its value so that &lt;code&gt;$\sigma_8$&lt;/code&gt; has a certain (observed) value.&lt;br /&gt;
Because&lt;br /&gt;
&lt;code&gt;$$\sigma^2(R) = \frac{1}{(2\pi)^3}\int \mathrm{d}^3kP(k)\tilde W(kR) = \int \mathrm{d}^3k Ak^nT^2(k))\tilde W(kR)$$&lt;/code&gt;&lt;br /&gt;
we have&lt;br /&gt;
&lt;code&gt;$$A_0 = \frac{s^2_R(R=8) }{ \int\mathrm{d}^3k\, k^n T^2(k) \tilde W(8*k)}$$&lt;/code&gt;.&lt;br /&gt;
Usually &lt;code&gt;$A_0$&lt;/code&gt; is calculated for &lt;code&gt;$\sigma_8=1$&lt;/code&gt; and then scaled with
&lt;code&gt;$A = A_0\sigma^2_{\rm 8;obs}$&lt;/code&gt; where &lt;code&gt;$\sigma_{\rm 8;obs}$&lt;/code&gt; is the observed values for
&lt;code&gt;$\sigma_8$&lt;/code&gt;. With the last observations we have &lt;code&gt;$\sigma_8 = 0.8118405$&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Just to have an idea you can do these computation with a simple python code.
The code below compare the computation done in Python with the values from
&lt;code&gt;camb_*_transfer_out_z0.dat&lt;/code&gt; with the normalized power spectrum from &lt;code&gt;camb_*_matterpower_z0.dat&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
import numpy as np
import matplotlib.pyplot as plt

# Load data
transfer = np.genfromtxt(&#39;camb_88704620_transfer_out_z0.dat&#39;, usecols = (0,6))
matterpower = np.genfromtxt(&#39;camb_88704620_matterpower_z0.dat&#39;)

# Python calculations
camb_k = transfer[:,0]
camb_tf = transfer[:,1] 
R = 8 #Mpc/h
s_8 = 0.8118405
sp_ind = 1

# Define the FT of the window function
def FTW(R, k):
  return 3*(np.sin(k*R)-k*R*np.cos(k*R)) / (k*R)**3

# camb_k**(2+sp_ind) that is k^(2+n) because d^3k=4\pi k^2dk
amp_integrand = camb_k**(2+sp_ind)*camb_tf**2 * FTW(8, camb_k)**2
amp_integral = integrate.trapz(amp_integrand, camb_k)
amp_0 = 2*np.pi**2/amp_integral
amp = amp_0*s_8**2
spectrum = camb_k**sp_ind*camb_tf**2 * amp

ax = fig.add_subplot(111)
ax.set_title(&#39;Fortran/Python CDM initial power spectrum&#39;)
ax.set_xlabel(&#39;k&#39;)
ax.set_ylabel(&#39;P(k)&#39;)
ax.set_xscale(&#39;log&#39;)
ax.set_yscale(&#39;log&#39;)

ax.plot(transfer[:,0], spectrum[:], color = &amp;quot;magenta&amp;quot;, 
           linestyle = &#39;-&#39;, marker = &#39;&#39;, label = &amp;quot;* python amp&amp;quot;) 
ax.plot(matterpower[:,0], matterpower[:,1], color = &amp;quot;black&amp;quot;, 
            linestyle = &#39;--&#39;, marker = &#39;&#39;, label = &amp;quot;matterpower&amp;quot;)
ax.legend(loc=&#39;best&#39;)
ax.grid(True)

# Adjust figure size and save
fig.set_size_inches(20, 20)
plt.savefig(&#39;camb_f90_py_check&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result is this&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../files/camb_f90_py_check.png&#34; alt=&#34;CAMB vs Python calculated initial power spectrum&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If you want you can check the power spectrum we have obtained by integrating it
to find &lt;code&gt;$\sigma_8$&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sigma_integrand = camb_k**2 * spectrum * FTW(8, camb_k)**2
s_8_check = pow(integrate.trapz(sigma_integrand, camb_k)/(2*np.pi**2), 0.5)
print &amp;quot;s_8_calculated&amp;quot;, s_8_check
print &amp;quot;s_8 observed&amp;quot;, s_8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;obtaining&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ziosi@uno:~/Code/spettro_CMB$ ./CAMB_check_plot.py
s_8_calculated 0.8118405
s_8 observed 0.8118405
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;N-GenIC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now we have the initial power spectrum ready for the ICs generator. After N-GenIC
have been compiled (try to read &lt;a href=&#34;my-first-gadget2-tests&#34;&gt;this&lt;/a&gt;
if you have compilation problems related to the parallel double precision FFTW libraries
or if you want to know how to customize the Makefile) we should have a look at the configuration file.&lt;br /&gt;
We are interested in:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Nmesh&lt;/code&gt;: the size (=the number of nodes) of the FFT grid used to compute the
displacement field, should be &lt;code&gt;Nmesh&lt;/code&gt; &lt;code&gt;$\geq$&lt;/code&gt; &lt;code&gt;Nsample&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Nsample&lt;/code&gt;: this is the maximum k that the code uses, i.e. this effectively
determines the Nyquist frequency that the code assumes, &lt;code&gt;$k_{\rm Nyquist} = 2\cdot \pi/{\rm Box} \cdot  {\rm Nsample}/2$&lt;/code&gt; Normally,
one chooses &lt;code&gt;Nsample&lt;/code&gt; such that &lt;code&gt;${\rm Ntot} =  {\rm Nsample}^3$&lt;/code&gt;, where &lt;code&gt;Ntot&lt;/code&gt; is the total number
of particles. Because the grid sample the particles quantities, Nmesh sets the Nyquist
frequency of Nsample, so it&amp;rsquo;s good if &lt;code&gt;${\rm Nmesh} = 2\cdot {\rm Nsample}$&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ReNormalizeInputSpectrum&lt;/code&gt;: set it to 0 because we are going to use the previous
spectrum that is already normalized, if you don&amp;rsquo;t remember this the code will have
integration problems&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TileFac&lt;/code&gt;: it represents how many times you need to tile the glass file
(for each dimension) to cover the number of particles you want to use.
The glass file contains 4097 particles. Glass particles positions will be
automatically stretched to cover the box dimension. When you download N-GenIC
you find &lt;code&gt;${\rm Nsample} = 128$&lt;/code&gt; and &lt;code&gt;${\rm TileFac} = 8$&lt;/code&gt;, this is because the total number of
particles is &lt;code&gt;${\rm Ntot} = {\rm Nsample}^3 = 128^3=2097125$&lt;/code&gt; and the number of glass particles
is &lt;code&gt;${\rm TileFac}^3\cdot {\rm Nglass} = 8^3\cdot 4096 = 2097125$&lt;/code&gt;. In practice, if you want to
know what &lt;code&gt;TileFac&lt;/code&gt; should be, and you have &lt;code&gt;Ntot&lt;/code&gt; particles in you simulation,
&lt;code&gt;TileFac&lt;/code&gt; will be &lt;code&gt;$\frac{{\rm Ntot}^{1/3}}{4096} = \frac{{\rm Nsample}}{4096}$&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WhichSpectrum&lt;/code&gt;: let you choose if you want to use an internal spectrum
(calculated with a function) or the spectrum from CAMB&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FileWithInputSpectrum&lt;/code&gt;: it&amp;rsquo;s, obviously, the name of the file containing the spectrum&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The other parameters are cosmological parameters or are related to the folders, the name and the
number of files, the parallelization and to the internal measure units.&lt;br /&gt;
Other options are (more or less) documented with comments in the code or in the README.&lt;br /&gt;
We can now start N-GenIC with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mpiexec -np 2  ./N-GenIC  ics.param
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;-np&lt;/code&gt; let you set the number of processors you want to use in parallel.&lt;br /&gt;
Before using the output files with gadget we should open those and calculate the power
spectrum to check that this realization of it is a good one. This problem arise because
of the sampling of the k-space where few modes are available, but I will deepen on those matter in a future post.&lt;br /&gt;
There is also an improved version of N-GenIC, 2LPTIC, but it need a different
installation of the FFTW so I didn&amp;rsquo;t try it.&lt;/p&gt;

&lt;p&gt;Many of these things can be found &lt;a href=&#34;http://www.annualreviews.org/doi/abs/10.1146/annurev.astro.36.1.599&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GIF2 files Python reader</title>
      <link>http://brunettoziosi.eu/posts/gif2-files-python-reader/</link>
      <pubDate>Tue, 06 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/gif2-files-python-reader/</guid>
      <description>&lt;p&gt;I create this script on the basis of the code to read the Millennium II data (the same used &lt;a href=&#34;http://elbrunz.wordpress.com/2011/12/02/from-binaries-to-hdf5-using-python/&#34; title=&#34;From binaries to HDF5 using Python&#34;&gt;here&lt;/a&gt;) provided by &lt;a href=&#34;http://mbk.ps.uci.edu/index.html&#34; title=&#34;Mike Boylan-Kolchin&#34;&gt;Mike Boylan-Kolchin&lt;/a&gt;. Being allowed to read the Fortran code to write and read the GIF2 files I could adapt this script to exactly fit this problem.&lt;/p&gt;

&lt;!-- TEASER_END--&gt;    

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import sys

class head:
    def __init__(self, fname):
        import types
        bo_mark=&#39;&amp;gt;&#39;
        # start by reading in header:    
        if type(fname) is types.StringType:
            f=open(fname, &#39;rb&#39;)
        elif type(fname) is not types.FileType:
            raise TypeError(&#39;argument must either be an open file or &#39; + 
                            &#39;a string containing a file name&#39;)
        else:
            f=fname
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the usual imports we define a class to read and contain the file header. These first lines check the &amp;ldquo;filename&amp;rdquo; argument.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;self.pad = np.fromfile(f, count=1, dtype=bo_mark+&#39;i4&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the unformatted Fortran binary files the &amp;ldquo;pad&amp;rdquo; is a 4-byte space to separate the values of different quantities in the file. &lt;code&gt;bo_mark&lt;/code&gt; contains the endianess (&amp;ldquo;bo&amp;rdquo; means byte order) of the system allowing Python to correctly interpret the numbers from the binary file. &lt;code&gt;count&lt;/code&gt; sets the number of item of type &lt;code&gt;dtype&lt;/code&gt; to be read. For example &lt;code&gt;count=3&lt;/code&gt; and &lt;code&gt;dtype=bo_mark+&#39;i4&#39;&lt;/code&gt; will store three 4-byte integer in the variable, with the byte order expressed by &lt;code&gt;bo_mark&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt; for big-endian, &lt;code&gt;&amp;gt;&lt;/code&gt; for little-endian.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# npart is an array containing the number of particles in the
        # file divided by type (gas, ...)
        self.npart = np.fromfile(f, count=6, dtype=bo_mark+&#39;i4&#39;)
        self.massarr = np.fromfile(f, count=6, dtype=bo_mark+&#39;f8&#39;)
        self.aaa = np.fromfile(f, count=1, dtype=bo_mark+&#39;f8&#39;)
        self.redshift = np.fromfile(f, count=1, dtype=bo_mark+&#39;f8&#39;)
        self.flag_sfr = np.fromfile(f, count=1, dtype=bo_mark+&#39;i4&#39;)
        self.flag_feedback = np.fromfile(f, count=1, dtype=bo_mark+&#39;i4&#39;)
        self.nall = np.fromfile(f, count=6, dtype=bo_mark+&#39;i4&#39;)
        self.cooling_flag = np.fromfile(f, count=1, dtype=bo_mark+&#39;i4&#39;)
        self.numfiles = np.fromfile(f, count=1, dtype=bo_mark+&#39;i4&#39;)
        self.boxsize = np.fromfile(f, count=1, dtype=bo_mark+&#39;f8&#39;)
        self.Omega = np.fromfile(f, count=1, dtype=bo_mark+&#39;f8&#39;)
        self.OmegaL0 = np.fromfile(f, count=1, dtype=bo_mark+&#39;f8&#39;)
        self.Hubblepar = np.fromfile(f, count=1, dtype=bo_mark+&#39;f8&#39;)
        self.version = np.fromfile(f, count=1, dtype=bo_mark+&#39;a96&#39;)
        self.pad2=np.fromfile(f, count=1, dtype=bo_mark+&#39;i4&#39;)
        if type(fname) is types.StringType: f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These lines read and store the values of the quantities saved in the header of the file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def read_gif2_file(fname):
    bo_mark = &#39;&amp;gt;&#39;
    f=open(fname, &#39;rb&#39;)
    # start by reading in header:    
    ghead=head(f)
    npt=ghead.npart.sum()````
    
This is the function we use to read the files: it set the endianness to &amp;quot;big-endian&amp;quot;, open the file in read-only mode, read the header and extract the total number of particles.    
````python
f.seek(4, 1)
    pos=np.fromfile(f, count=npt*3, dtype=bo_mark + &#39;f4&#39;).reshape((npt, 3))
    return pos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;f.seek(offset, from_what)&lt;/code&gt; move the pointer through the file to read bits from one position to another. The position is computed from adding &lt;code&gt;offset&lt;/code&gt; to a reference point; the reference point is selected by the &lt;code&gt;from_what&lt;/code&gt; argument. A &lt;code&gt;from_what&lt;/code&gt; value of 0 measures from the beginning of the file, 1 uses the current file position, and 2 uses the end of the file as the reference point. &lt;code&gt;from_what&lt;/code&gt; can be omitted and defaults to 0, using the beginning of the file as the reference point (from the &lt;a href=&#34;http://docs.python.org/tutorial/inputoutput.html&#34; title=&#34;Python documentation&#34;&gt;Python documentation&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;This last piece of code read the GIF2 galaxy catalogue (an ASCII file with &amp;ldquo;space separated values&amp;rdquo;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#! /usr/bin/env python

file = open(&#39;lcdm_galaxy_cat.z0.00&#39;, &#39;rb&#39;)
i = 0
for riga in file.readlines():
    parole = riga.split()
    if len(parole) == 11:
        print &amp;quot;iterazione &amp;quot;, i 
        print &amp;quot;aggiungo &amp;quot;
        x.append(parole[5])
        y.append(parole[6])
        z.append(parole[7])
    i+=1
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>From .csv to HDF5 in Python</title>
      <link>http://brunettoziosi.eu/posts/from-csv-to-hdf5-in-python/</link>
      <pubDate>Fri, 02 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/from-csv-to-hdf5-in-python/</guid>
      <description>&lt;p&gt;PyTables is a Python library that provide a simple but really useful interface to manage the HDF5 files with some other interesting features (compression, optimizations, &amp;hellip;). To the library presentation and documentation, for now refers, to the &lt;a href=&#34;http://www.pytables.org/moin&#34; target=&#34;_blank&#34; title=&#34;site&#34;&gt;site&lt;/a&gt;.&lt;br /&gt;
I used it a lot during my master thesis to manage the dataset from the Millennium database.&lt;br /&gt;
Here I provide a brief review of how I used it to store data obtained in .csv (comma separated values) format.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;    

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python

import numpy as np
import tables as tb
import time

t = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As usual, we have the initial import of the modules we need and start the timing of the code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fofhdf5 = tb.openFile(&#39;mill2_fof_snap67.h5&#39;, &#39;w&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This create the HDF5-file object we use to work on the file, in write (&lt;code&gt;&#39;w&#39;&lt;/code&gt;) mode. Read-only (&lt;code&gt;&#39;r&#39;&lt;/code&gt;) mode is also possible.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fof_data = np.genfromtxt(&#39;fof0.csv&#39;, dtype=([(&#39;fofId&#39;, &#39;i8&#39;), (&#39;np&#39;, &#39;i4&#39;), (&#39;mass&#39;, &#39;f4&#39;), (&#39;x&#39;, &#39;f4&#39;), (&#39;y&#39;, &#39;f4&#39;), (&#39;z&#39;, &#39;f4&#39;), (&#39;ix&#39;, &#39;i4&#39;), (&#39;iy&#39;, &#39;i4&#39;), (&#39;iz&#39;, &#39;i4&#39;), (&#39;m_crit_200&#39;, &#39;f4&#39;), (&#39;r_crit_200&#39;, &#39;f4&#39;), (&#39;m_mean_200&#39;, &#39;f4&#39;), (&#39;r_meam_200&#39;, &#39;f4&#39;), (&#39;m_tophat&#39;, &#39;f4&#39;), (&#39;r_tophat&#39;, &#39;f4&#39;), (&#39;numSubs&#39;, &#39;i4&#39;)]), comments=&#39;#&#39;, delimiter=&#39;,&#39;, skiprows=26)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we read the .csv/ASCII table and from this we create a table of numpy arrays, each of them with its own name and type. It&amp;rsquo;s also possible to specify the character for the comments in the file (&lt;code&gt;#&lt;/code&gt;), the character separating the values (commas, spaces, &amp;hellip;) and the number of line to be skipped (file header).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;table = fofhdf5.createTable(fofhdf5.root, description=fof_data, name=&#39;fof_data_snap67&#39;, title=&amp;quot;fof_data_snap67&amp;quot;, expectedrows=11697806)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create the HDF5-table with the proper hierarchy, some metadata (description and title). Specify the number of rows one expects to put into the table helps the library to optimize the operations and the space.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i in range(1, 20):
    fof_data = np.genfromtxt(&#39;fof&#39;+str(i)+&#39;.csv&#39;, dtype=([(&#39;fofId&#39;, &#39;i8&#39;), (&#39;np&#39;, &#39;i4&#39;), (&#39;mass&#39;, &#39;f4&#39;), (&#39;x&#39;, &#39;f4&#39;), (&#39;y&#39;, &#39;f4&#39;), (&#39;z&#39;, &#39;f4&#39;), (&#39;ix&#39;, &#39;i4&#39;), (&#39;iy&#39;, &#39;i4&#39;), (&#39;iz&#39;, &#39;i4&#39;), (&#39;m_crit_200&#39;, &#39;f4&#39;), (&#39;r_crit_200&#39;, &#39;f4&#39;), (&#39;m_mean_200&#39;, &#39;f4&#39;), (&#39;r_meam_200&#39;, &#39;f4&#39;), (&#39;m_tophat&#39;, &#39;f4&#39;), (&#39;r_tophat&#39;, &#39;f4&#39;), (&#39;numSubs&#39;, &#39;i4&#39;)]), comments=&#39;#&#39;, delimiter=&#39;,&#39;, skiprows=26)
    
    table.append(fof_data)
    table.flush()
    print &amp;quot;Loop &amp;quot;, i, &amp;quot; done.&amp;quot;

fofhdf5.close()
print &amp;quot;Done in &amp;quot;, time.time()-t, &amp;quot;seconds !!!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;for&lt;/code&gt; loop opens other ASCII tables and append them to the existing HDF5-table. The &lt;code&gt;table.flush()&lt;/code&gt; command let the library physically write the data on the disk instead of maintaining them in memory and write them periodically. After that we close the file object.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From binaries to HDF5 using Python</title>
      <link>http://brunettoziosi.eu/posts/from-binaries-to-hdf5-using-python/</link>
      <pubDate>Fri, 02 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/from-binaries-to-hdf5-using-python/</guid>
      <description>&lt;p&gt;I have used this script to convert the Millennium II data from the unformatted fortran binary formato to the DF5 one.&lt;br /&gt;
The core of the script is a module (&lt;code&gt;modified_read_snapshots&lt;/code&gt;) built on the basis of a script kindly provided by &lt;a href=&#34;http://mbk.ps.uci.edu/index.html&#34; target=&#34;_blank&#34; title=&#34;Mike Boylan-Kolchin&#34;&gt;Mike Boylan-Kolchin&lt;/a&gt; from the group that perform the Millennium II simulation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python    

import time
import kd3hdf5
import tables as tb
import modified_read_snapshots as rs

t = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The usual imports and time initialization!:P&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def bin2hdf5(bin_file, h5_file, tree = False):
    snap = rs.read_snapshot(bin_file)
    h5f = kd3hdf5.KDTree(h5_file, &#39;w&#39;)
    h5f.data_store(snap[&#39;pos&#39;])
    if tree == True:
        h5f.tree_build
    h5f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function accept as arguments the name of the binary file, the name of the HDF5 file to be created and give the user the possibility to create a KDTree with the data. By default it won&amp;rsquo;t create this tree. If no KDTree must be created the function only uses the part of the &lt;code&gt;kd3hdf5&lt;/code&gt; module that store the data into the HDF5 file. We will have a brief view of this at the end of the post.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def main():
    print &amp;quot;start&amp;quot;
    for i in [0, 10, 100, 200, 511]:
        t2 = time.time()
        print &amp;quot;Loop &amp;quot;, i
        t3 = time.time()
        bin2hdf5(&#39;../binary/snap_newMillen_subidorder_067.&#39;+str(i), &#39;../hdf5/data_&#39;+str(i))
        print &amp;quot;Loop &amp;quot;, i, &amp;quot; finished in &amp;quot;, time.time()-t2

    print &amp;quot;That&#39;s all folks, in &amp;quot;, time.time()-t, &amp;quot;!!!&amp;quot;

if __name__ == &amp;quot;__main__&amp;quot;:
    main()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing more than calling the previous function on the data files looping on their names!:)&lt;br /&gt;
Respect to the other posts here we make use of the &lt;code&gt;main&lt;/code&gt; function but is nothing extraordinary!:P&lt;/p&gt;

&lt;p&gt;The code from the &lt;code&gt;kd3hdf5&lt;/code&gt; module is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class KDTree(object):
    #Docs [...]

    def __init__(self, filename, mode):
        if mode == &#39;read&#39; or mode == &#39;r&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;r&amp;quot;)
        elif mode == &#39;append&#39; or mode == &#39;a&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;a&amp;quot;)
        elif mode == &#39;build&#39; or mode == &#39;w&#39; or mode == &#39;write&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;w&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This provide the creation of the object, linked to an HDF5 file and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def data_store(self, data):
        t = time.time()
        self.h5file.createArray(self.h5file.root, &#39;data&#39;, np.asarray(data), title=&#39;data&#39;)
        self.h5file.root.data._v_attrs.n_elements = data.shape[0]
        self.h5file.root.data._v_attrs.m_dimensions = data.shape[1]
        self.h5file.root.data._v_attrs.maxes = np.amax(data,axis=0)   # maxes and mins for each coord
        self.h5file.root.data._v_attrs.mins = np.amin(data,axis=0)
        print self.h5file.root.data._v_attrs.n_elements, &amp;quot; Stored in &amp;quot;, time.time()-t, &amp;quot;seconds.&amp;quot;
        t = time.time()
        self.h5file.root.data.flush()
        print time.time()-t, &amp;quot; seconds to commit changes.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fill the file with the data and some metadata (table dimension and maxes and mins of the data).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python slicing, rebinning and indexing</title>
      <link>http://brunettoziosi.eu/posts/python-slicing-rebinning-and-indexing/</link>
      <pubDate>Fri, 25 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/python-slicing-rebinning-and-indexing/</guid>
      <description>&lt;p&gt;During my master thesis I had to manage a lot of (different) data from GIF and GIF2 projects, Millimillennium, Millenium and Millennium 2 simulations and so on. Sometimes there were the need to sort, divide or rearrange these dataset.&lt;br /&gt;
Here some examples.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sort the Millennium 2 data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I developed this script to sort the Millennium 2 data in the $x$ coordinate. The dataset was composed of 512 hdf5 files and I would like to create 1000 files of 100 kpc/h each, taking particles for all the original files.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/bin/env python
import time
import numpy as np
import tables as tb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the usual modules importing. &lt;code&gt;tables&lt;/code&gt; is the module provided by PyTables to manage, in a great way, hdf5 file under Python.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;t_glob = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Timing is always good!!!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This create the first &amp;quot;5 Mpc/h&amp;quot; file, every loop operate on 100 kpc/h of data 
for i in range(0,50):
    t = time.time()
    i_dist = i/10.0
    j_dist = i_dist + 0.1
    print &amp;quot;Starting with limits [Mpc/h]&amp;quot;, i_dist, j_dist
    temp2 = np.array([])
    temp2.shape = (0,3)
    # This loop open each of the 512 original files
    # selecting the particles inside the limits
    # and stacking them into the array that will 
    # be saved in the new file
    for j in range(0,512):
        filename = &#39;../../hdf5/data_&#39;+str(j)
        print &amp;quot;Open &amp;quot;, filename
        h5 = tb.openFile(filename, &#39;r&#39;)
        original = h5.root.data.read()
        h5.close()
        temp = original[original[:,0]&amp;amp;gt;i_dist]
        if temp.size &amp;amp;lt; 3:
            temp3 = np.array([])
            temp3.shape=(0,3)
        else:
            temp3 = temp[temp[:,0]&amp;amp;lt;=j_dist]
        try:
            temp2 = np.vstack((temp2,temp3))
        except:
            print &amp;quot;Error in stacking&amp;quot;
            print &amp;quot;temp2 dimensions &amp;quot;, temp2.shape
            print &amp;quot;temp3 dimensions &amp;quot;, temp3.shape
            exit()
    tt=time.time()

    # Sorting the array in the x direction
    temp2[temp2[:,0].argsort(),]
    print &amp;quot;Time for argsort &amp;quot;, time.time()-tt

    # Writing data to file
    destname = &#39;../../hdf5_sorted/mill2sort-&#39;+str(i)
    print &amp;quot;Writing &amp;quot;, destname
    dest = tb.openFile(destname, &#39;w&#39;)
    dest.createArray(dest.root, &#39;data&#39;, temp2, title=&#39;data&#39;)
    dest.flush()
    dest.close()
    print &amp;quot;Time for loop  &amp;quot;, i, &amp;quot; is &amp;quot;, time.time()-t
print &amp;quot;Done in &amp;quot;,time.time()-t_glob, &amp;quot;seconds&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Rebin the sorted Millennium 2 data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After I have sorted the data, we need to rebin the dataset because it doesn&amp;rsquo;t fit into our machine memory.&lt;br /&gt;
This script make use of the &lt;a href=&#34;http://brunettoziosi.blogspot.it/2011/11/python-parallel-job-manager.html&#34; target=&#34;_blank&#34; title=&#34;Python parallel job manager&#34;&gt; parallel job manager&lt;/a&gt; to break the 1000 files of the sorted dataset into 5000 files each containing 20 kpc/h of data, sorted in the $x$ direction.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#! /usr/bin/env python

import sys, os
import numpy as np
import tables as tb
from subprocess import Popen, PIPE
from multiprocessing import Process, Queue


#############################################
sub_slice_dim = 0.02    #Mpc/h
sub_slice_num = 5 # for each of the original slice
n_procs = 5
tot_mill_slice = 999   # number of original slices
############################################


def slicing(i, j, sub_slice_dim, sub_slice_num):
    &amp;quot;&amp;quot;&amp;quot;Given a mill2 slice it creates 5 subslices.
    &amp;quot;&amp;quot;&amp;quot;
    start_dim = j\*sub_slice_dim
    stop_dim = start_dim + sub_slice_dim
    print &amp;quot;Loop &amp;quot;, j, &amp;quot; of &amp;quot;, sub_slice_num , &amp;quot; between &amp;quot;, start_dim, &amp;quot; and &amp;quot;, stop_dim, &amp;quot; in slice &amp;quot;, i 
    pos_greater = mill_slice[start_dim &amp;amp;lt; mill_slice[:,0]]
    pos = pos_greater[pos_greater[:,0] &amp;amp;lt;= stop_dim]
    h5=tb.openFile(&#39;/home/ziosi/mill2_data/hdf5_sorted_rebinned/mill2sort-&#39;+str(i*5+j)+&#39;.h5&#39;, &#39;w&#39;)
    h5.createArray(h5.root, &#39;data&#39;, pos, title=&#39;mill2_sorted_rebinned_pos&#39;)
    h5.flush()
    h5.close()

def breakmill(in_queue):
    &amp;quot;&amp;quot;&amp;quot;Bring a slice from the queue and start the function to
    sub_slice it.
    &amp;quot;&amp;quot;&amp;quot;
    while in_queue.qsize != 0:
        ii = in_queue.get()
        i = ii[0]
        sub_slice_dim = ii[1]
        sub_slice_num = ii[2]
        original_slice = &amp;quot;/home/ziosi/mill2_data/hdf5_sorted/mill2sort-&amp;quot;+str(i)
        mill_slice = tb.openFile(original_slice, &#39;r&#39;)
        slice_data = mill_slice.root.data.read()
        slice_min = np.amin(slice_data[:,0])
        for j in xrange(5):
            slicing(i, j, sub_slice, slice_dim, sub_slice_num)
    
# Create the queues.
in_queue = Queue()
out_queue = Queue()

# Fill the input queue.
try:
    for i in xrange(tot_mill_slice):
        in_queue.put([i, sub_slice_dim, sub_slice_num])
except:
    print &amp;quot;Input queue not filled, exit!&amp;quot;
    sys.exit(1)

procs = []

# Create the processes.
try:
    for i in range(n_procs):
        print &amp;quot;Process creation loop &amp;quot;, i
        procs.append(Process(target=breakmill, args=(in_queue, out_queue)))
except:
    print &amp;quot;Creating processes not complete, exit...&amp;quot;
    sys.exit(1)

# Start the processes.
try:
    for i in procs:
        i.start()
except:
    print &amp;quot;Start processes not complete, exit...&amp;quot;;
    sys.exit(1)

# Check for processes status.
for i in procs:
    print &amp;quot;Process &amp;quot;, i,&amp;quot; @ &amp;quot; , i.pid, &amp;quot; is &amp;quot;, status(i)

print &amp;quot;Done.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Indexing data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We also need to index a data file to can retrieve only a slice from the entire file. We did it using the following three elements:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;flags = np.arange(0, 110, 0.1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is the array containing the markers for the distances we want to index. This means that if we want to index distances from 0 to 10 every 1, we get: 0,1,2,3,4,5,6,7,8,9,10, so we can select, for example, the element between 0 and 1 without load the entire list.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;start = indexes[np.maximum(np.searchsorted(indexes[:,0], xstart, side=&#39;left&#39;)-1, 0), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;contains the index of the cell in the array that contains the first element we want&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;stop = indexes[np.minimum(np.searchsorted(indexes[:+1], xstop, side=&#39;right&#39;)+1, indexes.shape[0]-1), 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;contains the index of the cell in the array that contains the first element we want.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;indexes = np.hstack((flags.reshape((flags.shape[0], 1)), start.reshape((start.shape[0], 1)), end.reshape((end.shape[0], 1))))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is the $(n,3)$ array with the flag, the start and the stop indexes. It is saved into the data file.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>