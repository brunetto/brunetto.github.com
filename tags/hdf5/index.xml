<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hdf5 on Post It!</title>
    <link>http://brunettoziosi.eu/tags/hdf5/</link>
    <description>Recent content in Hdf5 on Post It!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 May 2012 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://brunettoziosi.eu/tags/hdf5/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>HDF5 in Python: PyTables</title>
      <link>http://brunettoziosi.eu/posts/hdf5-in-python-pytables/</link>
      <pubDate>Fri, 25 May 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/hdf5-in-python-pytables/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.hdfgroup.org/HDF5/&#34; target=&#34;_blank&#34; title=&#34;HDF5 Group homepage&#34;&gt;HDF5&lt;/a&gt; is a wonderful file format you can use to put into tons of data with easy, without the need to think about endianess, binary formats and so on.&lt;br /&gt;
Pytables is an extremely optimized library built on top of HDF5 capabilities to make even simpler the use of this type of file.&lt;br /&gt;
It&amp;rsquo;s also possible to navigate into a file graphically with &lt;a href=&#34;http://vitables.org/&#34; target=&#34;_blank&#34; title=&#34;ViTables homepage&#34;&gt;ViTables&lt;/a&gt;.&lt;br /&gt;
Here I would like to present some of the features I use more often.&lt;br /&gt;
&amp;lt;!&amp;ndash;TEASER_END&amp;ndash;&amp;gt;&lt;br /&gt;
Open, flush and close a file&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tables as tb

h5 = tb.openfile(&amp;quot;filename.h5&amp;quot;, &#39;r&#39;)
...
h5.flush()
h5.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;&#39;r&#39;&lt;/code&gt; means &amp;ldquo;open the file in read-only mode&amp;rdquo;. It&amp;rsquo;s also possible to open it as &lt;code&gt;&#39;w&#39;&lt;/code&gt; (create a new file: it overwrites the file if it still exists) and &lt;code&gt;&#39;a&#39;&lt;/code&gt; (append: create if it does not exist, if it exists, read and modify it).&lt;/p&gt;

&lt;p&gt;Create a group to contain some data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;group = h5.createGroup(h5.root, &amp;quot;group&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;h5.root&lt;/code&gt; is the location of the new object created (where we want to create the group) and can also be passe as string (&amp;ldquo;/&amp;rdquo;) and &lt;code&gt;&amp;quot;group&amp;quot;&lt;/code&gt; is the string with the name.&lt;/p&gt;

&lt;p&gt;Store an array&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a = np.array([....])
array = h5.createArray(h5.root.group, &#39;name&#39;, array_to_store, &#39;title&#39;)
array = h5.createArray(&amp;quot;/group&amp;quot;, &#39;name&#39;, array_to_store, &#39;title&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a table (from &lt;a href=&#34;create-recreate-and-remove-duplicates-in-array-manipulation-obviously-in-python.html&#34;&gt;Create, recreate and remove duplicates in array manipulation, obviously in Python!:)&lt;/a&gt; or &lt;a href=&#34;from-csv-to-hdf5-in-python.html&#34;&gt;From .csv to HDF5 in Python&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f = open(&amp;quot;filename.csv&amp;quot;, &#39;r&#39;)
line = f.readline()
values = np.genfromtxt(StringIO(line), dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, &#39;f4&#39;)]), delimiter=&#39;,&#39;)
values.shape = 1

# or in an equivalent way, if the file dimensions permit to lad the entire file:
# values = np.genfromtxt(&amp;quot;filename.csv&amp;quot;, dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, # &#39;f4&#39;)]), delimiter=&#39;,&#39;)

h5 = tb.openFile(&#39;filename.h5&#39;, &#39;w&#39;)
table = h5.createTable(h5.root, description=values, name=&#39;table_name&#39;, title=&amp;quot;table_description&amp;quot;, expectedrows=12158536)
table.flush()

for line in f:
	values = np.genfromtxt(StringIO(line), dtype=([(&#39;column_1&#39;, &#39;i8&#39;), (&#39;column_2&#39;, &#39;f4&#39;), (&#39;column_3&#39;, &#39;f4&#39;)]), delimiter=&#39;,&#39;)
	values.shape = 1
	table.append(values)
	
table.flush()
h5.flush()
h5.close()
f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s also possible to walk all the nodes under a group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i in h5.walkNodes(h5.root.group):
	print i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and to delete a node/array/table:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h5.removeNode(h5.root.group, &#39;name&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All the nodes are available through their path:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h5.getNode(&amp;quot;/group&amp;quot;, &amp;quot;name&amp;quot;)
h5.root.group.name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to read a table or an array, you can use the function &lt;code&gt;read()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h5.getNode(&amp;quot;/group&amp;quot;, &amp;quot;name&amp;quot;).read()
h5.root.group.name.read()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>From .csv to HDF5 in Python</title>
      <link>http://brunettoziosi.eu/posts/from-csv-to-hdf5-in-python/</link>
      <pubDate>Fri, 02 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/from-csv-to-hdf5-in-python/</guid>
      <description>&lt;p&gt;PyTables is a Python library that provide a simple but really useful interface to manage the HDF5 files with some other interesting features (compression, optimizations, &amp;hellip;). To the library presentation and documentation, for now refers, to the &lt;a href=&#34;http://www.pytables.org/moin&#34; target=&#34;_blank&#34; title=&#34;site&#34;&gt;site&lt;/a&gt;.&lt;br /&gt;
I used it a lot during my master thesis to manage the dataset from the Millennium database.&lt;br /&gt;
Here I provide a brief review of how I used it to store data obtained in .csv (comma separated values) format.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;    

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python

import numpy as np
import tables as tb
import time

t = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As usual, we have the initial import of the modules we need and start the timing of the code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fofhdf5 = tb.openFile(&#39;mill2_fof_snap67.h5&#39;, &#39;w&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This create the HDF5-file object we use to work on the file, in write (&lt;code&gt;&#39;w&#39;&lt;/code&gt;) mode. Read-only (&lt;code&gt;&#39;r&#39;&lt;/code&gt;) mode is also possible.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fof_data = np.genfromtxt(&#39;fof0.csv&#39;, dtype=([(&#39;fofId&#39;, &#39;i8&#39;), (&#39;np&#39;, &#39;i4&#39;), (&#39;mass&#39;, &#39;f4&#39;), (&#39;x&#39;, &#39;f4&#39;), (&#39;y&#39;, &#39;f4&#39;), (&#39;z&#39;, &#39;f4&#39;), (&#39;ix&#39;, &#39;i4&#39;), (&#39;iy&#39;, &#39;i4&#39;), (&#39;iz&#39;, &#39;i4&#39;), (&#39;m_crit_200&#39;, &#39;f4&#39;), (&#39;r_crit_200&#39;, &#39;f4&#39;), (&#39;m_mean_200&#39;, &#39;f4&#39;), (&#39;r_meam_200&#39;, &#39;f4&#39;), (&#39;m_tophat&#39;, &#39;f4&#39;), (&#39;r_tophat&#39;, &#39;f4&#39;), (&#39;numSubs&#39;, &#39;i4&#39;)]), comments=&#39;#&#39;, delimiter=&#39;,&#39;, skiprows=26)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we read the .csv/ASCII table and from this we create a table of numpy arrays, each of them with its own name and type. It&amp;rsquo;s also possible to specify the character for the comments in the file (&lt;code&gt;#&lt;/code&gt;), the character separating the values (commas, spaces, &amp;hellip;) and the number of line to be skipped (file header).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;table = fofhdf5.createTable(fofhdf5.root, description=fof_data, name=&#39;fof_data_snap67&#39;, title=&amp;quot;fof_data_snap67&amp;quot;, expectedrows=11697806)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create the HDF5-table with the proper hierarchy, some metadata (description and title). Specify the number of rows one expects to put into the table helps the library to optimize the operations and the space.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i in range(1, 20):
    fof_data = np.genfromtxt(&#39;fof&#39;+str(i)+&#39;.csv&#39;, dtype=([(&#39;fofId&#39;, &#39;i8&#39;), (&#39;np&#39;, &#39;i4&#39;), (&#39;mass&#39;, &#39;f4&#39;), (&#39;x&#39;, &#39;f4&#39;), (&#39;y&#39;, &#39;f4&#39;), (&#39;z&#39;, &#39;f4&#39;), (&#39;ix&#39;, &#39;i4&#39;), (&#39;iy&#39;, &#39;i4&#39;), (&#39;iz&#39;, &#39;i4&#39;), (&#39;m_crit_200&#39;, &#39;f4&#39;), (&#39;r_crit_200&#39;, &#39;f4&#39;), (&#39;m_mean_200&#39;, &#39;f4&#39;), (&#39;r_meam_200&#39;, &#39;f4&#39;), (&#39;m_tophat&#39;, &#39;f4&#39;), (&#39;r_tophat&#39;, &#39;f4&#39;), (&#39;numSubs&#39;, &#39;i4&#39;)]), comments=&#39;#&#39;, delimiter=&#39;,&#39;, skiprows=26)
    
    table.append(fof_data)
    table.flush()
    print &amp;quot;Loop &amp;quot;, i, &amp;quot; done.&amp;quot;

fofhdf5.close()
print &amp;quot;Done in &amp;quot;, time.time()-t, &amp;quot;seconds !!!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;for&lt;/code&gt; loop opens other ASCII tables and append them to the existing HDF5-table. The &lt;code&gt;table.flush()&lt;/code&gt; command let the library physically write the data on the disk instead of maintaining them in memory and write them periodically. After that we close the file object.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From binaries to HDF5 using Python</title>
      <link>http://brunettoziosi.eu/posts/from-binaries-to-hdf5-using-python/</link>
      <pubDate>Fri, 02 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/from-binaries-to-hdf5-using-python/</guid>
      <description>&lt;p&gt;I have used this script to convert the Millennium II data from the unformatted fortran binary formato to the DF5 one.&lt;br /&gt;
The core of the script is a module (&lt;code&gt;modified_read_snapshots&lt;/code&gt;) built on the basis of a script kindly provided by &lt;a href=&#34;http://mbk.ps.uci.edu/index.html&#34; target=&#34;_blank&#34; title=&#34;Mike Boylan-Kolchin&#34;&gt;Mike Boylan-Kolchin&lt;/a&gt; from the group that perform the Millennium II simulation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python    

import time
import kd3hdf5
import tables as tb
import modified_read_snapshots as rs

t = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The usual imports and time initialization!:P&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def bin2hdf5(bin_file, h5_file, tree = False):
    snap = rs.read_snapshot(bin_file)
    h5f = kd3hdf5.KDTree(h5_file, &#39;w&#39;)
    h5f.data_store(snap[&#39;pos&#39;])
    if tree == True:
        h5f.tree_build
    h5f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function accept as arguments the name of the binary file, the name of the HDF5 file to be created and give the user the possibility to create a KDTree with the data. By default it won&amp;rsquo;t create this tree. If no KDTree must be created the function only uses the part of the &lt;code&gt;kd3hdf5&lt;/code&gt; module that store the data into the HDF5 file. We will have a brief view of this at the end of the post.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def main():
    print &amp;quot;start&amp;quot;
    for i in [0, 10, 100, 200, 511]:
        t2 = time.time()
        print &amp;quot;Loop &amp;quot;, i
        t3 = time.time()
        bin2hdf5(&#39;../binary/snap_newMillen_subidorder_067.&#39;+str(i), &#39;../hdf5/data_&#39;+str(i))
        print &amp;quot;Loop &amp;quot;, i, &amp;quot; finished in &amp;quot;, time.time()-t2

    print &amp;quot;That&#39;s all folks, in &amp;quot;, time.time()-t, &amp;quot;!!!&amp;quot;

if __name__ == &amp;quot;__main__&amp;quot;:
    main()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing more than calling the previous function on the data files looping on their names!:)&lt;br /&gt;
Respect to the other posts here we make use of the &lt;code&gt;main&lt;/code&gt; function but is nothing extraordinary!:P&lt;/p&gt;

&lt;p&gt;The code from the &lt;code&gt;kd3hdf5&lt;/code&gt; module is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class KDTree(object):
    #Docs [...]

    def __init__(self, filename, mode):
        if mode == &#39;read&#39; or mode == &#39;r&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;r&amp;quot;)
        elif mode == &#39;append&#39; or mode == &#39;a&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;a&amp;quot;)
        elif mode == &#39;build&#39; or mode == &#39;w&#39; or mode == &#39;write&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;w&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This provide the creation of the object, linked to an HDF5 file and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def data_store(self, data):
        t = time.time()
        self.h5file.createArray(self.h5file.root, &#39;data&#39;, np.asarray(data), title=&#39;data&#39;)
        self.h5file.root.data._v_attrs.n_elements = data.shape[0]
        self.h5file.root.data._v_attrs.m_dimensions = data.shape[1]
        self.h5file.root.data._v_attrs.maxes = np.amax(data,axis=0)   # maxes and mins for each coord
        self.h5file.root.data._v_attrs.mins = np.amin(data,axis=0)
        print self.h5file.root.data._v_attrs.n_elements, &amp;quot; Stored in &amp;quot;, time.time()-t, &amp;quot;seconds.&amp;quot;
        t = time.time()
        self.h5file.root.data.flush()
        print time.time()-t, &amp;quot; seconds to commit changes.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fill the file with the data and some metadata (table dimension and maxes and mins of the data).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>