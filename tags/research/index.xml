<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Post It!</title>
    <link>http://brunettoziosi.eu/tags/research/</link>
    <description>Recent content in Research on Post It!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jun 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://brunettoziosi.eu/tags/research/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Gravitational waves cheat sheet</title>
      <link>http://brunettoziosi.eu/posts/gw-cheat-sheet/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/gw-cheat-sheet/</guid>
      <description>

&lt;p&gt;I would like to share few notes, a cheat sheet, about gravitational waves I
put together while writing a chapter  of my PhD thesis
and preparing for the PhD school internal exam.
I did it to tidy up the mess of references and equations you may find around
that never agree and has a terrible notation!!&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Here the equations, below the images of the papers.&lt;/p&gt;

&lt;h3 id=&#34;general-introduction:4&#34;&gt;General introduction&lt;/h3&gt;

&lt;p&gt;Consider a small perturbation of the flat cartedian metric&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$g_{\alpha\beta}(\vec{x}) = \eta_{\alpha\beta} + h_{\alpha\beta}(\vec{x})\label{eq:perturbedMetric}\tag{1}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where &lt;code&gt;$\eta_{_{\alpha\beta}}$&lt;/code&gt; is the Minkowsky metric.&lt;br /&gt;
Consider the Einstein&amp;rsquo;s equation&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$R_{\alpha\beta}-\frac{1}{2}g_{\alpha\beta}R = \frac{8\pi G}{c^4}T_{\alpha\beta}\label{eq:EinsteinEquation}\tag{2}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where &lt;code&gt;$R_{\alpha\beta}$&lt;/code&gt; is the Ricci tensor, &lt;code&gt;$R$&lt;/code&gt; is the scalar curvature and &lt;code&gt;$T_{\alpha\beta}$&lt;/code&gt;
is the stress-energy tensor.&lt;/p&gt;

&lt;p&gt;For the metric &lt;code&gt;$\eqref{eq:perturbedMetric}$&lt;/code&gt; and in vacuum (&lt;code&gt;$T_{\alpha\beta}=0$&lt;/code&gt;) equation
&lt;code&gt;$\eqref{eq:EinsteinEquation}$&lt;/code&gt; simply becomes&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$ \partial_\beta h_\alpha^\beta(\vec{x})-\frac{1}{2}\partial_\alpha h_\beta^\beta(\vec{x}) = 0\label{eq:gwpartialderivative}\tag{3}$$&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Equation &lt;code&gt;$\eqref{eq:gwpartialderivative}$&lt;/code&gt; can be rewritten using the D&amp;rsquo;Alambert operator as&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\square h_{\alpha\beta}(\vec{x}) = 0\label{eq:waveEquation}\tag{4}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where we recognize the wave equation&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\square \vec{u} = 0$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;with &lt;code&gt;$\square = \frac{1}{c^2}\frac{\partial^2}{\partial t^2}-\nabla^2 = \frac{1}{c^2}\frac{\partial^2}{\partial t^2}-\frac{\partial^2}{\partial x^2}-\frac{\partial^2}{\partial y^2}-\frac{\partial^2}{\partial z^2}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The simplest solution has form&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$ h_{\alpha\beta}(\vec{x}) = \begin{pmatrix}h_+ &amp;amp; h_\times\\h_\times &amp;amp; -h_+\end{pmatrix}e^{i(kz-\omega t)}\label{eq:simplestSolution}\tag{5}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Considering a mass density, source of the gravitational waves, &lt;code&gt;$\eqref{eq:waveEquation}$&lt;/code&gt; becomes&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\square h_{\alpha\beta}(\vec{x}) = -\frac{16\pi G}{c^4}T_{\alpha\beta}\label{eq:notVacuumWaveEquation}\tag{6}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;With some simplifying assumptions, equation &lt;code&gt;$\eqref{eq:notVacuumWaveEquation}$&lt;/code&gt;
can be integrated and gives (if the source is a distribution of masses at rest,
at a distance &lt;code&gt;$r$&lt;/code&gt; from the observer)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$h^{ij}(t, \vec{x}) \sim \frac{2 G}{rc^4}\frac{{\rm d} ^2}{{\rm d} t^2}\left[I^{ij}(t-r/c)\right]$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where  &lt;code&gt;$t-r/c$&lt;/code&gt; is the delayed time and
&lt;code&gt;$I^{ij}$&lt;/code&gt; second mass moment or moment of inertia, that is the quadrupole moment of the
mass, &lt;code&gt;$I^{ij} \equiv \int {\rm d}^3 x \rho(t, \vec{x})x^ix^j$&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;gravitational-waves-from-binaries:4&#34;&gt;Gravitational waves from binaries&lt;/h3&gt;

&lt;p&gt;Assuming edge on observations (&lt;code&gt;$\theta = i = \frac{\pi}{2}\Rightarrow \cos(\theta) = 0$&lt;/code&gt;) the wave polarization modes are given by:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\begin{aligned}h_{+}(t, \theta, \phi, r) &amp;amp;= \frac{1}{r}\frac{4G\mu\omega_{\rm orb}^2a^2}{c^4}\frac{1+\cos^2\theta}{2}\cos\left(2\omega_{\rm orb}t_{\rm ret}+\phi\right)\\h_{\times}(t, \theta, \phi, r) &amp;amp;= \frac{1}{r}\frac{4G\mu\omega_{\rm orb}^2a^2}{c^4}\cos\theta\sin\left(2\omega_{\rm orb}t_{\rm ret}+\phi\right)\end{aligned}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and the final &lt;strong&gt;strain&lt;/strong&gt; (relative deformation caused by the gravitational wave) is&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$h = \frac{4G}{c^4}\frac{\mu\omega_{\rm orb}^2a^2}{r}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where &lt;code&gt;$a$&lt;/code&gt; is the semi-major axis of the binary and &lt;code&gt;$r$&lt;/code&gt; the distance source-observer.
$\omega&lt;em&gt;{\rm gw} = 2\omega&lt;/em&gt;{\rm orb}$.&lt;/p&gt;

&lt;p&gt;Substituting the semi-major axis we obtain&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$h = \frac{4 G^2}{c^4}\frac{m_1m_2}{a r}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;while Substituting the angular frequency from Kepler equations we obtain&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$h = \frac{4 G^{5/3}}{c^4} \frac{m_1m_2}{(m_1+m_2)^{1/3}}\omega_{\rm orb}^{2/3} = \frac{4 G^{5/3}}{c^4} m_{\rm chirp}^{5/3}\omega_{\rm orb}^{2/3}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where
&lt;code&gt;$$m_{\rm chirp} \equiv \left(\frac{m_1m_2}{m_1+m_2}\right)^{3/5}(m_1+m_2)^{2/5} = \frac{(m_1m_2)^{3/5}}{(m_1+m_2)^{1/5}}$$&lt;/code&gt;
is the chirp mass, a (not so) useful combination of the masses on which both the frequency and the strain of GWs
emitted during the inspiral of a DCOB (double compact object binary) depend.&lt;/p&gt;

&lt;p&gt;A handy approximation is given by&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$h\propto \left[\frac{m_{\rm chirp}}{{\rm M}_\odot}\right]^{5/3} \left[\frac{P_{\rm b}}{{\rm hours}}\right]^{-2/3} \left[\frac{r}{{\rm kpc}}\right]^{-1}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;At the &lt;strong&gt;ISCO&lt;/strong&gt; (innermos stable circular orbit) the strain become&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$h_{\rm ISCO} = \frac{G}{c^2}\frac{1}{r}\frac{m_1m_2}{m_1+m_2} \sim 2.47 \times 10^{-19}\frac{10^6 \,{\rm pc}}{r}\frac{m_1m_2}{m_1+m_2}5\,{\rm M}_\odot$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;radiated power&lt;/strong&gt; is&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\begin{aligned}P &amp;amp;= \frac{{\rm d}E_{\rm orb}}{{\rm d} t} = -\frac{{\rm d}}{{\rm d} t}\left[\frac{Gm_1m_2}{2a}\right] = \frac{Gm_1m_2}{2}\frac{1}{a^2}\frac{{\rm d}a}{{\rm d}t}=\\&amp;amp;=\frac{32}{5}\frac{G^4}{c^5}\frac{1}{a^5}(m_1m_2)^2(m_1+m_2)\quad\text{from quadrupole formalism}\\&amp;amp;=\frac{32}{5}\frac{c^5}{G}\left[\frac{Gm_{\rm chirp}\omega_{\rm GW}}{2c^3}\right]^{10/3}\end{aligned}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;from which we can derive&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\frac{{\rm d}\omega_{\rm GW}}{{\rm d}t} = \omega_{\rm GW}^{11/3}m_{\rm chirp}^{5/3}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;thet gives&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\omega_{\rm gw} = \left[\frac{64}{5\times2^{2/3}}\right]^{-3/8}\left[\frac{Gm_{\rm chirp}}{c^3}\right]^{-5/8}t_{\rm GW}^{-3/8}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and (for circular orbits)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$t_{\rm GW}\sim\frac{5}{256}\frac{c^5}{G^3}\frac{a^4}{(m_1m_2)(m_1+m_2)}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;http://journals.aps.org/pr/abstract/10.1103/PhysRev.136.B1224&#34;&gt;Peters(1964)&lt;/a&gt;
we obtain more precise and general relations (~ 3.5PN):&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\begin{aligned}\langle\frac{{\rm d} E}{{\rm d} t}\rangle &amp;amp;= -\frac{32}{5}\frac{G^4m_1^2m_2^2(m_1+m_2)}{c^5a^5(1-e^2)^{7/2}}\left(1+\frac{73}{24}e^2+\frac{37}{96}e^4\right)\label{eq:energyAverageEmissionRate}\\\langle\frac{{\rm d} L}{{\rm d} t}\rangle &amp;amp;= -\frac{32}{5}\frac{G^{7/2}m_1^2m_2^2(m_1+m_2)^{1/2}}{c^5a^{7/2}(1-e^2)^2}(1+\frac{7}{8}e^2)\label{eq:angularMomentumAverageEmissionRate}\end{aligned}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\begin{aligned}\langle\frac{{\rm d} a}{{\rm d} t}\rangle &amp;amp;= -\frac{64}{5}\frac{G^3m_1m_2(m_1+m_2)}{c^5a^3(1-e^2)^{7/2}}\left(1+\frac{73}{24}e^2+\frac{37}{96}e^4\right)\label{eq:smaAverageVariation}\\\langle\frac{{\rm d} e}{{\rm d} t}\rangle &amp;amp;= -\frac{304}{15}e\frac{G^3m_1m_2(m_1+m_2)^3}{c^5a^4(1-e^2)^{5/2}}(1+\frac{121}{304}e^2)\label{eq:eccAverageVariation}\end{aligned}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\label{eq:diffAOnE}\langle\frac{{\rm d} a}{{\rm d} e}\rangle = \frac{12}{19}\frac{a}{e}\frac{\left[1+\frac{73}{24}e^2 + \frac{36}{96}e^4\right]}{(1-e^2)\left[1+\frac{121}{304}e^2\right]}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\langle\frac{{\rm d} a}{{\rm d} t}\rangle = -\frac{64}{5}\frac{G^3m_1^2m_2^2(m_1+m_2)}{c^5a^3}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and integrating from $a_0$ to $a$ and from $t=0$ to $t$ we obtain:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\label{eq:AOfTZeroEcc} a(t) = (a_0^4-4Ct)^{1/4}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;with &lt;code&gt;$C = \frac{64}{5}\frac{G^3m_1^2m_2^2(m_1+m_2)}{c^5}$&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Thus the system merges in a time&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\label{eq:tGWe0}t_{m\rm gr}(e\rightarrow 0) \sim \frac{a_0^4}{4C}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$t_{m\rm gr}(e\rightarrow 1) \sim 1.8\frac{5}{256} \frac{c^5}{G^3}\frac{a^4(1-e^2)^{7/2}}{(m_1m_2)(m_1+m_2)}\label{eq:tGWe1}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Often a slightly different version is used in the literature:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\label{eq:tGWliterature}t_{\rm GW} = \frac{5}{256} \frac{c^5}{G^3}\frac{a^4(1-e^2)^{7/2}}{(m_1m_2)(m_1+m_2)}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In the same way, for the semi-major axis shrinking, we find&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\label{eq:AOfTAllEcc}a(t) = \left(a_0^4-4C\frac{t}{(1-e^2)^{7/2}}\right)^{1/4}$$&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;utils:4&#34;&gt;Utils&lt;/h3&gt;

&lt;h4 id=&#34;chirp-mass:4&#34;&gt;Chirp mass&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;$$m_{\rm chirp} \equiv \left(\frac{m_1m_2}{m_1+m_2}\right)^{3/5}(m_1+m_2)^{2/5} = \frac{(m_1m_2)^{3/5}}{(m_1+m_2)^{1/5}}$$&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;kepler:4&#34;&gt;Kepler&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;$$P = \frac{2\pi}{\omega} = \left[\frac{4\pi^2 a^3}{G(m_1+m_2)}\right]^{1/2}$$&lt;/code&gt;
&lt;code&gt;$$a = \frac{G(m_1+m_2)^{1/3}}{\omega_{\rm orb}^{2/3}}$$&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;isco:4&#34;&gt;ISCO&lt;/h4&gt;

&lt;p&gt;At the innermost Stable Circular Orbit (AKA LSO, Last Stable Orbit):&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\omega_{\rm ISCO} = \frac{2c^3}{6^{3/2}G}\frac{1}{m_1+m_2}$$&lt;/code&gt;
&lt;code&gt;$$a_{\rm ISCO} = 3\times\frac{2G(m_1+m_2)}{c^2}$$&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;images:4&#34;&gt;Images&lt;/h3&gt;

&lt;table style=&#34;width:100%&#34;&gt;

&lt;div class=&#34;gallery&#34; itemscope itemtype=&#34;http://schema.org/ImageGallery&#34;&gt;

 


&lt;figure itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
  &lt;a href=&#34;http://brunettoziosi.eu/../../img/gw-cheat-sheet/gravitational-waves-from-compact-binaries-2_1.jpg&#34; itemprop=&#34;contentUrl&#34; data-size=&#34;2216x3064&#34;&gt;
      &lt;img src=&#34;http://brunettoziosi.eu/../../img/gw-cheat-sheet_thumb/gravitational-waves-from-compact-binaries-2_1.jpg&#34; itemprop=&#34;thumbnail&#34; alt=&#34;&#34; /&gt;

  &lt;/a&gt;


  &lt;figcaption itemprop=&#34;caption description&#34;&gt;
    
    &lt;span itemprop=&#34;copyrightHolder&#34;&gt;BrunettoZiosi&lt;/span&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

 


&lt;figure itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
  &lt;a href=&#34;http://brunettoziosi.eu/../../img/gw-cheat-sheet/gravitational-waves-from-compact-binaries-2_2.jpg&#34; itemprop=&#34;contentUrl&#34; data-size=&#34;2300x3200&#34;&gt;
      &lt;img src=&#34;http://brunettoziosi.eu/../../img/gw-cheat-sheet_thumb/gravitational-waves-from-compact-binaries-2_2.jpg&#34; itemprop=&#34;thumbnail&#34; alt=&#34;&#34; /&gt;

  &lt;/a&gt;


  &lt;figcaption itemprop=&#34;caption description&#34;&gt;
    
    &lt;span itemprop=&#34;copyrightHolder&#34;&gt;BrunettoZiosi&lt;/span&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;


&lt;div class=&#34;title&#34;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;http://brunettoziosi.eu/css/photoswipe.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;http://brunettoziosi.eu/css/default-skin/default-skin.css&#34;&gt;
&lt;script src=&#34;http://brunettoziosi.eu/js/photoswipe.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://brunettoziosi.eu/js/photoswipe-ui-default.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://brunettoziosi.eu/js/initphotoswipe.js&#34;&gt;&lt;/script&gt;



&lt;div class=&#34;pswp&#34; tabindex=&#34;-1&#34; role=&#34;dialog&#34; aria-hidden=&#34;true&#34;&gt;

&lt;div class=&#34;pswp__bg&#34;&gt;&lt;/div&gt;

&lt;div class=&#34;pswp__scroll-wrap&#34;&gt;
    
    &lt;div class=&#34;pswp__container&#34;&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div class=&#34;pswp__ui pswp__ui--hidden&#34;&gt;
    &lt;div class=&#34;pswp__top-bar&#34;&gt;
      
      &lt;div class=&#34;pswp__counter&#34;&gt;&lt;/div&gt;
      &lt;button class=&#34;pswp__button pswp__button--close&#34; title=&#34;Close (Esc)&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--share&#34; title=&#34;Share&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--fs&#34; title=&#34;Toggle fullscreen&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--zoom&#34; title=&#34;Zoom in/out&#34;&gt;&lt;/button&gt;
      
      
      &lt;div class=&#34;pswp__preloader&#34;&gt;
        &lt;div class=&#34;pswp__preloader__icn&#34;&gt;
          &lt;div class=&#34;pswp__preloader__cut&#34;&gt;
            &lt;div class=&#34;pswp__preloader__donut&#34;&gt;&lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;pswp__share-modal pswp__share-modal--hidden pswp__single-tap&#34;&gt;
      &lt;div class=&#34;pswp__share-tooltip&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;button class=&#34;pswp__button pswp__button--arrow--left&#34; title=&#34;Previous (arrow left)&#34;&gt;
    &lt;/button&gt;
    &lt;button class=&#34;pswp__button pswp__button--arrow--right&#34; title=&#34;Next (arrow right)&#34;&gt;
    &lt;/button&gt;
    &lt;div class=&#34;pswp__caption&#34;&gt;
      &lt;div class=&#34;pswp__caption__center&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .gallery { float: right; }
    .gallery img { width: 100%; height: auto; }
    .gallery figure { display: block; float: left; margin: 0 5px 5px 0; width: 250px; }  
    .gallery figcaption { display: none; }
    span[itemprop=&#34;copyrightHolder&#34;] { color : #888; float: right; }
    span[itemprop=&#34;copyrightHolder&#34;]:before { content: &#34;Foto: &#34;; }
&lt;/style&gt;


&lt;script&gt;initPhotoSwipeFromDOM(&#39;.gallery&#39;);&lt;/script&gt;


&lt;/table&gt;
    

&lt;h3 id=&#34;references:4&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Maggiore, M. (2008). Oxford University Press.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://journals.aps.org/pr/abstract/10.1103/PhysRev.136.B1224&#34;&gt;Peters(1964)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.roma1.infn.it/teongrav/VALERIA/TEACHING/ONDE_GRAV_STELLE_BUCHINERI/AA2013_14/dispense.pdf&#34;&gt;General relativity lectures@Roma1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.astro.umd.edu/~miller/teaching/&#34;&gt;Cole Miller lectures&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>PDF manipulation</title>
      <link>http://brunettoziosi.eu/posts/pdf-manipulation/</link>
      <pubDate>Fri, 05 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/pdf-manipulation/</guid>
      <description>

&lt;p&gt;It happens, from time to time, that I find myself looking for a way to manipulate PDF
on the fly. For example, I want to print them two-pages per sheet, or to extract
few pages, or to shrink the size of the file without degradate the quality.&lt;/p&gt;

&lt;p&gt;Here are few trick I collected and post here to be able to find them.&lt;/p&gt;

&lt;h2 id=&#34;print-two-pages-per-sheet:5&#34;&gt;Print two pages per sheet&lt;/h2&gt;

&lt;p&gt;The first tricks comes from &lt;a href=&#34;http://0x2a.at/blog/2011/02/pdf_manipulation_on_the_cli/&#34;&gt;here&lt;/a&gt;
and assume you have &lt;a href=&#34;http://www2.warwick.ac.uk/fac/sci/statistics/staff/academic-research/firth/software/pdfjam/&#34;&gt;&lt;code&gt;pdfjam&lt;/code&gt;&lt;/a&gt;
installed.
This is how you can produce a pdf with two pages per sheet:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pdfjam --nup 2x1 infile.pdf --landscape --outfile outfile.pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;booklet:5&#34;&gt;Booklet&lt;/h2&gt;

&lt;p&gt;You can also print your pdf file as booklet. This means that the pages
of your file are shuffled (and placed two per sheet) so that you can
join them with a clip or some glue or strings in the middle just like
a real book. The sommand is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pdfbook --short-edge infile.pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;pdfbook&lt;/code&gt; is part of &lt;code&gt;pdfjam&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;extract-or-join-pages:5&#34;&gt;Extract (or join) pages&lt;/h2&gt;

&lt;p&gt;If you need to extrac some pages from your pdf file you can just run&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pdftk infile.pdf cat &amp;lt;first_page&amp;gt;-&amp;lt;last_page&amp;gt; output outfile.pdf 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To join pdf files, instead, run&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pdftk infile1.pdf infile2.pdf infile3.pdf cat output outfile.pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Obviously you need &lt;a href=&#34;http://packages.ubuntu.com/search?keywords=pdftk&#34;&gt;&lt;code&gt;pdftk&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;shrink-pdf-file-size:5&#34;&gt;Shrink pdf file size&lt;/h2&gt;

&lt;p&gt;Sometiimes a pdf grows in size with no reason (apparently). It is possible to shrink it
by reduce it to pdf defaults. You will need &lt;a href=&#34;http://www.ghostscript.com/&#34;&gt;&lt;code&gt;gs&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The command you need to run is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/default -dNOPAUSE -dQUIET -dBATCH -sOutputFile=outfile.pdf infile.pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It can be quite difficult to remember, so you can create a bash alias for a function
doing it for you. In &lt;code&gt;.bashrc&lt;/code&gt; add&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;alias pdfdefault=&#39;function _pdfdefault() { gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/default -dNOPAUSE -dQUIET -dBATCH -sOutputFile=$2 $1;}; _pdfdefault&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and run &lt;code&gt;. ~/.bashrc&lt;/code&gt; before running &lt;code&gt;pdfdefault infile.pdf outfile.pdf&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;two-pages-per-sheet-with-latex:5&#34;&gt;Two pages per sheet with latex&lt;/h2&gt;

&lt;p&gt;It is possible, if you are writing something with pdf, to produce a pdf
with two pages per sheet without needing to run &lt;code&gt;pdfjam&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In this case just add, at the beginning of your latex document&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;\usepackage{pgfpages}
\pgfpagesuselayout{2 on 1}[a4paper], landscape]
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Not only Big Data</title>
      <link>http://brunettoziosi.eu/posts/not-only-big-data/</link>
      <pubDate>Thu, 08 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/not-only-big-data/</guid>
      <description>&lt;p&gt;Recently I&amp;rsquo;ve been at a &lt;a href=&#34;http://www.cineca.it/en&#34;&gt;Cineca&lt;/a&gt; workshop focused on tools to deal with big data analysis.
We had a taste of MapReduce/Hadoop/Spark and friends and we used Docker.
I wrote a small presentation to update my collegues and it become a in-progress presentation of the tools I think are
useful in our everyday work. This presentation aims of acting both as a showcase of what can help us and as a cheat sheet.
You can find it after the break.&lt;/p&gt;

&lt;iframe src=&#34;http://rawgit.com/brunetto/my-public-talks/master/2014-12-cinecaBigData/index.html&#34; width=&#34;800&#34; height=&#34;600&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Python plot examples</title>
      <link>http://brunettoziosi.eu/posts/python-plot-examples/</link>
      <pubDate>Mon, 29 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/python-plot-examples/</guid>
      <description>&lt;p&gt;Two examples on how to make plots with &lt;a href=&#34;http://home.gna.org/veusz&#34;&gt;Veusz&lt;/a&gt; and
&lt;a href=&#34;http://matplotlib.org&#34;&gt;Matplotlib&lt;/a&gt;.&lt;br /&gt;
I prefer Veusz because it&amp;rsquo;s easier to configure, modify and it produces
perfect &lt;code&gt;pdf&lt;/code&gt; plots, but sometimes Matplotlib it&amp;rsquo;s faster for producing just
a draft plot to inspect data!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# -*- coding: utf8 -*- 

from __future__ import division # no more &amp;quot;zero&amp;quot; integer division bugs!:P
import time
import numpy as np
import veusz.embed as ve

def sm_hist(data, delta=5, n_bin=None, range_=None):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta)
	range_ = (dataMin, dataMin + n_bin * delta)
	counts, bin_edges = np.histogram(data, n_bin, range_, density = False)
	return counts, bin_edges
	
def sm_hist2(data, delta=5):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta) + 1
	idxs = ((data  - dataMin) / delta).astype(int)
	counts = np.zeros(n_bin) 
	bin_edges = np.arange(dataMin, dataMax+2, delta)
	for idx in idxs:
		counts[idx] += 1
	counts = np.hstack((np.array([0]), counts, np.array([0])))
	bin_edges = np.hstack((bin_edges[0], bin_edges, bin_edges[-1]))
	return counts, bin_edges

def plotFunc(inpath=&amp;quot;./&amp;quot;, outpath=&amp;quot;./&amp;quot;):
	font = &amp;quot;Times New Roman&amp;quot;
	colors = [u&#39;blue&#39;, u&#39;green&#39;]
	xmin = [&amp;quot;auto&amp;quot;, &amp;quot;auto&amp;quot;]
	xmax = [&amp;quot;auto&amp;quot;, &amp;quot;auto&amp;quot;]
	ymin = [&amp;quot;auto&amp;quot;, 0]
	ymax = [&amp;quot;auto&amp;quot;, &amp;quot;auto&amp;quot;]
	
	xData = np.arange(100) 
	yData = np.random.randint(0, 100, size=100) + np.sin(np.arange(100))
	
	figure = ve.Embedded(&amp;quot;Window_1&amp;quot;)
	page = figure.Root.Add(&#39;page&#39;, width = &#39;30cm&#39;, height=&#39;15cm&#39;)
	grid = page.Add(&#39;grid&#39;, autoadd = False, rows = 1, columns = 2,
						scaleRows=[0.2],
						topMargin=&#39;1cm&#39;,
						bottomMargin=&#39;1cm&#39;
						)
	graphList = []
	
	graphList.append(grid.Add(&#39;graph&#39;, name=&amp;quot;scatter&amp;quot;, autoadd=False, 
							hide = False, 
							Border__width = &#39;2pt&#39;,
							leftMargin = &#39;0.6cm&#39;,
							rightMargin = &#39;0.4cm&#39;,
							topMargin = &#39;0.5cm&#39;,
							bottomMargin = &#39;1cm&#39;,
							))
	
	graphList.append(grid.Add(&#39;graph&#39;, name=&amp;quot;hist&amp;quot;, autoadd=False, 
							hide = False, 
							Border__width = &#39;2pt&#39;,
							leftMargin = &#39;2cm&#39;,
							rightMargin = &#39;0.4cm&#39;,
							topMargin = &#39;0.5cm&#39;,
							bottomMargin = &#39;1cm&#39;,
							))
	
	for i in range(len(graphList)):
		graphList[i].Add(&#39;axis&#39;, name=&#39;x&#39;, label = &amp;quot;x&amp;quot;,
								min = xmin[i],
								max = xmax[i],
								log = False,
								Label__size = &#39;25pt&#39;,
								Label__font = font,
								TickLabels__size = &#39;17pt&#39;,
								TickLabels__format = u&#39;Auto&#39;,
								MajorTicks__width = &#39;2pt&#39;,
								MajorTicks__length = &#39;10pt&#39;,
								MinorTicks__width = &#39;1pt&#39;,
								MinorTicks__length = &#39;6pt&#39;
							)
		graphList[i].Add(&#39;axis&#39;, name=&#39;y&#39;, label = &amp;quot;y&amp;quot;, 
								direction = &#39;vertical&#39;,
								min = ymin[i],
								max = ymax[i],
								log = False,
								autoRange = u&#39;+5%&#39;,
								Label__size = &#39;25pt&#39;,
								Label__font = font,
								TickLabels__size = &#39;20pt&#39;,
								TickLabels__format = u&#39;Auto&#39;,
								MajorTicks__width = &#39;2pt&#39;,
								MajorTicks__length = &#39;10pt&#39;,
								MinorTicks__width = &#39;1pt&#39;,
								MinorTicks__length = &#39;6pt&#39;
							)
	
	graphList[0].Add(&#39;xy&#39;, key=&amp;quot;scatterPlotKey&amp;quot;, name=&#39;scatterPlotName&#39;,
						marker = u&#39;circle&#39;,
						MarkerFill__color = colors[0],
						markerSize = u&#39;3pt&#39;, 
						)

	xDataName = &amp;quot;xScatterData&amp;quot;
	yDataName = &amp;quot;yScatterData&amp;quot;
	figure.SetData(xDataName, xData)
	figure.SetData(yDataName, yData)
	graphList[0].scatterPlotName.xData.val = xDataName
	graphList[0].scatterPlotName.yData.val = yDataName
	
	
	counts, bin_edges = sm_hist2(yData, delta=5)
	
	graphList[1].Add(&#39;xy&#39;, key=&amp;quot;histPlotKey&amp;quot;, name=&#39;histPlotName&#39;,
						xData = bin_edges,
						yData = counts,
						marker = &#39;none&#39;,
						PlotLine__steps = u&#39;left&#39;,
						PlotLine__color = colors[1],
						PlotLine__style = u&amp;quot;solid&amp;quot;,
						PlotLine__width = u&#39;3&#39;,
						FillBelow__color = colors[1],
						FillBelow__style = &amp;quot;forward 2&amp;quot;,
						FillBelow__hide = False,
						FillBelow__transparency = 70,
						#FillBelow__backtransparency = 50,
						FillBelow__linewidth = &#39;1pt&#39;,
						FillBelow__linestyle = &#39;solid&#39;,
						FillBelow__backcolor = &amp;quot;white&amp;quot;,
						FillBelow__backhide = True,
						Label__posnHorz = &#39;right&#39;,
						Label__size = &#39;14pt&#39;, 
						Label__color = &#39;black&#39;
						)

	histKey = graphList[1].Add(&#39;key&#39;, autoadd=False, 
						horzPosn = &#39;left&#39;,
						vertPosn = &#39;top&#39;,
						Text__font = font,
						Text__size = &#39;15&#39;,
						Border__width = &#39;1.5pt&#39;
						)
	
	end = raw_input(&amp;quot;Press any key to finish...&amp;quot;)
	
	figure.Save(&amp;quot;example.vsz&amp;quot;)
	figure.Export(&amp;quot;example.png&amp;quot;, backcolor=&#39;#ffffff&#39;)
	figure.Export(&amp;quot;example.pdf&amp;quot;)

if __name__ == &amp;quot;__main__&amp;quot;:
	inpath = &amp;quot;./&amp;quot;
	outpath = &#39;./&#39;
	tt = time.time()
	plotFunc(inpath, outpath)
	print &amp;quot;Done in &amp;quot;, time.time()-tt, &amp;quot; seconds.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../../files/example.png&#34; alt=&#34;Veusz plot&#34; title=&#34;Veusz plot&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# -*- coding: utf8 -*- 

from __future__ import division # no more &amp;quot;zero&amp;quot; integer division bugs!:P
import time
import numpy as np
import matplotlib.pylab as plt
import matplotlib.font_manager as font_manager

# SM like style
params = {&#39;backend&#39;: &#39;png&#39;,
		&#39;font.family&#39;: &amp;quot;serif&amp;quot;,
		&#39;font.size&#39;: 25,
		&#39;axes.labelsize&#39;: 35,
		#&#39;text.fontsize&#39;: 30,
		&#39;legend.fontsize&#39;: 30,
		&#39;xtick.labelsize&#39;: 28,
		&#39;xtick.major.size&#39;: 20.0,
		&#39;xtick.major.width&#39;: 3.0,
		&#39;xtick.minor.size&#39;: 12.0,
		&#39;xtick.minor.width&#39;: 2,
		&#39;ytick.labelsize&#39;: 28,
		&#39;ytick.major.size&#39;: 20.0,
		&#39;ytick.major.width&#39;: 3.0,
		&#39;ytick.minor.size&#39;: 12.0,
		&#39;ytick.minor.width&#39;: 2,
		#&#39;text.usetex&#39;: True,
		&#39;axes.linewidth&#39;: 3.0,
		&#39;lines.linewidth&#39;: 2,
		&#39;lines.markersize&#39;: 15,
		&#39;axes.grid&#39;: False,
		&#39;grid&#39;: {&#39;color&#39;:&#39;gray&#39;, &#39;linestyle&#39;:&#39;-&#39;, &#39;linewidth&#39;:1},
		&#39;figure.figsize&#39;: (10,10),
		&#39;figure.subplot.left&#39;: 0.15,  # the left side of the subplots of the figure
		&#39;figure.subplot.right&#39;   : 0.95,    # the right side of the subplots of the figure
		&#39;figure.subplot.bottom&#39;  : 0.12,   # the bottom of the subplots of the figure
		&#39;figure.subplot.top&#39;     : 0.92,    # the top of the subplots of the figure
		&#39;figure.subplot.wspace&#39;  : 0.2,    # the amount of width reserved for blank space between subplots
		&#39;figure.subplot.hspace&#39;  : 0.2,    # the amount of height reserved for white space between subplots
		&#39;figure.figsize&#39;: (12, 12)
           }
plt.rcParams.update(params)
	
def sm_hist(data, delta=5, n_bin=None, range_=None):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta)
	range_ = (dataMin, dataMin + n_bin * delta)
	counts, bin_edges = np.histogram(data, n_bin, range_, density = False)
	# These two lines double the points let you make the histogram
	counts = np.ravel(zip(counts,counts)) 
	bin_edges = np.ravel(zip(bin_edges,bin_edges))
	counts = np.hstack((np.array([0]), counts, np.array([0])))
	return counts, bin_edges
	
	
def sm_hist2(data, delta=5):
	dataMin = np.floor(data.min())
	dataMax = np.ceil(data.max())
	n_bin = np.ceil(1.*(dataMax-dataMin) / delta) + 1
	idxs = ((data  - dataMin) / delta).astype(int)
	counts = np.zeros(n_bin) 
	bin_edges = np.arange(dataMin, dataMax+delta, delta)
	for idx in idxs:
		counts[idx] += 1
	print counts
	# These two lines double the points let you make the histogram
	counts = np.ravel(zip(counts,counts)) 
	bin_edges = np.ravel(zip(bin_edges,bin_edges))
	counts = np.hstack((np.array([0]), counts))
	bin_edges = np.hstack((bin_edges, bin_edges[-1]))
	return counts, bin_edges

def singlePlotScatter(xData, yData, nRows, nCols, x0, y0, rowspan, colspan):
	ax = plt.subplot2grid((nRows,nCols), (x0,y0), rowspan, colspan)
	ax.set_xlabel(&amp;quot;x label&amp;quot;)
	ax.set_ylabel(&amp;quot;y label&amp;quot;)
	ax.set_xscale(&amp;quot;linear&amp;quot;)
	ax.set_yscale(&amp;quot;linear&amp;quot;)
	ax.set_title(&amp;quot;Plot title&amp;quot;)
	ax.title.set_y(1.02) # adjust title position
	ax.xaxis.grid(True, which=&amp;quot;both&amp;quot;)
	ax.yaxis.grid(True, which=&amp;quot;major&amp;quot;)
	ax.plot(xData, yData, 
			color = &amp;quot;green&amp;quot;, 
			markeredgewidth = 0.8, 
			linestyle = &#39;-&#39;, 
			linewidth = 2,
			marker = &#39;o&#39;, 
			markersize = 1, 
			label = &amp;quot;label&amp;quot;)
	return ax

def singlePlotHist(yData, nRows, nCols, x0, y0, rowspan, colspan):
	ax = plt.subplot2grid((nRows,nCols), (x0,y0), rowspan, colspan)
	ax.set_xlabel(&amp;quot;x label&amp;quot;)
	ax.set_ylabel(&amp;quot;y label&amp;quot;)
	ax.set_xscale(&amp;quot;linear&amp;quot;)
	ax.set_yscale(&amp;quot;linear&amp;quot;)
	ax.set_title(&amp;quot;Plot title&amp;quot;)
	ax.title.set_y(1.02) # adjust title position
	ax.xaxis.grid(True, which=&amp;quot;both&amp;quot;)
	ax.yaxis.grid(True, which=&amp;quot;major&amp;quot;)
	counts, bin_edges = sm_hist2(yData, delta = 10)
	ax.set_ylim((0, 1.2*counts.max()))
	
	ax.plot(bin_edges, counts, 
				color = &amp;quot;blue&amp;quot;,
				alpha = 0.8,
				linewidth = 2,
				antialiased = True,
				zorder = 3 
				)
	ax.fill(bin_edges, counts, 
				alpha = 0.5,
				hatch = &amp;quot;/&amp;quot;,
				edgecolor = &amp;quot;blue&amp;quot;,
				facecolor = &amp;quot;white&amp;quot;,
				antialiased = True, 
				label = &amp;quot;whatever you want&amp;quot;
				)
	ax.legend(loc=&#39;upper left&#39;, numpoints = 1, prop=font_manager.FontProperties(size=18)).draw_frame(False)

	return ax

if __name__ == &amp;quot;__main__&amp;quot;:
	tt = time.time()
	xData = np.arange(100) 
	yData = np.random.randint(0, 100, size=100) + np.sin(np.arange(100))
	
	fig = plt.figure()
	fig.suptitle(&amp;quot;Figure title&amp;quot;)
	axs = []
	nPlots = 2
	
	axs.append(singlePlotScatter(xData, yData, nRows=1, nCols=2, x0=0, y0=0, rowspan=1, colspan=1))
	axs.append(singlePlotHist(yData, nRows=1, nCols=2, x0=0, y0=1, rowspan=1, colspan=1))
	
	fig.set_size_inches(20, 10)
	plt.savefig(&amp;quot;./grid.png&amp;quot;, dpi=100)
	plt.close(fig)
	
	print &amp;quot;Done in &amp;quot;, time.time()-tt, &amp;quot; seconds.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../../files/grid.png&#34; alt=&#34;Matplotlib plot&#34; title=&#34;Mathplotlib plot&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Eating</title>
      <link>http://brunettoziosi.eu/pages/research/fit/</link>
      <pubDate>Thu, 23 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/pages/research/fit/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://scikit-learn.org/stable/modules/linear_model.html&#34;&gt;SciKit Generalized Linear Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;linear-least-squares-fits-with-errors-in-both-coordinates:20&#34;&gt;Linear least-squares fits with errors in both coordinates.&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jordanperr/PH291-Dual-Axis-Error-Calculation&#34;&gt;PH291-Dual-Axis-Error-Calculation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://idlastro.gsfc.nasa.gov/ftp/pro/math/fitexy.pro&#34;&gt;IDL function&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://libraries.maine.edu/Spatial/gisweb/spatdb/acsm/ac94053.html&#34;&gt;Weighted least-squares curve fitting with errors in all variables&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;gaussian-processes-variograms-kriging:20&#34;&gt;Gaussian processes / variograms / Kriging&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.ambhas.com/tools/html/krige_8py_source.html&#34;&gt;http://www.ambhas.com/tools/html/krige_8py_source.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://hpgl.aoizora.org/index.php?option=com_content&amp;amp;view=article&amp;amp;id=47&amp;amp;Itemid=56&#34;&gt;http://hpgl.aoizora.org/index.php?option=com_content&amp;amp;view=article&amp;amp;id=47&amp;amp;Itemid=56&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://blog.technokrat.nl/?p=409&#34;&gt;http://blog.technokrat.nl/?p=409&lt;/a&gt; (qui usano la versione R in python)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/scikit-learn/scikit-learn/pull/14&#34;&gt;https://github.com/scikit-learn/scikit-learn/pull/14&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://nbviewer.ipython.org/github/fonnesbeck/Bios366/blob/master/notebooks/Section5_1-Gaussian-Processes.ipynb&#34;&gt;http://nbviewer.ipython.org/github/fonnesbeck/Bios366/blob/master/notebooks/Section5_1-Gaussian-Processes.ipynb&lt;/a&gt; (gaussian processes è il nome ufficiale e generico degli algoritmi tipo quelli di krige)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://girs.googlecode.com/svn/trunk/maths/kriging/kriging.py&#34;&gt;http://girs.googlecode.com/svn/trunk/maths/kriging/kriging.py&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://scikit-learn.org/0.11/auto_examples/gaussian_process/plot_gp_regression.html&#34;&gt;http://scikit-learn.org/0.11/auto_examples/gaussian_process/plot_gp_regression.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.gaussianprocess.org/&#34;&gt;http://www.gaussianprocess.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://pygpr.sourceforge.net/&#34;&gt;http://pygpr.sourceforge.net/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://sysbio.mrc-bsu.cam.ac.uk/group/images/6/6f/Infpy_gp.pdf&#34;&gt;http://sysbio.mrc-bsu.cam.ac.uk/group/images/6/6f/Infpy_gp.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://code.google.com/p/python-in-hydrology/source/browse/trunk/codes/foo/krig_example.py?r=9&#34;&gt;https://code.google.com/p/python-in-hydrology/source/browse/trunk/codes/foo/krig_example.py?r=9&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.enthought.com/services/training/geophysics&#34;&gt;https://www.enthought.com/services/training/geophysics&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://ambhas.com/books/python-in-hydrology/book.html&#34;&gt;http://ambhas.com/books/python-in-hydrology/book.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.astroml.org/book_figures/chapter8/fig_gp_example.html&#34;&gt;http://www.astroml.org/book_figures/chapter8/fig_gp_example.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/astroML/astroML/blob/master/book_figures/chapter8/fig_gp_mu_z.py&#34;&gt;https://github.com/astroML/astroML/blob/master/book_figures/chapter8/fig_gp_mu_z.py&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://books.google.it/books?id=2fM8AQAAQBAJ&amp;amp;pg=PA539&amp;amp;lpg=PA539&amp;amp;dq=astroml+variogram&amp;amp;source=bl&amp;amp;ots=_9Pq65sDwK&amp;amp;sig=IU2yqsREt7hze9xjKx3rBrUb5aA&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=S40GU5OsGsnStAbM54CYAw&amp;amp;ved=0CCoQ6AEwAA#v=onepage&amp;amp;q=astroml%20variogram&amp;amp;f=false&#34;&gt;http://books.google.it/books?id=2fM8AQAAQBAJ&amp;amp;pg=PA539&amp;amp;lpg=PA539&amp;amp;dq=astroml+variogram&amp;amp;source=bl&amp;amp;ots=_9Pq65sDwK&amp;amp;sig=IU2yqsREt7hze9xjKx3rBrUb5aA&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=S40GU5OsGsnStAbM54CYAw&amp;amp;ved=0CCoQ6AEwAA#v=onepage&amp;amp;q=astroml%20variogram&amp;amp;f=false&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/&#34;&gt;http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/stober/4964727&#34;&gt;https://gist.github.com/stober/4964727&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>StarLab (GPU) old guide</title>
      <link>http://brunettoziosi.eu/pages/research/utils/starlab-gpu-old-guide/</link>
      <pubDate>Fri, 23 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/pages/research/utils/starlab-gpu-old-guide/</guid>
      <description>

&lt;p&gt;&lt;/br&gt;&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;../../../../posts/starlab-gpu-installation&#34;&gt;Click here for the &lt;strong&gt;new guide!!!&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;to-install-cuda-you-can-try-with-the-cuda-packages-in-the-ubuntu-repositories:55&#34;&gt;To install CUDA you can try with the CUDA packages in the Ubuntu repositories.&lt;/h2&gt;

&lt;p&gt;If they fail, you have to download CUDA from ****&lt;/p&gt;

&lt;p&gt;To locate the CUDA files you can try:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep nvcc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep include&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep include | grep toolkit&lt;/code&gt; (for the SDK files of the new release)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep lib | grep cudaart&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- TEASER_END --&gt;

&lt;h2 id=&#34;sapporo:55&#34;&gt;Sapporo&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;in setup_sapporo.sh change&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export LD_LIBRARY_PATH=/usr/local/cuda-5.0/:/usr/local/cuda-5.0/samples/common/inc:/usr/include/boost/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(installation of the binary drivers from the NVIDIA site) to&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export LD_LIBRARY_PATH=/usr/include/:/usr/lib/nvidia-cuda-toolkit/include/:/usr/include/boost/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(ubuntu CUDA distro packages)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;in Makefile put the right path in &lt;code&gt;NVCC := /usr/bin/nvcc&lt;/code&gt; and be sure to have the right
paths in&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDAPATH    := /usr/include/
#/usr/local/cuda-5.0
CUDASDKPATH := /usr/lib/nvidia-cuda-toolkit/include/
#/usr/local/cuda-5.0/samples/common/inc
CUDAINCLUDE := -I$(CUDAPATH)/include -I$(CUDASDKPATH)
# RE - added these path/includes (added to NVCCFLAGS and CXXFLAGS, too)
BOOSTPATH := /usr/include/boost 
BOOSTINCLUDE := -I$(BOOSTPATH)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the commented path refers to the binary installation from the NVIDIA site.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Launch &lt;code&gt;bash ./setup_sapporo.sh&lt;/code&gt; and if you get&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;host_evaluate_gravity.cu:3: fatal error: multithreading.h: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;puth &lt;code&gt;multithreading.h&lt;/code&gt; in the sapporo folder and then in &lt;code&gt;host_evaluate_gravity.cu&lt;/code&gt; change&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;multithreading.h&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;quot;multithreading.h&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so c++ can find the header in the current directory.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if all is going right, by running again &lt;code&gt;bash setup_sapporo.sh&lt;/code&gt; you should
obtain something like
````bash
/bin/rm -rf *.o &lt;em&gt;.cu_o libsapporo.a
/bin/rm -rf test_gravity_block test_gravity_N2ngb
g++ -O3 -DNGB -I/usr/include//include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost    -c -o GPUWorker.o GPUWorker.cc
g++ -O3 -DNGB -I/usr/include//include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost  -c sapporo.cpp -o sapporo.o
sapporo.cpp: In member function ‘int sapporo::open(int)’:
sapporo.cpp:40:25: warning: ignoring return value of ‘char&lt;/em&gt; fgets(char&lt;em&gt;, int, FILE&lt;/em&gt;)’, declared with attribute warn_unused_result [-Wunused-result]
sapporo.cpp:42:25: warning: ignoring return value of ‘char* fgets(char&lt;em&gt;, int, FILE&lt;/em&gt;)’, declared with attribute warn_unused_result [-Wunused-result]
sapporo.cpp:67:24: warning: ignoring return value of ‘char* fgets(char&lt;em&gt;, int, FILE&lt;/em&gt;)’, declared with attribute warn_unused_result [-Wunused-result]
g++ -O3 -DNGB -I/usr/include//include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost  -c send_fetch_data.cpp -o send_fetch_data.o
g++ -O3 -DNGB -I/usr/include//include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost  -c sapporoG6lib.cpp -o sapporoG6lib.o&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*/usr/bin/nvcc -O0 -g -D_DEBUG  -maxrregcount=64 -I/usr/include//include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost  -c host_evaluate_gravity.cu -o host_evaluate_gravity.cu_o
 Iar qv libsapporo.a GPUWorker.o sapporo.o send_fetch_data.o sapporoG6lib.o host_evaluate_gravity.cu_o
ar: creating libsapporo.a
a - GPUWorker.o
a - sapporo.o
a - send_fetch_data.o
a - sapporoG6lib.o
a - host_evaluate_gravity.cu_o
ranlib libsapporo.a&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
* to test the compilation run 
````bash 
test_gravity_N2ngb 900
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;test_gravity_block 900
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where 900 is the number of particles involved in the test. You can choose the number you prefer
but the test fail if the number is less than ~800.&lt;/p&gt;

&lt;h2 id=&#34;starlab:55&#34;&gt;StarLab&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;change configure CUDA lines:
&lt;code&gt;bash
CUDAINC=&amp;quot;-I/usr/include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost&amp;quot; 
CUDALIB=&amp;quot;-L/usr/libx86_64-linux-gnu/ -lcudart&amp;quot;
LIBS=&amp;quot;$CUDAINC $CUDALIB -lboost_system -lboost_thread -lpthread -DNGB&amp;quot;
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;and change local/grape.sh
````bash
CUDAINC=&amp;ldquo;-I/usr/include -I/usr/lib/nvidia-cuda-toolkit/include/ -I/usr/include/boost&amp;rdquo;
CUDALIB=&amp;ldquo;-L/usr/libx86_64-linux-gnu/ -lcudart&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;cudainc-i-usr-local-cuda-5-0-include-i-usr-local-cuda-5-0-samples-common-inc-i-usr-include-boost:55&#34;&gt;CUDAINC=&amp;ldquo;-I/usr/local/cuda-5.0/include -I/usr/local/cuda-5.0/samples/common/inc -I/usr/include/boost&amp;rdquo;&lt;/h1&gt;

&lt;h1 id=&#34;cudalib-l-usr-local-cuda-5-0-lib64-lcudart:55&#34;&gt;CUDALIB=&amp;ldquo;-L/usr/local/cuda-5.0/lib64/ -lcudart&amp;rdquo;&lt;/h1&gt;

&lt;p&gt;LIBS1=&amp;ldquo;$CUDAINC $CUDALIB -lboost_system -lboost_thread -lpthread -DNGB&amp;rdquo;&lt;/p&gt;

&lt;p&gt;#g++ -O3 $flags -g -o test_gravity_block test_gravity_block.cpp -L. -lsapporo $CUDAINC $CUDALIB -lboost_thread
g++ -O3 $flags -g -o test_gravity_block test_gravity_block.cpp -L. -lsapporo $CUDAINC $CUDALIB $LIBS1&lt;/p&gt;

&lt;h1 id=&#34;where-to-find-grape-libraries:55&#34;&gt;Where to find GRAPE libraries:&lt;/h1&gt;

&lt;h1 id=&#34;grape-ldflags-l-home-mapelli-micmap-programmi-sapporo161-release:55&#34;&gt;GRAPE&lt;em&gt;LDFLAGS&lt;/em&gt;=&amp;lsquo;-L/home/mapelli/MICMAP/programmi/sapporo161_release/&amp;rsquo;&lt;/h1&gt;

&lt;p&gt;GRAPE&lt;em&gt;LDFLAGS&lt;/em&gt;=&amp;lsquo;-L/home/ziosi/Code/Mapelli/starlab/sapporo/sapporo161_release&amp;rsquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
* run `make clean`

* run `./configure --without-fortran` (`--without-f77`)

* `make`

* `make install`

* now you can find the `kira` binary in `/usr/local/bin` or`/usr/bin`

* run 
````bash
./kira -t 500 -d 1 -D 1 -b 1 \
             -n 10 -e 0.000 -B   \
	 &amp;lt;  cineca95_bin_N5000_frac01_W5_Z001_IC.txt \
	 &amp;gt; new_cineca95_bin_N5000_frac01_W5_Z001.txt \
	 2&amp;gt; ew_cineca95_bin_N5000_frac01_W5_Z001.txt
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>http://brunettoziosi.eu/pages/research/research/</link>
      <pubDate>Wed, 21 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/pages/research/research/</guid>
      <description>

&lt;h2 id=&#34;phd-project-phd:70&#34;&gt;&lt;a href=&#34;../phd&#34;&gt;PhD Project&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;The impact of stellar evolution and dynamics on the formation of
compact-object binaries&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;During my PhD I was part of &lt;a href=&#34;http://web.pd.astro.it/mapelli/group.html&#34;&gt;Dr. Mapelli&amp;rsquo;s research group&lt;/a&gt; working
on N-body simulations of young and dense star clusters in order to
understand the impact of stellar evolution and dynamics on the formation and evolution
of compact-object (neutron stars and black holes) binary systems.&lt;br /&gt;
These objects are thought to be the best candidates to produce gravitational
waves observable in the near future with the second-generation ground-based
gravitational wave interferometers Advanced Ligo and Virgo.&lt;/p&gt;

&lt;p&gt;More info &lt;a href=&#34;../phd&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;scientific-interests:70&#34;&gt;Scientific interests&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;dynamics of black holes and neutron stars in star clusters&lt;/li&gt;
&lt;li&gt;direct-summation N-body simulations in star clusters&lt;/li&gt;
&lt;li&gt;gravitational waves in the frequency range of Advanced VIRGO and LIGO&lt;/li&gt;
&lt;li&gt;stellar and binary evolution&lt;/li&gt;
&lt;li&gt;big data analysis and visualization&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;master-thesis-master:70&#34;&gt;&lt;a href=&#34;../master&#34;&gt;Master Thesis&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;My master thesis involved developing a code to calculate the cross-correlation
among the centers of dark matter haloes in cosmological simulations.
We wanted to do that &amp;ldquo;brute-force&amp;rdquo; in coordinate space instead of adopting the Fourier transform method
commonly preferred in literature to be able to catch the small features expected at
small scales. The code is, however, based on a KD-tree to reduce the time needed and
run in parallel over multiple slices form the same simulation box.&lt;/p&gt;

&lt;h2 id=&#34;bachelor-thesis-master:70&#34;&gt;&lt;a href=&#34;../master&#34;&gt;Bachelor Thesis&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;My bachelor thesis was about the use of optical vortexes (light beams with distorted
wavefronts) in astrophysics.&lt;/p&gt;

&lt;h2 id=&#34;useful-links:70&#34;&gt;Useful links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://adsabs.harvard.edu/abstract_service.html&#34;&gt;Nasa ADS&lt;/a&gt;,
&lt;a href=&#34;http://labs.adsabs.harvard.edu/wiki/doku.php&#34;&gt;Lab version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/&#34;&gt;arXiv.org&lt;/a&gt;, &lt;a href=&#34;http://arxiv.org/list/astro-ph/new&#34;&gt;new astro* papers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.unipd.it/&#34;&gt;University of Padua&lt;/a&gt;,
&lt;a href=&#34;http://www.unipd.it/scuole/scienze&#34;&gt;Science School&lt;/a&gt;,
&lt;a href=&#34;http://www.dfa.unipd.it/&#34;&gt;Department of Physics and Astronomy&lt;/a&gt;,
&lt;a href=&#34;http://www.dfa.unipd.it/index.php?id=112&#34;&gt;Building&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>From .csv to HDF5 in Python</title>
      <link>http://brunettoziosi.eu/posts/from-csv-to-hdf5-in-python/</link>
      <pubDate>Fri, 02 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/from-csv-to-hdf5-in-python/</guid>
      <description>&lt;p&gt;PyTables is a Python library that provide a simple but really useful interface to manage the HDF5 files with some other interesting features (compression, optimizations, &amp;hellip;). To the library presentation and documentation, for now refers, to the &lt;a href=&#34;http://www.pytables.org/moin&#34; target=&#34;_blank&#34; title=&#34;site&#34;&gt;site&lt;/a&gt;.&lt;br /&gt;
I used it a lot during my master thesis to manage the dataset from the Millennium database.&lt;br /&gt;
Here I provide a brief review of how I used it to store data obtained in .csv (comma separated values) format.&lt;/p&gt;

&lt;!-- TEASER_END --&gt;    

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python

import numpy as np
import tables as tb
import time

t = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As usual, we have the initial import of the modules we need and start the timing of the code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fofhdf5 = tb.openFile(&#39;mill2_fof_snap67.h5&#39;, &#39;w&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This create the HDF5-file object we use to work on the file, in write (&lt;code&gt;&#39;w&#39;&lt;/code&gt;) mode. Read-only (&lt;code&gt;&#39;r&#39;&lt;/code&gt;) mode is also possible.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fof_data = np.genfromtxt(&#39;fof0.csv&#39;, dtype=([(&#39;fofId&#39;, &#39;i8&#39;), (&#39;np&#39;, &#39;i4&#39;), (&#39;mass&#39;, &#39;f4&#39;), (&#39;x&#39;, &#39;f4&#39;), (&#39;y&#39;, &#39;f4&#39;), (&#39;z&#39;, &#39;f4&#39;), (&#39;ix&#39;, &#39;i4&#39;), (&#39;iy&#39;, &#39;i4&#39;), (&#39;iz&#39;, &#39;i4&#39;), (&#39;m_crit_200&#39;, &#39;f4&#39;), (&#39;r_crit_200&#39;, &#39;f4&#39;), (&#39;m_mean_200&#39;, &#39;f4&#39;), (&#39;r_meam_200&#39;, &#39;f4&#39;), (&#39;m_tophat&#39;, &#39;f4&#39;), (&#39;r_tophat&#39;, &#39;f4&#39;), (&#39;numSubs&#39;, &#39;i4&#39;)]), comments=&#39;#&#39;, delimiter=&#39;,&#39;, skiprows=26)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we read the .csv/ASCII table and from this we create a table of numpy arrays, each of them with its own name and type. It&amp;rsquo;s also possible to specify the character for the comments in the file (&lt;code&gt;#&lt;/code&gt;), the character separating the values (commas, spaces, &amp;hellip;) and the number of line to be skipped (file header).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;table = fofhdf5.createTable(fofhdf5.root, description=fof_data, name=&#39;fof_data_snap67&#39;, title=&amp;quot;fof_data_snap67&amp;quot;, expectedrows=11697806)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create the HDF5-table with the proper hierarchy, some metadata (description and title). Specify the number of rows one expects to put into the table helps the library to optimize the operations and the space.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for i in range(1, 20):
    fof_data = np.genfromtxt(&#39;fof&#39;+str(i)+&#39;.csv&#39;, dtype=([(&#39;fofId&#39;, &#39;i8&#39;), (&#39;np&#39;, &#39;i4&#39;), (&#39;mass&#39;, &#39;f4&#39;), (&#39;x&#39;, &#39;f4&#39;), (&#39;y&#39;, &#39;f4&#39;), (&#39;z&#39;, &#39;f4&#39;), (&#39;ix&#39;, &#39;i4&#39;), (&#39;iy&#39;, &#39;i4&#39;), (&#39;iz&#39;, &#39;i4&#39;), (&#39;m_crit_200&#39;, &#39;f4&#39;), (&#39;r_crit_200&#39;, &#39;f4&#39;), (&#39;m_mean_200&#39;, &#39;f4&#39;), (&#39;r_meam_200&#39;, &#39;f4&#39;), (&#39;m_tophat&#39;, &#39;f4&#39;), (&#39;r_tophat&#39;, &#39;f4&#39;), (&#39;numSubs&#39;, &#39;i4&#39;)]), comments=&#39;#&#39;, delimiter=&#39;,&#39;, skiprows=26)
    
    table.append(fof_data)
    table.flush()
    print &amp;quot;Loop &amp;quot;, i, &amp;quot; done.&amp;quot;

fofhdf5.close()
print &amp;quot;Done in &amp;quot;, time.time()-t, &amp;quot;seconds !!!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;for&lt;/code&gt; loop opens other ASCII tables and append them to the existing HDF5-table. The &lt;code&gt;table.flush()&lt;/code&gt; command let the library physically write the data on the disk instead of maintaining them in memory and write them periodically. After that we close the file object.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python slicing, rebinning and indexing</title>
      <link>http://brunettoziosi.eu/posts/python-slicing-rebinning-and-indexing/</link>
      <pubDate>Fri, 25 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/python-slicing-rebinning-and-indexing/</guid>
      <description>&lt;p&gt;During my master thesis I had to manage a lot of (different) data from GIF and GIF2 projects, Millimillennium, Millenium and Millennium 2 simulations and so on. Sometimes there were the need to sort, divide or rearrange these dataset.&lt;br /&gt;
Here some examples.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sort the Millennium 2 data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I developed this script to sort the Millennium 2 data in the $x$ coordinate. The dataset was composed of 512 hdf5 files and I would like to create 1000 files of 100 kpc/h each, taking particles for all the original files.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/bin/env python
import time
import numpy as np
import tables as tb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the usual modules importing. &lt;code&gt;tables&lt;/code&gt; is the module provided by PyTables to manage, in a great way, hdf5 file under Python.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;t_glob = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Timing is always good!!!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# This create the first &amp;quot;5 Mpc/h&amp;quot; file, every loop operate on 100 kpc/h of data 
for i in range(0,50):
    t = time.time()
    i_dist = i/10.0
    j_dist = i_dist + 0.1
    print &amp;quot;Starting with limits [Mpc/h]&amp;quot;, i_dist, j_dist
    temp2 = np.array([])
    temp2.shape = (0,3)
    # This loop open each of the 512 original files
    # selecting the particles inside the limits
    # and stacking them into the array that will 
    # be saved in the new file
    for j in range(0,512):
        filename = &#39;../../hdf5/data_&#39;+str(j)
        print &amp;quot;Open &amp;quot;, filename
        h5 = tb.openFile(filename, &#39;r&#39;)
        original = h5.root.data.read()
        h5.close()
        temp = original[original[:,0]&amp;amp;gt;i_dist]
        if temp.size &amp;amp;lt; 3:
            temp3 = np.array([])
            temp3.shape=(0,3)
        else:
            temp3 = temp[temp[:,0]&amp;amp;lt;=j_dist]
        try:
            temp2 = np.vstack((temp2,temp3))
        except:
            print &amp;quot;Error in stacking&amp;quot;
            print &amp;quot;temp2 dimensions &amp;quot;, temp2.shape
            print &amp;quot;temp3 dimensions &amp;quot;, temp3.shape
            exit()
    tt=time.time()

    # Sorting the array in the x direction
    temp2[temp2[:,0].argsort(),]
    print &amp;quot;Time for argsort &amp;quot;, time.time()-tt

    # Writing data to file
    destname = &#39;../../hdf5_sorted/mill2sort-&#39;+str(i)
    print &amp;quot;Writing &amp;quot;, destname
    dest = tb.openFile(destname, &#39;w&#39;)
    dest.createArray(dest.root, &#39;data&#39;, temp2, title=&#39;data&#39;)
    dest.flush()
    dest.close()
    print &amp;quot;Time for loop  &amp;quot;, i, &amp;quot; is &amp;quot;, time.time()-t
print &amp;quot;Done in &amp;quot;,time.time()-t_glob, &amp;quot;seconds&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Rebin the sorted Millennium 2 data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After I have sorted the data, we need to rebin the dataset because it doesn&amp;rsquo;t fit into our machine memory.&lt;br /&gt;
This script make use of the &lt;a href=&#34;http://brunettoziosi.blogspot.it/2011/11/python-parallel-job-manager.html&#34; target=&#34;_blank&#34; title=&#34;Python parallel job manager&#34;&gt; parallel job manager&lt;/a&gt; to break the 1000 files of the sorted dataset into 5000 files each containing 20 kpc/h of data, sorted in the $x$ direction.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#! /usr/bin/env python

import sys, os
import numpy as np
import tables as tb
from subprocess import Popen, PIPE
from multiprocessing import Process, Queue


#############################################
sub_slice_dim = 0.02    #Mpc/h
sub_slice_num = 5 # for each of the original slice
n_procs = 5
tot_mill_slice = 999   # number of original slices
############################################


def slicing(i, j, sub_slice_dim, sub_slice_num):
    &amp;quot;&amp;quot;&amp;quot;Given a mill2 slice it creates 5 subslices.
    &amp;quot;&amp;quot;&amp;quot;
    start_dim = j\*sub_slice_dim
    stop_dim = start_dim + sub_slice_dim
    print &amp;quot;Loop &amp;quot;, j, &amp;quot; of &amp;quot;, sub_slice_num , &amp;quot; between &amp;quot;, start_dim, &amp;quot; and &amp;quot;, stop_dim, &amp;quot; in slice &amp;quot;, i 
    pos_greater = mill_slice[start_dim &amp;amp;lt; mill_slice[:,0]]
    pos = pos_greater[pos_greater[:,0] &amp;amp;lt;= stop_dim]
    h5=tb.openFile(&#39;/home/ziosi/mill2_data/hdf5_sorted_rebinned/mill2sort-&#39;+str(i*5+j)+&#39;.h5&#39;, &#39;w&#39;)
    h5.createArray(h5.root, &#39;data&#39;, pos, title=&#39;mill2_sorted_rebinned_pos&#39;)
    h5.flush()
    h5.close()

def breakmill(in_queue):
    &amp;quot;&amp;quot;&amp;quot;Bring a slice from the queue and start the function to
    sub_slice it.
    &amp;quot;&amp;quot;&amp;quot;
    while in_queue.qsize != 0:
        ii = in_queue.get()
        i = ii[0]
        sub_slice_dim = ii[1]
        sub_slice_num = ii[2]
        original_slice = &amp;quot;/home/ziosi/mill2_data/hdf5_sorted/mill2sort-&amp;quot;+str(i)
        mill_slice = tb.openFile(original_slice, &#39;r&#39;)
        slice_data = mill_slice.root.data.read()
        slice_min = np.amin(slice_data[:,0])
        for j in xrange(5):
            slicing(i, j, sub_slice, slice_dim, sub_slice_num)
    
# Create the queues.
in_queue = Queue()
out_queue = Queue()

# Fill the input queue.
try:
    for i in xrange(tot_mill_slice):
        in_queue.put([i, sub_slice_dim, sub_slice_num])
except:
    print &amp;quot;Input queue not filled, exit!&amp;quot;
    sys.exit(1)

procs = []

# Create the processes.
try:
    for i in range(n_procs):
        print &amp;quot;Process creation loop &amp;quot;, i
        procs.append(Process(target=breakmill, args=(in_queue, out_queue)))
except:
    print &amp;quot;Creating processes not complete, exit...&amp;quot;
    sys.exit(1)

# Start the processes.
try:
    for i in procs:
        i.start()
except:
    print &amp;quot;Start processes not complete, exit...&amp;quot;;
    sys.exit(1)

# Check for processes status.
for i in procs:
    print &amp;quot;Process &amp;quot;, i,&amp;quot; @ &amp;quot; , i.pid, &amp;quot; is &amp;quot;, status(i)

print &amp;quot;Done.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Indexing data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We also need to index a data file to can retrieve only a slice from the entire file. We did it using the following three elements:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;flags = np.arange(0, 110, 0.1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is the array containing the markers for the distances we want to index. This means that if we want to index distances from 0 to 10 every 1, we get: 0,1,2,3,4,5,6,7,8,9,10, so we can select, for example, the element between 0 and 1 without load the entire list.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;start = indexes[np.maximum(np.searchsorted(indexes[:,0], xstart, side=&#39;left&#39;)-1, 0), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;contains the index of the cell in the array that contains the first element we want&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;stop = indexes[np.minimum(np.searchsorted(indexes[:+1], xstop, side=&#39;right&#39;)+1, indexes.shape[0]-1), 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;contains the index of the cell in the array that contains the first element we want.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;indexes = np.hstack((flags.reshape((flags.shape[0], 1)), start.reshape((start.shape[0], 1)), end.reshape((end.shape[0], 1))))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is the $(n,3)$ array with the flag, the start and the stop indexes. It is saved into the data file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python CLI and configuration file parser</title>
      <link>http://brunettoziosi.eu/posts/python-cli-and-configuration-file-parser/</link>
      <pubDate>Thu, 17 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/python-cli-and-configuration-file-parser/</guid>
      <description>&lt;p&gt;One of the first things I needed writing the code for my thesis was the ability to read options and parameters both from a configuration file and from the command line. After some attempts I have found (at &lt;a href=&#34;http://www.decalage.info/&#34; target=&#34;_blank&#34; title=&#34;http://www.decalage.info&#34;&gt;&lt;a href=&#34;http://www.decalage.info&#34;&gt;http://www.decalage.info&lt;/a&gt;&lt;/a&gt;) a file parser to read a configuration file and the Python library &lt;a href=&#34;http://docs.python.org/dev/library/argparse.html&#34; target=&#34;_blank&#34; title=&#34;argparse&#34;&gt;argparse&lt;/a&gt; for the command line parsing. In addition I have modified the file parser and I&amp;rsquo;ve added a &amp;ldquo;variable container&amp;rdquo; object, inspired by some snippets found somewhere on the web.&lt;br /&gt;
&lt;!-- TEASER_END --&gt;
I chose to first parse the configuration file and after the command line options: if it&amp;rsquo;s necessary the command line options will overwrite the file options.&lt;br /&gt;
Let&amp;rsquo;s consider the code, fully commented.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import argparse
def parse_config(filename):    
    &amp;quot;&amp;quot;&amp;quot;Read the config file and store the variables into a dictionary.
    Thanks to http://www.decalage.info
    &amp;quot;&amp;quot;&amp;quot;
    mlogger.info(&amp;quot;Reading config file.&amp;quot;)

    COMMENT_CHAR = &#39;#&#39;
    OPTION_CHAR =  &#39;=&#39;

    options = {}
    f = open(filename)
    for line in f:
        # First, remove comments:
        if COMMENT_CHAR in line:
            # split on comment char, keep only the part before
            line, comment = line.split(COMMENT_CHAR, 1)
        # Second, find lines with an option=value:
        if OPTION_CHAR in line:
            # split on option char:
            option, value = line.split(OPTION_CHAR, 1)
            # strip spaces:
            option = option.strip()
            value = value.strip()
            # store in dictionary:
            options[option] = value
    f.close()
    return options
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is the container for the variables, also clearly commented.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Bunch(object):
    &amp;quot;&amp;quot;&amp;quot;Create a dictionary object containing all the initial variables.
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, d=None):
        if d is not None: self.__dict__.update(d)

def var(filename):
    &amp;quot;&amp;quot;&amp;quot;Read the initial variables and return a dictionary object.

    Parameters
    ==========

    filename = string, the name of the config file

    Returns
    =======

    Bunch(locals()) = dictionary object containing the local variables

    &amp;quot;&amp;quot;&amp;quot;

    # Read the config file and create a dictionary.
    options = parse_config(filename)

    # Common variables.
    mlogger.info(&amp;quot;Defining common parameters.&amp;quot;)

    parameter_1 = options[&#39;parameter_1&#39;]
    parameter_2 = options[&#39;parameter_2&#39;]
    parameter_3 = None
    option_1 = False

    return Bunch(locals())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the commented code for the command line parsing.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Read the configuration file.
    v = mod.var(&#39;../config.txt&#39;)

    # Check if there are CLI arguments, if yes start parsing.
    if argv is None:
        # Check for CLI variables.
        argv = sys.argv

        # Create the parser object.
        parser = argparse.ArgumentParser()

        # Create the parser entry.
        parser.add_argument(&#39;-p1&#39;, &#39;-parameter_1&#39;, &#39;--parameter_1&#39;, action=&#39;store&#39;, dest=&#39;parameter_1&#39;, default=v.parameter_1, 
                    help=&#39;Parameter 1 description&#39;)
        parser.add_argument(&#39;-p2&#39;, &#39;-parameter_2&#39;, &#39;--oparameter_2&#39;, action=&#39;store&#39;, dest=&#39;parameter_2&#39;, default=v.parameter_2, 
                    help=&#39;Parameter 2 description&#39;)
        parser.add_argument(&#39;-o&#39;, &#39;--option&#39;, action=&#39;store_true&#39;, dest=&#39;option&#39;, default=None, 
                    help=&#39;Oprion description&#39;)

        # Add the parsed variables to a container object
        cli = parser.parse_args()

        # Overwrite the config file parameters
        v.parameter_1 = cli.parameter_1
        v.parameter_2 = cli.parameter_2
        v.option = cli.option

    elif isinstance(argv, dict):
        # Reading variables passed to Main as a function (Guido docet
        # http://www.artima.com/weblogs/viewpost.jsp?thread=4829).
        for i in argv.keys():
            if i in (&amp;quot;-p1&amp;quot;, &amp;quot;--parameter_1&amp;quot;): 
                v.parameter_1 = argv[i]
            elif i in (&amp;quot;-p2&amp;quot;, &amp;quot;--parameter_2&amp;quot;): 
                v.parameter_2 = argv[i]
            elif i in (&amp;quot;-o&amp;quot;, &amp;quot;--option&amp;quot;):
                v.option = True
            else:
                print &amp;quot;Wrong parameter passed to main function, exit!!!&amp;quot;
                sys.exit(1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The configuration file look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Short description of parameter 1
parameter_1 = value

# Short description of parameter 2
parameter_2 = None
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>