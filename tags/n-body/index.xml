<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>N Body on Post It!</title>
    <link>http://brunettoziosi.eu/tags/n-body/</link>
    <description>Recent content in N Body on Post It!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Aug 2013 09:34:11 +0000</lastBuildDate>
    <atom:link href="http://brunettoziosi.eu/tags/n-body/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>StarLab-GPU installation</title>
      <link>http://brunettoziosi.eu/posts/starlab-gpu-installation/</link>
      <pubDate>Tue, 20 Aug 2013 09:34:11 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/starlab-gpu-installation/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../../pages/research/utils/starlab-gpu-old-guide&#34;&gt;Click here for the old guide!!!&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;2014/09/16: updated with installation instruction for g2@Swinburne and some troubleshooting.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;UPDATE 2:&lt;/strong&gt; &lt;strong&gt;&lt;a href=&#34;../dockerized-starlab/&#34;&gt;new post&lt;/a&gt;&lt;/strong&gt; about installing and using StarLab in a Docker container!!
Less troubles, more reproducibility!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; if you want to compile starlab &lt;strong&gt;without GPU support&lt;/strong&gt;, you only need to&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ignore the &amp;ldquo;&lt;code&gt;sapporo&lt;/code&gt;&amp;rdquo;  and &amp;ldquo;&lt;code&gt;CUDA&lt;/code&gt;&amp;rdquo; instructions&lt;/li&gt;
&lt;li&gt;rename &lt;code&gt;starlab/local/grape.sh&lt;/code&gt; to &lt;code&gt;starlab/local/_grape.sh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;substitute &lt;code&gt;configure --without-f77&lt;/code&gt; with &lt;code&gt;configure --with-grape=no --without-f77&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;in case you can&amp;rsquo;t &lt;code&gt;make&lt;/code&gt; succesfully may be you need to copy the folder
&lt;code&gt;starlab/src/gfx&lt;/code&gt; and do not make clean&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Well, probably you landed here searching information about StarLab, how to
install it, how to run it, how prevent it to harm your cat.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DISCLAIMER 1:&lt;/strong&gt; I won&amp;rsquo;t promise anything about your cat but I will try to help you having a
reasonable well running installation of StarLab.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DISCLAIMER 2:&lt;/strong&gt; I&amp;rsquo;m not a programmer, I&amp;rsquo;m not a system administrator and I don&amp;rsquo;t even
know how to program in CUDA (yet). Maybe something here is wrong ore outdated.
I&amp;rsquo;m only giving you some of the experienced I collected in n+1 times I installed StarLab.
Nothin less, nothing more.&lt;br /&gt;
Also note that most of the knowledge I put here come
from my &lt;a href=&#34;http://web.pd.astro.it/mapelli/&#34;&gt;supervisor&lt;/a&gt;.&lt;br /&gt;
I also thanks Mario Spera for the usefull advices.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DISCLAIMER 3:&lt;/strong&gt; StarLab still seems to &lt;strong&gt;always&lt;/strong&gt; crash if you try to simulate a system
with more than ~6000 binaries.&lt;/p&gt;

&lt;h2 id=&#34;starlab:76&#34;&gt;StarLab&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.sns.ias.edu/~starlab/&#34;&gt;StarLab&lt;/a&gt; is &amp;ldquo;A Software Environment for Collisional Stellar Dynamics&amp;rdquo;.
&lt;a href=&#34;http://www.sns.ias.edu/~starlab/&#34;&gt;Here&lt;/a&gt; you can find useful information about it that
is not useful to rewrite here, so have a look and then come back!:)&lt;/p&gt;

&lt;h2 id=&#34;starlab-gpu:76&#34;&gt;StarLab-GPU&lt;/h2&gt;

&lt;p&gt;Welcome back!!&lt;br /&gt;
Next step: StarLab was designed to run on &lt;a href=&#34;http://en.wikipedia.org/wiki/Gravity_Pipe&#34;&gt;GRAPE&lt;/a&gt;
but thanks to the &lt;a href=&#34;http://castle.strw.leidenuniv.nl/software/sapporo.html&#34;&gt;Sapporo&lt;/a&gt;
library you can run it on GPUs.&lt;/p&gt;

&lt;p&gt;Now we will try to install a GPU-ready version of StarLab. To be honest, we run
a &lt;strong&gt;private&lt;/strong&gt; version of StarLab for GPU with some customizations (if you are interested,
see &lt;a href=&#34;http://arxiv.org/abs/1211.6441&#34;&gt;Mapelli et al. 2013&lt;/a&gt;; &lt;a href=&#34;http://arxiv.org/abs/1301.4227&#34;&gt;Mapelli &amp;amp; Bressan 2013&lt;/a&gt;).&lt;br /&gt;
Unfortunately you can&amp;rsquo;t download it now, but I hope the differences in the installation
process are negligible. Ask us if you are interested in our version of StarLab.&lt;br /&gt;
Because I&amp;rsquo;m not sure about what you will find in the public version os Sapporo and StarLab,
I will show my version of the relevant files you need to install everything.
The installation is done on a Ubuntu 14.04 workstation so change them accordingly to
your OS. I will also provide some examples on what you need to install StarLab on
the clusters I tested.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start!!&lt;/p&gt;

&lt;h4 id=&#34;download:76&#34;&gt;Download&lt;/h4&gt;

&lt;p&gt;Be sure you have boost libraries, nVidia driver and CUDA correctly installed.
You can try to check them using&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep nvcc&lt;/code&gt; (cuda compiler)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep include&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep include | grep toolkit&lt;/code&gt; (for the SDK files of the new release)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | grep lib | grep cudart&lt;/code&gt; (CUDA runtime)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | boost lib&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;locate cuda | boost include&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It could be also useful to have a copy of the old CUDA SDK. Yes, I know, it&amp;rsquo;s a mess,
but it&amp;rsquo;s not my fault!:P&lt;/p&gt;

&lt;p&gt;Download&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sns.ias.edu/~starlab/download/starlab.tar.gz&#34;&gt;StarLab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://castle.strw.leidenuniv.nl/documents/Sapporo/sapporo161.tgz&#34;&gt;Sapporo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and decompress the archives with &lt;code&gt;tar -xvf archiveName&lt;/code&gt;.&lt;br /&gt;
Try to have the following folder tree:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;$SLPATH/slpack&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SLPATH/slpack/NVIDIA&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SLPATH/slpack/NVIDIA/NVIDIA_CUDA-5.0_Samples&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SLPATH/slpack/NVIDIA/NVIDIA_GPU_Computing_SDK&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SLPATH/slpack/sapporo&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SLPATH/slpack/starlab&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The NVIDIA folder is optional, but I would suggest to have with you alle the NVIDIA
file you can find, soon or later you will need them. CUDA is continuosly changing,
SDK is not toolkit, dependencies are different and broken between different versions.
We will try to survive and to have the most standard installation we can.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$SLPATH&lt;/code&gt; should be the path where you put your StarLab installation.&lt;br /&gt;
I&amp;rsquo;m not sure about what you will find in the public version of StarLab and Sapporo.&lt;/p&gt;

&lt;h3 id=&#34;sapporo:76&#34;&gt;Sapporo&lt;/h3&gt;

&lt;p&gt;Enter in the sapporo folder, and to be sure to start a clean installation run
&lt;code&gt;make clean&lt;/code&gt;.
Here you need to find:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Makefile&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compile.sh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host_evaluate_gravity.cu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;compile.sh&lt;/code&gt; is the script StarLab will run later to decide if you are worthy of
its presence in your computer. If &lt;code&gt;compile.sh&lt;/code&gt; fail, StarLab won&amp;rsquo;t install.&lt;/p&gt;

&lt;p&gt;You also need to find somewhere (= in an old CUDA SKD?)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cutil.h&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;multithreading.h&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and to copy them in this folder.&lt;br /&gt;
If you are not able to find them, ask me, I have copies of those files.&lt;/p&gt;

&lt;p&gt;Open &lt;code&gt;host_evaluate_gravity.cu&lt;/code&gt; and change&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;#include &amp;lt;cutil.h&amp;gt;
#include &amp;lt;multithreading.h&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;#include &amp;quot;cutil.h&amp;quot;
#include &amp;quot;multithreading.h&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is to make Sapporo read the local version of &lt;code&gt;cutil.h&lt;/code&gt; and &lt;code&gt;multithreading.h&lt;/code&gt;
in case your CUDA version does not support them anymore.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s time to fix a bug (thanks Mario):
in &lt;code&gt;sapporo.cpp&lt;/code&gt; change&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;		fprintf(stderr, &amp;quot;\n&amp;quot;);
		nCUDAdevices = how_many;
    } else {
		fprintf(stderr,&amp;quot; sapporo::open - no config file is found \n&amp;quot;);
		fprintf(stderr,&amp;quot;  using all %d CUDA device(s), nj_max= %d\n&amp;quot;, nCUDAdevices, nj_max);
		//Set original_how_many to a positive number so we get assigned different devices
		//incase the devices are not in compute exclusive mode.
		original_how_many = 1;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;		fprintf(stderr, &amp;quot;\n&amp;quot;);
		nCUDAdevices = how_many;
		fclose(fd); // thanks Mario Spera, without this SL will crash after a while if using sapporo.config
  } else {
    fprintf(stderr,&amp;quot; sapporo::open - no config file is found \n&amp;quot;);
    fprintf(stderr,&amp;quot;  using all %d CUDA device(s), nj_max= %d\n&amp;quot;, nCUDAdevices, nj_max);
    //Set original_how_many to a positive number so we get assigned different devices
    //incase the devices are not in compute exclusive mode.
    original_how_many = 1;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so the &lt;code&gt;sapporo.config&lt;/code&gt; file can be close and won&amp;rsquo;t crash your run.&lt;/p&gt;

&lt;p&gt;Now open &lt;code&gt;Makefile&lt;/code&gt; and fit&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Makefile&#34;&gt;CXX  := g++
CC   := gcc
NVCC := /usr/bin/nvcc
CUDAPATH    := /usr/include/
CUDAINCLUDE := -I$(CUDAPATH) 
BOOSTPATH := /usr/include/boost 
BOOSTINCLUDE := -I$(BOOSTPATH)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to your case.&lt;br /&gt;
Open &lt;code&gt;compile.sh&lt;/code&gt; and be sure to have something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

flags=-DNGB

CUDAINC=&amp;quot;-I/usr/include -I/usr/lib/nvidia-cuda-toolkit/include/&amp;quot;
CUDALIB=&amp;quot;-L/usr/lib/x86_64-linux-gnu/&amp;quot;
CUDAFLAG=&amp;quot;-lcudart&amp;quot;
BOOSTINC=&amp;quot;-I/usr/include/boost&amp;quot;
BOOSTLIB=&amp;quot;-L/usr/lib/x86_64-linux-gnu/&amp;quot;
BOOSTFLAG=&amp;quot;-lboost_system -lboost_thread -lpthread&amp;quot;


g++ -O3 $flags -g -o test_gravity_block test_gravity_block.cpp -L. -lsapporo $CUDAINC $CUDALIB $CUDAFLAG $BOOSTINC $BOOSTLIB $BOOSTFLAG
g++ -O3 $flags -g -o test_gravity_N2ngb test_gravity_N2ngb.cpp -L. -lsapporo $CUDAINC $CUDALIB $CUDAFLAG $BOOSTINC $BOOSTLIB $BOOSTFLAG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Try to compile with &lt;code&gt;make&lt;/code&gt;. If it works, try to tun &lt;code&gt;bash compile.sh&lt;/code&gt;. If this works too,
then test sapporo with&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;./test_gravity_block 800&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./test_gravity_block 800&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Be aware that a number (of particles) too small would crash the tests.&lt;/p&gt;

&lt;p&gt;Assuming &lt;code&gt;sapporo&lt;/code&gt; is ready, let&amp;rsquo;s move to starlab.&lt;/p&gt;

&lt;h3 id=&#34;starlab-1:76&#34;&gt;StarLab&lt;/h3&gt;

&lt;p&gt;In StarLab the relevant files you have to worry about are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sbin/sqrt.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;configure&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;local/grape.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rename &lt;code&gt;sbin/sqrt.c&lt;/code&gt; to &lt;code&gt;sbin/sqrt.C&lt;/code&gt; otherwise
you could have linker problems again the C math library.&lt;br /&gt;
Now open &lt;code&gt;configure&lt;/code&gt; and search for CUDA. Probably you won&amp;rsquo;t find anything.&lt;br /&gt;
Search for &lt;code&gt;Check all named libraries for g6_open&lt;/code&gt;, you should find something like&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#   Check all named libraries for g6_open() (GRAPE-6).

    grape6=no

    for gl in $GRAPE_LIBS_; do
        as_ac_Lib=`echo &amp;quot;ac_cv_lib_${gl/-l/}&#39;&#39;_g6_open_&amp;quot; | $as_tr_sh`
echo &amp;quot;$as_me:$LINENO: checking for g6_open_ in -l${gl/-l/}&amp;quot; &amp;gt;&amp;amp;5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;modify it to include boost and CUDA like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;for gl in $GRAPE_LIBS_; do
	CUDAINC=&amp;quot;-I/usr/include -I/usr/lib/nvidia-cuda-toolkit/include/&amp;quot;
	CUDALIB=&amp;quot;-L/usr/lib/x86_64-linux-gnu/&amp;quot;
	CUDAFLAG=&amp;quot;-lcudart&amp;quot;
	BOOSTINC=&amp;quot;-I/usr/include/boost/&amp;quot;
	BOOSTLIB=&amp;quot;-L/usr/lib/x86_64-linux-gnu/&amp;quot;
	BOOSTFLAG=&amp;quot;-lboost_system -lboost_thread -lpthread&amp;quot;
	
	LIBS=&amp;quot;$CUDAINC $CUDALIB $CUDAFLAG $BOOSTINC $BOOSTLIB $BOOSTFLAG -DNGB&amp;quot;
		
	as_ac_Lib=`echo &amp;quot;ac_cv_lib_${gl/-l/}&#39;&#39;_g6_open_&amp;quot; | $as_tr_sh`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be sure to always use double quotes and to terminate the paths to folders with a slash (&lt;code&gt;/&lt;/code&gt;),
some machines are quite choosy.&lt;/p&gt;

&lt;p&gt;Last edit is on &lt;code&gt;local/grape.sh&lt;/code&gt; to let StarLab know where your sapporo installation is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GRAPE_LDFLAGS_=&#39;-L$SLPATH/slpack/sapporo&#39;
GRAPE_LIBS_=&#39;-lsapporo&#39;
# For now, define this as `yes&#39; for the AMD64 boxes only, `no&#39; otherwise.
OLD_READ_NEIGHBOUR_LIST=no
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before compiling, if you want, you can check also &lt;code&gt;sapporo/sapporo.config&lt;/code&gt;.&lt;br /&gt;
Inside you will find something like that:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;524288
-1
0
1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where 524288 should be the maximum number of particles you can handle, -1 the number
of CUDA devices to use (-1 means all? maybe&amp;hellip;), 0 and 1 are the GPU number you want to use.&lt;br /&gt;
Recent CUDA seems to be smart enought to understand where to run without having to specify
(but look after your cat!!!).&lt;/p&gt;

&lt;p&gt;Alright!! If you managed to reach this point, very good. Last three commands. In the
&lt;code&gt;starlab&lt;/code&gt; folder run&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;configure --with-f77=no&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;go out for a walk&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;make install&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When running configure, avoid the &lt;code&gt;--without-option&lt;/code&gt; version of an option, prefer
&lt;code&gt;--with-option=no&lt;/code&gt;, it&amp;rsquo;s safer.&lt;/p&gt;

&lt;p&gt;If you recompile StarLab AND/OR Sapporo, type &lt;code&gt;make clean&lt;/code&gt; two times. delete the files in
&lt;code&gt;starlab/usr/bin&lt;/code&gt;, turn around 3 times, touch your nose and type &lt;code&gt;make&lt;/code&gt; two times. Then
&lt;code&gt;make install&lt;/code&gt; again.&lt;br /&gt;
No, &lt;code&gt;make clean&lt;/code&gt; and &lt;code&gt;make&lt;/code&gt; are not enought to update your object
files or binaries.&lt;/p&gt;

&lt;p&gt;Depending on your environment, if you run into problems, be sure that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;you loaded the correct modules (if you are in a cluster for examples&lt;/li&gt;
&lt;li&gt;you are into the right node (some machine let you compile your code on a
node that is not the login node)&lt;/li&gt;
&lt;li&gt;if you encounter strange messages regarding missing rules for missing files,
for example &lt;code&gt;libxhdyn.la&lt;/code&gt; or something regarding &lt;code&gt;gfx&lt;/code&gt;-something, may be tou need to
tune your config file to exclude, for example, the X/Qt/&amp;hellip; libraries, in case
try to run &lt;code&gt;configure --with-f77=no --with-qt=no&lt;/code&gt;; in case try to have a look at
&lt;code&gt;configure --help&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;run-starlab:76&#34;&gt;Run StarLab&lt;/h3&gt;

&lt;p&gt;Before run a simulation you need to create the initial conditions.&lt;/p&gt;

&lt;h4 id=&#34;initial-conditions:76&#34;&gt;Initial Conditions&lt;/h4&gt;

&lt;p&gt;StarLab is provided with few tools to help (really?) you in this task. A common
way to create ICs for &lt;a href=&#34;http://arxiv.org/abs/1404.7147&#34;&gt;our simulations&lt;/a&gt; is something like:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;ehm, I don&#39;t know if I can tell you, sorry man...:(&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;launch:76&#34;&gt;Launch&lt;/h4&gt;

&lt;p&gt;StarLab read ICs from the STDIN, write the output snapshots to STDOUT and everything
you want to know about your simulations to STDERR, so, &lt;code&gt;&amp;lt;ehm.... see ICs&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;tidal-fields:76&#34;&gt;Tidal fields&lt;/h4&gt;

&lt;p&gt;Be patience&amp;hellip;&lt;/p&gt;

&lt;h3 id=&#34;known-issues-and-troubleshooting:76&#34;&gt;Known issues and Troubleshooting&lt;/h3&gt;

&lt;p&gt;If StarLab did not kill your cat in a horrile way, then, it can still ruin your life.&lt;br /&gt;
Some of the things that can happen are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;you can find binaries with eccentricity greater than one (StarLab does
not update some binaries after they are disrupted? flybyes seen as binaries? don&amp;rsquo;t know)&lt;/li&gt;
&lt;li&gt;StarLab can crash if you try to simulate a number of centers of mass greater than
5*10^4 together with a fraction of primordial binaries &amp;gt;=0.1&lt;/li&gt;
&lt;li&gt;boost problems? check the correct flags for your version (choose among some combination of
&lt;code&gt;-lboost_system, -lboost_system-mt, -lboost_thread, -lpthread&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;check you put all the &lt;code&gt;_&lt;/code&gt;, &amp;ldquo;-I&amp;rdquo;, &amp;ldquo;-l&amp;rdquo;, &amp;ldquo;-L&amp;rdquo; in the right places&lt;/li&gt;
&lt;li&gt;check all the libraries paths&lt;/li&gt;
&lt;li&gt;check for double quotes (&lt;code&gt;&amp;quot;&lt;/code&gt;) instead of single ones (&lt;code&gt;&#39;&lt;/code&gt;) in the paths&lt;/li&gt;
&lt;li&gt;check the modules, environment variables&lt;/li&gt;
&lt;li&gt;check you are on the right node&lt;/li&gt;
&lt;li&gt;check your environment against the configure options you passed
(have a look at &lt;code&gt;configure --help&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;if you need to modify StarLab and you want to add your own flags,
you need to comment&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;  getia(b-&amp;gt;get_log_story(), &amp;quot;step_slow&amp;quot;,
        b-&amp;gt;get_kira_counters()-&amp;gt;step_slow, nss);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;function call in &lt;code&gt;kira_counters.C&lt;/code&gt; otherwise you won&amp;rsquo;t be able to compile StarLab.&lt;/p&gt;

&lt;h3 id=&#34;clusters:76&#34;&gt;Clusters&lt;/h3&gt;

&lt;h4 id=&#34;eurora:76&#34;&gt;EURORA&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;in &lt;code&gt;setup_sapporo.sh&lt;/code&gt;
(if you want to compile sapporo using queues, or, load modules by hand if you want to
compile interactively)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;module purge
module load profile/advanced
module load gnu/4.6.3
module load boost/1.53.0--gnu--4.6.3
module load cuda

LD_LIBRARY_PATH=/cineca/prod/compilers/cuda/5.0.35/none/lib64:/cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/lib
export LD_LIBRARY_PATH
cd $HOME/slPack/sapporo
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;in &lt;code&gt;compile.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDAINC=&amp;quot;-I/cineca/prod/compilers/cuda/5.0.35/none/include/ -I/cineca/prod/compilers/cuda/5.0.35/none/samples/common/inc/ -I/cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/include/&amp;quot;
CUDALIB=&amp;quot;-L/cineca/prod/compilers/cuda/5.0.35/none/lib64 -L/cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/lib -lcudart&amp;quot;
g++ -O3 $flags -g -o test_gravity_block test_gravity_block.cpp -L. -lsapporo $CUDAINC $CUDALIB -lboost_thread-mt
g++ -O3 $flags -g -o test_gravity_N2ngb test_gravity_N2ngb.cpp -L. -lsapporo $CUDAINC $CUDALIB -lboost_thread-mt
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;in &lt;code&gt;Makefile&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;NVCC := /cineca/prod/compilers/cuda/5.0.35/none/bin/nvcc
CUDAPATH    := /cineca/prod/compilers/cuda/5.0.35/none
CUDASDKPATH := /cineca/prod/compilers/cuda/5.0.35/none/samples
CUDAINCLUDE := -I$(CUDAPATH)/include -I$(CUDASDKPATH)/common/inc 
BOOSTPATH := /cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/include
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;in &lt;code&gt;configure&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CUDAINC=&amp;quot;-I/cineca/prod/compilers/cuda/5.0.35/none/include -I/cineca/prod/compilers/cuda/5.0.35/none/samples/common/inc -I/cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/include/&amp;quot;
CUDALIB=&amp;quot;-L/cineca/prod/compilers/cuda/5.0.35/none/lib64 -lcudart&amp;quot; 
LIBS=&amp;quot;$CUDAINC $CUDALIB -L/cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/lib -lboost_thread-mt -DNGB&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;in &lt;code&gt;grape.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;GRAPE_LDFLAGS_=&#39;-L$HOME/slPack/sapporo/&#39;
GRAPE_LIBS_=&#39;-lsapporo&#39;

&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;in &lt;code&gt;setup_starlab.sh.sh&lt;/code&gt;
(if you want to compile sapporo using queues, or, load modules by hand if you want to
compile interactively)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;module purge
module load profile/advanced
module load gnu/4.6.3
module load boost/1.53.0--gnu--4.6.3
module load cuda
LD_LIBRARY_PATH=/cineca/prod/compilers/cuda/5.0.35/none/lib64:/cineca/prod/libraries/boost/1.53.0/gnu--4.6.3/lib
export LD_LIBRARY_PATH
cd $HOME/slPack/starlab
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;green-ii-hpc-system-swinburne-university:76&#34;&gt;Green II HPC system @ Swinburne University&lt;/h4&gt;

&lt;p&gt;Thanks to prof. Jarrod Hurley I was able to test the installation of StarLab on the Green II HPC
system at the Swinburne University. Here how to do that.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Log into the system and find yourself in the login node.&lt;/li&gt;
&lt;li&gt;Clone the private repo / download the folders and unpack them like described before.&lt;/li&gt;
&lt;li&gt;Then you need to log into one of the compile/test nodes from the head node: &lt;code&gt;ssh $USER@gstar001&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;load the right modules:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;module load gcc/4.6.4
module load boost/x86_64/gnu/1.51.0-gcc4.6
module load cuda/4.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You need that version of &lt;code&gt;gcc&lt;/code&gt; and &lt;code&gt;boost&lt;/code&gt; because of issues with boost threads in the default versions.
Just in case, check that the paths in the &lt;code&gt;Makefile&lt;/code&gt; and &lt;code&gt;compile.h&lt;/code&gt; agree with that shown in&lt;br /&gt;
&lt;code&gt;module show boost/x86_64/gnu/1.51.0-gcc4.6&lt;/code&gt;
and
&lt;code&gt;module show cuda&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Make sure you have no &lt;code&gt;&#39;&lt;/code&gt; around your path, maybe, if you need, only &lt;code&gt;&amp;quot;&lt;/code&gt; otherwise &lt;code&gt;sapporo&lt;/code&gt; won&amp;rsquo;t compile.
Just in case, check that the paths in the &lt;code&gt;Makefile&lt;/code&gt; and &lt;code&gt;compile.h&lt;/code&gt; agree with that shown in&lt;br /&gt;
&lt;code&gt;module show boost/x86_64/gnu/1.51.0-gcc4.6&lt;/code&gt;
and
&lt;code&gt;module show cuda&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If you have our private version you can
* &lt;code&gt;cp ../scripts/g2/Makefile ./&lt;/code&gt;
* &lt;code&gt;cp ../scripts/g2/compile.sh ./&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;otherwise try to modify them to have:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;CXX  := g++
CC   := gcc
NVCC := /usr/local/cuda-4.0/bin/nvcc
CUDAINC := -I/usr/local/cuda-4.0/include -I/usr/local/cuda-4.0/C/common/inc 
BOOSTINC := -I/usr/local/x86_64/gnu/boost-1.51.0-gcc4.6
NVCCFLAGS := -O0 -g -D_DEBUG  -maxrregcount=64 $(CUDAINC) $(BOOSTINC) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in the &lt;code&gt;Makefile&lt;/code&gt; and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;flags=-DNGB

CUDAINC=&amp;quot;-I/usr/local/cuda-4.0/include -I/usr/local/cuda-4.0/C/common/inc&amp;quot;
CUDALIB=&amp;quot;-L/usr/local/cuda-4.0/lib64 -L/usr/local/cuda-4.0/lib:/usr/local/cuda-4.0/C/lib&amp;quot;
CUDAFLAG=&amp;quot;-lcudart&amp;quot;
BOOSTINC=&amp;quot;-I/usr/local/x86_64/gnu/boost-1.51.0-gcc4.6&amp;quot;
BOOSTLIB=&amp;quot;-L/usr/local/x86_64/gnu/boost-1.51.0-gcc4.6&amp;quot;
BOOSTFLAG=&amp;quot;-lboost_system  -lboost_thread-mt -lpthread&amp;quot;

g++ -O3 $flags -g -o test_gravity_block test_gravity_block.cpp -L. -lsapporo $CUDAINC $CUDALIB $CUDAFLAG $BOOSTINC $BOOSTLIB $BOOSTFLAG
g++ -O3 $flags -g -o test_gravity_N2ngb test_gravity_N2ngb.cpp -L. -lsapporo $CUDAINC $CUDALIB $CUDAFLAG $BOOSTINC $BOOSTLIB $BOOSTFLAG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in &lt;code&gt;compile.sh&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then run&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bash compile.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No go the the starlab folder (&lt;code&gt;cd ../starlab&lt;/code&gt;) and fix the &lt;code&gt;configure&lt;/code&gt; file accordingly to this&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#   Check all named libraries for g6_open() (GRAPE-6).

    grape6=no

    for gl in $GRAPE_LIBS_; do
    ##############################
    ######      g2
    ##############################
    CUDAINC=&amp;quot;-I/usr/local/cuda-4.0/include/ -I/usr/local/cuda-4.0/C/common/inc/&amp;quot;
    CUDALIB=&amp;quot;-L/usr/local/cuda-4.0/lib64 -L/usr/local/cuda-4.0/lib:/usr/local/cuda-4.0/C/lib&amp;quot;
    CUDAFLAG=&amp;quot;-lcudart&amp;quot;
    BOOSTINC=&amp;quot;-I/usr/local/x86_64/gnu/boost-1.51.0-gcc4.6/&amp;quot;
    BOOSTLIB=&amp;quot;-L/usr/local/x86_64/gnu/boost-1.51.0-gcc4.6&amp;quot;
    BOOSTFLAG=&amp;quot;-lboost_system  -lboost_thread-mt -lpthread&amp;quot;
    
    LIBS=&amp;quot;$CUDAINC $CUDALIB $CUDAFLAG $BOOSTINC $BOOSTLIB $BOOSTFLAG -DNGB&amp;quot;
        
        
    as_ac_Lib=`echo &amp;quot;ac_cv_lib_${gl/-l/}&#39;&#39;_g6_open_&amp;quot; | $as_tr_sh`

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and the &lt;code&gt;local/grape.sh&lt;/code&gt; file to point to your sapporo installation.&lt;/p&gt;

&lt;p&gt;If you have our version of StarLab, just copy the right files:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cp ../scripts/g2/configure ./&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cp ../scripts/g2/grape.sh ./local/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Make sure again &lt;code&gt;grape.sh&lt;/code&gt; points to the right folder&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;./configure --without-f77 --with-qt=no&lt;/code&gt; (if you want qt, load the modules and check the versions)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make clean &amp;amp;&amp;amp; make clean &amp;amp;&amp;amp; make clean&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make &amp;amp;&amp;amp; make&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rm ./usr/bin/*&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make install&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;** Troubleshooting **&lt;/p&gt;

&lt;p&gt;If you get this error (or some other error)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make[2]: Entering directory `/mnt/home/bziosi/slpack/starlab/src/gfx/lux&#39;
/bin/sh ../../../libtool --preserve-dup-deps --mode=link gcc  -g -O2  -L/usr/lib64/qt-3.3/lib -o libgfx-2.la   win.lo draw.lo draw1.lo color.lo dialog.lo mcd.lo interface.lo termio.lo utility.lo simple.lo  -I/usr/local/cuda-4.0/include -I/usr/local/cuda-4.0/C/common/inc -L/usr/local/cuda-4.0/lib64 -L/usr/local/cuda-4.0/lib:/usr/local/cuda-4.0/C/lib -lcudart -L/usr/local/x86_64/gnu/boost-1.51.0-gcc4.6 -lboost_system  -lboost_thread-mt -lpthread -DNGB
ar cru .libs/libgfx-2.a  win.o draw.o draw1.o color.o dialog.o mcd.o interface.o termio.o utility.o simple.o
ar: interface.o: No such file or directory
make[2]: *** [libgfx-2.la] Error 1
make[2]: Leaving directory `/mnt/home/bziosi/slpack/starlab/src/gfx/lux&#39;
make[1]: *** [clibs23] Error 2
make[1]: Leaving directory `/mnt/home/bziosi/slpack/starlab/src/gfx&#39;
make: *** [libs] Error 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;when compiling may be you can try to &lt;code&gt;make&lt;/code&gt; and &lt;code&gt;make clean&lt;/code&gt; some times.&lt;br /&gt;
Also remember that make clean is not working properly, so you need to &lt;code&gt;make clean&lt;/code&gt; more than once or delete the binaries by yourself.&lt;/p&gt;

&lt;p&gt;If you have errors regarding no rules for &lt;code&gt;libxhdyn.la&lt;/code&gt;, probably you forgot to exclude
some options from the configure, so run &lt;code&gt;configure --with-f77=no --with-qt=no&lt;/code&gt; or try &lt;code&gt;configure --help&lt;/code&gt;
to check for other options.&lt;/p&gt;

&lt;h3 id=&#34;additional-material:76&#34;&gt;Additional material&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Code units (coming soon&amp;hellip;)&lt;/li&gt;
&lt;li&gt;StarLab internals (TODO)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bitbucket.org/michelis/slpack&#34;&gt;Our repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/brunetto/sltools&#34;&gt;Tools to easily manage SL runs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.science.uva.nl/sites/modesta/wiki/index.php/Starlab_tools&#34;&gt;StarLab tools wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sns.ias.edu/~starlab/tools/auto/&#34;&gt;Auto-built tools list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Cosmological simulations #9: Gadget-2 (N-body part)</title>
      <link>http://brunettoziosi.eu/posts/cosmological-simulations-9-gadget-2-n-body-part/</link>
      <pubDate>Mon, 20 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/cosmological-simulations-9-gadget-2-n-body-part/</guid>
      <description>&lt;p&gt;Here I would like to do a brief presentation of the main features of Gadget-2.&lt;br /&gt;
Gadget-2 (&lt;a href=&#34;http://www.mpa-garching.mpg.de/gadget/&#34; target=&#34;_blank&#34; title=&#34;Gadget2 homepage&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://www.brunettoziosi.eu/blog/wordpress/my-first-gadget2-tests/&#34; target=&#34;_blank&#34; title=&#34;My first Gadget-2 tests&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2966.2005.09655.x/abstract;jsessionid=DED86CDB5CD8A572F3631F0C42828086.d01t03&#34; target=&#34;_blank&#34; title=&#34;Gadget-2 paper&#34;&gt;here&lt;/a&gt;) is a cosmological simulation code developed primarily by &lt;a href=&#34;http://www.mpa-garching.mpg.de/~volker/&#34; target=&#34;_blank&#34; title=&#34;Volker Springel&#39;s homepage&#34;&gt;Volker Springel&lt;/a&gt;. It is a &lt;a href=&#34;http://www.brunettoziosi.eu/blog/wordpress/cosmological-simulations-3-calculating-the-force/&#34; target=&#34;_blank&#34; title=&#34;Cosmological simulations #3: force calculation!&#34;&gt;TreePM&lt;/a&gt; code so it splits forces between long-range (PM part) and short-range (tree part using multipole expansion to approximate the force of distant particles groups).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The tree&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gadget-2 uses a&lt;a href=&#34;http://en.wikipedia.org/wiki/Octree&#34; target=&#34;_blank&#34; title=&#34;oct-tree&#34;&gt; BH oct-tree&lt;/a&gt; (see also &lt;a href=&#34;http://en.wikipedia.org/wiki/Barnes%E2%80%93Hut_simulation&#34; target=&#34;_blank&#34; title=&#34;Barnes&amp;amp;Hut simulation on wikipedia&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://www.artcompsci.org/~makino/softwares/C++tree/index.html&#34; target=&#34;_blank&#34; title=&#34;NBODY, an implementation of Barnes-Hut treecode&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://ifa.hawaii.edu/~barnes/software.html&#34; target=&#34;_blank&#34; title=&#34;Barnes&#39; page&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://www.cita.utoronto.ca/~dubinski/treecode/treecode.html&#34; target=&#34;_blank&#34; title=&#34;A parallel tree code explenation&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://www.prism.gatech.edu/~gth716h/BNtree/&#34; target=&#34;_blank&#34; title=&#34;Barnes-Hut Implementation in HTML/Javascript&#34;&gt;here&lt;/a&gt;) to calculate the short-range forces in the real space. This choice was done because this type of tree, compared to other types (KD-Tree, &amp;hellip;), requires the creation of less nodes, that imply that less memory is used. It&amp;rsquo;s characterized by eight sub-nodes for each node and has only one particle in each leaf. The code decides to open a leaf according to a certain leaf opening criterion based on the estimated force error. The force for distant groups of particles is approximated with the multipole (here octopole) of the tree node and the error depends on the dimensions and the distances of the node considered.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PM part&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The PM part of the code is used to calculate the long-range forces. The algorithm is something like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CIC (cloud-in-cell) assignment is used to construct the mass density field on to the mesh from the information on the particles&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;the discrete FT of the mesh is multiplied for the Green function for the potential in periodic boundaries (modified with the exponential truncation for the force splitting)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;deconvolution for the CIC kernel twice: the first for the smoothing effect of CIC assignment, the second for the force interpolation&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathrm{FT}^{-1}$ to obtain the potential on the mesh&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;finite differentiate the potential to obtain the forces&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;interpolate the forces to the particles positions using CIC&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note: real-to-complex FT are used to save times and memory respect to full complex transforms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Time step&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This type of code has a large dynamic range in time scale, from the denser regions where the evolution is rapid to the less denser regions in which the evolution occur slower so we can describe it with larger time resolution. In this scenario evolving all particles with the smallest time-scale is a waste of time and computational resources. Because using different time-steps for each particle add instabilities to the system, Gadget-2 separates time-step between long-range (longer time step) and short-range (shorter time step) force computations. The perturbation of the system for different time-steps is related to the symplectic nature of the system, but I still have not understood what it really means and implies! I know that it refers to the phase space volume and has effect on the information conservation. May be in the future I&amp;rsquo;ll write a post about this!&lt;br /&gt;
Despite these arguments, sometimes individual time step are allowed because they perturb the system but not the symplecticity of the single particle.&lt;br /&gt;
In the normal integration mode time-steps are discretized in a power of two hierarchy and particles can always move to smaller time steps but to longer time steps only in subsequent step, synchronized with higher time-steps. Alternatively the code can populate time-steps discretizeing them as integer multiples of the minimum time-step among the particles set. This lead to a more homogeneous distribution of particles across the time-line which can simplify work load balancing.&lt;br /&gt;
The integration is performed using the &lt;a href=&#34;http://en.wikipedia.org/wiki/Leapfrog_integration&#34; target=&#34;_blank&#34; title=&#34;Leapfrog method&#34;&gt;leapfrog method&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parallelization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Usually the parallelization distributes particles across the CPUs using an orthogonal domain decomposition but in this way the trees built-in each domain depend on the domain geometry. Because the force depend on the tree (through the multipole expansion of the mass distribution) the force can be different if you change the number of processors.&lt;br /&gt;
Gadget-2 introduce a space-filling fractal, the Peano-Hilber (PH) curve to map 3D space into a 1D curve that encompasses all the particles. Now the PH curve can be cut and each piece assigned to a CPU and in this way the force is independent of the processors number. If you cut every segment in eight pieces recursively you find again the tree decomposition, so there is a close correspondence between the decomposition obtained with the BH oct-tree and that of the PH curve.&lt;br /&gt;
The PH curve has some remarkably properties, for example points that are close along the 1D PH curve are in general close in 3D space, so the mapping preserves locality and if we cut the PH curve into segments of a certain length we obtain a domain decomposition which has the property that the spatial domains are simply connected and quite &amp;ldquo;compact&amp;rdquo; (i.e., they tend to have small surface-to-volume ratios and low aspect ratio, a highly desirable property for reducing communication costs with neighbouring domains and for speeding up the local computation).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Operations scheme&lt;/strong&gt;&lt;br /&gt;
Here a brief scheme on how the short range force calculation works on multiple processors. The PM computation uses the &lt;a href=&#34;http://www.fftw.org/fftw2_doc/fftw_4.html&#34; target=&#34;_blank&#34; title=&#34;Parallel FFTWs&#34;&gt;parallel FFTWs&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Compute the PH key for each particle&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sort the keys locally and split the PH curve into segments&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adjust the sorted segments to a global sort, splitting and joining segments if needed, with little communication&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Assign the particles to the processes&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Construct a BH tree for the particles of each processors representing particles on other processors with pseudo-particles (acting like placeholders)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;During the tree traverse (e.g. in processor A) these pseudo-particles cannot be opened, the are flagged and inserted into a list that collects all the particles that are to be sent (=requested) to the other processors (e.g. to processor B)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Processor B traverse again its local tree and send back the resulting force contribution to processor A&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Learning C from simulations, #3: C horrors!</title>
      <link>http://brunettoziosi.eu/posts/learning-c-from-simulations-3-c-horrors/</link>
      <pubDate>Mon, 20 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/learning-c-from-simulations-3-c-horrors/</guid>
      <description>&lt;p&gt;Yeah, this is post #3! Post #2 is &amp;ldquo;work in progress&amp;rdquo; and it will be on FFTs!&lt;/p&gt;

&lt;p&gt;Today I was trying to understand what this piece of code do:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for(i = 0; i &amp;lt; Nmesh / 2; i++)
    {
      for(j = 0; j &amp;lt; i; j++)
 seedtable[i * Nmesh + j] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i + 1; j++)
 seedtable[j * Nmesh + i] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i; j++)
 seedtable[(Nmesh - 1 - i) * Nmesh + j] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i + 1; j++)
 seedtable[(Nmesh - 1 - j) * Nmesh + i] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i; j++)
 seedtable[i * Nmesh + (Nmesh - 1 - j)] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i + 1; j++)
 seedtable[j * Nmesh + (Nmesh - 1 - i)] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i; j++)
 seedtable[(Nmesh - 1 - i) * Nmesh + (Nmesh - 1 - j)] = 0x7fffffff * gsl_rng_uniform(random_generator);

      for(j = 0; j &amp;lt; i + 1; j++)
 seedtable[(Nmesh - 1 - j) * Nmesh + (Nmesh - 1 - i)] = 0x7fffffff * gsl_rng_uniform(random_generator);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;!-- TEASER_END --&gt;    

&lt;p&gt;It&amp;rsquo;s a piece of the source of N-GenIC, Springel&amp;rsquo;s ICs generator for &lt;a href=&#34;http://www.gadgetcode.org/right.html&#34; target=&#34;_blank&#34; title=&#34;Gadget2&#34;&gt;Gadget2&lt;/a&gt;. Obviously no comments were present and I have no experience of how those codes work. I know that this is a way to fill the &lt;code&gt;seedtable&lt;/code&gt; array, maybe a matrix that provides random seeds for the FFTs or to generate the [latex]delta[/latex]s for the realization of the density field. This array is stored in 1D so to access the elements we have to do some magic with indices. Trying to understand how the matrix is filled and how the indices works, and to practice with C I&amp;rsquo;ve wrote this piece of code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;math.h&amp;gt;

int i = 0, j = 0;
int N = 10;

int main(int argc, char **argv){
  for(i = 0; i &amp;lt; N/2; i++){
    printf(&amp;quot;i = %in&amp;quot;, i);
    for(j = 0; j &amp;lt; i; j++)
      printf(&amp;quot;t j= %in&amp;quot;, j);
      if(!(i * N + j))
 printf(&amp;quot;j doesn&#39;t existn&amp;quot;);
      printf(&amp;quot;tt i * Nmesh + j = %in&amp;quot;,  i * N + j);
  /*
    a lot of commented code from the code above
  */
  }
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result was&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;i = 0
j doesn&#39;t exist
                 i * Nmesh + j = 0
i = 1
         j= 0
                 i * Nmesh + j = 11
i = 2
         j= 0
         j= 1
                 i * Nmesh + j = 22
i = 3
         j= 0
         j= 1
         j= 2
                 i * Nmesh + j = 33
i = 4
         j= 0
         j= 1
         j= 2
         j= 3
                 i * Nmesh + j = 44
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;clearly wrong.&lt;br /&gt;
So I&amp;rsquo;ve modified the code (thanks to my coworker) to print &lt;code&gt;j&lt;/code&gt; and the expression in both the lines, and the result was&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;i = 0
j doesn&#39;t exist
         j= 0, i * Nmesh + j = 0
i = 1
         j= 0, i * Nmesh + j = 10
         j= 1, i * Nmesh + j = 11
i = 2
         j= 0, i * Nmesh + j = 20
         j= 1, i * Nmesh + j = 21
         j= 2, i * Nmesh + j = 22
i = 3
         j= 0, i * Nmesh + j = 30
         j= 1, i * Nmesh + j = 31
         j= 2, i * Nmesh + j = 32
         j= 3, i * Nmesh + j = 33
i = 4
         j= 0, i * Nmesh + j = 40
         j= 1, i * Nmesh + j = 41
         j= 2, i * Nmesh + j = 42
         j= 3, i * Nmesh + j = 43
         j= 4, i * Nmesh + j = 44
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;wrong again!&lt;/p&gt;

&lt;p&gt;The key is the second &lt;code&gt;for&lt;/code&gt; statement, without the brackets. It was difficult to me to see this because C allows a for statement without brackets evaluating only the first line into the loop, and there were a lot of loop of one line commented into the code. The correct code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;math.h&amp;gt;

int i = 0, j = 0;
int N = 10;

int main(int argc, char **argv){
  for(i = 0; i &amp;lt; N/2; i++){
    printf(&amp;quot;i = %in&amp;quot;, i);
    for(j = 0; j &amp;lt; i; j++){
      printf(&amp;quot;t j= %i, i * Nmesh + j = %in&amp;quot;, j, i * N + j);
      if(!(i * N + j))
 printf(&amp;quot;j doesn&#39;t existn&amp;quot;);
      printf(&amp;quot;t j= %i, i * Nmesh + j = %in&amp;quot;, j, i * N + j);
  /*
    a lot of commented code from the code above
  */
    }
  }
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;works right!&lt;br /&gt;
Obviously the Python version I&amp;rsquo;ve wrote before was perfect the first time I wrote it.!:P In Python, due to the mandatory indentation (and without those terrible brackets!:P) it&amp;rsquo;s straightforward to understand what belong to a loop and what doesn&amp;rsquo;t!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From binaries to HDF5 using Python</title>
      <link>http://brunettoziosi.eu/posts/from-binaries-to-hdf5-using-python/</link>
      <pubDate>Fri, 02 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/from-binaries-to-hdf5-using-python/</guid>
      <description>&lt;p&gt;I have used this script to convert the Millennium II data from the unformatted fortran binary formato to the DF5 one.&lt;br /&gt;
The core of the script is a module (&lt;code&gt;modified_read_snapshots&lt;/code&gt;) built on the basis of a script kindly provided by &lt;a href=&#34;http://mbk.ps.uci.edu/index.html&#34; target=&#34;_blank&#34; title=&#34;Mike Boylan-Kolchin&#34;&gt;Mike Boylan-Kolchin&lt;/a&gt; from the group that perform the Millennium II simulation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python    

import time
import kd3hdf5
import tables as tb
import modified_read_snapshots as rs

t = time.time()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The usual imports and time initialization!:P&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def bin2hdf5(bin_file, h5_file, tree = False):
    snap = rs.read_snapshot(bin_file)
    h5f = kd3hdf5.KDTree(h5_file, &#39;w&#39;)
    h5f.data_store(snap[&#39;pos&#39;])
    if tree == True:
        h5f.tree_build
    h5f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function accept as arguments the name of the binary file, the name of the HDF5 file to be created and give the user the possibility to create a KDTree with the data. By default it won&amp;rsquo;t create this tree. If no KDTree must be created the function only uses the part of the &lt;code&gt;kd3hdf5&lt;/code&gt; module that store the data into the HDF5 file. We will have a brief view of this at the end of the post.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def main():
    print &amp;quot;start&amp;quot;
    for i in [0, 10, 100, 200, 511]:
        t2 = time.time()
        print &amp;quot;Loop &amp;quot;, i
        t3 = time.time()
        bin2hdf5(&#39;../binary/snap_newMillen_subidorder_067.&#39;+str(i), &#39;../hdf5/data_&#39;+str(i))
        print &amp;quot;Loop &amp;quot;, i, &amp;quot; finished in &amp;quot;, time.time()-t2

    print &amp;quot;That&#39;s all folks, in &amp;quot;, time.time()-t, &amp;quot;!!!&amp;quot;

if __name__ == &amp;quot;__main__&amp;quot;:
    main()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing more than calling the previous function on the data files looping on their names!:)&lt;br /&gt;
Respect to the other posts here we make use of the &lt;code&gt;main&lt;/code&gt; function but is nothing extraordinary!:P&lt;/p&gt;

&lt;p&gt;The code from the &lt;code&gt;kd3hdf5&lt;/code&gt; module is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class KDTree(object):
    #Docs [...]

    def __init__(self, filename, mode):
        if mode == &#39;read&#39; or mode == &#39;r&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;r&amp;quot;)
        elif mode == &#39;append&#39; or mode == &#39;a&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;a&amp;quot;)
        elif mode == &#39;build&#39; or mode == &#39;w&#39; or mode == &#39;write&#39;:
            self.h5file = tb.openFile(filename, mode = &amp;quot;w&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This provide the creation of the object, linked to an HDF5 file and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def data_store(self, data):
        t = time.time()
        self.h5file.createArray(self.h5file.root, &#39;data&#39;, np.asarray(data), title=&#39;data&#39;)
        self.h5file.root.data._v_attrs.n_elements = data.shape[0]
        self.h5file.root.data._v_attrs.m_dimensions = data.shape[1]
        self.h5file.root.data._v_attrs.maxes = np.amax(data,axis=0)   # maxes and mins for each coord
        self.h5file.root.data._v_attrs.mins = np.amin(data,axis=0)
        print self.h5file.root.data._v_attrs.n_elements, &amp;quot; Stored in &amp;quot;, time.time()-t, &amp;quot;seconds.&amp;quot;
        t = time.time()
        self.h5file.root.data.flush()
        print time.time()-t, &amp;quot; seconds to commit changes.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fill the file with the data and some metadata (table dimension and maxes and mins of the data).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cosmological simulations #7: Limitations and some considerations</title>
      <link>http://brunettoziosi.eu/posts/cosmological-simulations-7-limitations-and-some-considerations/</link>
      <pubDate>Sun, 13 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/cosmological-simulations-7-limitations-and-some-considerations/</guid>
      <description>

&lt;h2 id=&#34;limitations:115&#34;&gt;Limitations&lt;/h2&gt;

&lt;p&gt;In the previous posts we encountered some of the limitations of cosmological&lt;br /&gt;
simulations. Let&amp;rsquo;s review these in detail.&lt;br /&gt;
First, we can consider a simulation composed of a finite box in a bigger space but to represent a real system, this box shouldn&amp;rsquo;t be isolated so we use the periodic boundary conditions (&lt;a href=&#34;http://brunettoziosi.blogspot.it/2011/11/cosmological-simulations-2-how.html&#34; target=&#34;_blank&#34; title=&#34;Cosmological simulations #2: how?&#34;&gt;here&lt;/a&gt;). This means that all the space around the box is filled with images of the box itself: a particle that leaves the box from one side will come in&lt;br /&gt;
from the opposite side.&lt;/p&gt;

&lt;p&gt;Second, the mass inside the box is not continuous. Instead, it is made by particles of mass of the order of $10^9$ solar masses. These particles represent collisionless fluid elements (made by a huge quantity of real particles) with a certain&lt;br /&gt;
volume and can&amp;rsquo;t be treated as solid spheres. When two simulation particles are&lt;br /&gt;
separated by a distance smaller than the radius of the volumes they represents&lt;br /&gt;
they must feel less than the force coming from the entire mass (thanks to the&lt;br /&gt;
Gauss/Birkhoff&amp;rsquo;s theorem). To do this we soften (read &amp;ldquo;we reduce&amp;rdquo;) the force at&lt;br /&gt;
such small scales (&lt;a href=&#34;http://brunettoziosi.blogspot.it/2011/11/cosmological-simulations-2-how.html&#34; target=&#34;_blank&#34; title=&#34;Cosmological simulations #2: how?&#34;&gt;here&lt;/a&gt;). Third, time is not continuous and its discreteness was also treated (&lt;a href=&#34;http://brunettoziosi.blogspot.it/2011/11/cosmological-simulations-4-moving.html&#34; target=&#34;_blank&#34; title=&#34;Cosmological simulations: #4: Moving the particles!&#34;&gt;here&lt;/a&gt;) with some&lt;br /&gt;
criteria to decide the time steps.&lt;br /&gt;
Until now, however, we haven&amp;rsquo;t consider the effects of taking into account&lt;br /&gt;
initial density fluctuations over a range of scales that is finite. In&lt;br /&gt;
addition to this, the finite size of the box pose a limit on the force&lt;br /&gt;
resolution, because fluctuations on scales bigger than the box side will not&lt;br /&gt;
included in the simulation due to the way the Fourier transforms act on a&lt;br /&gt;
period box. Some tests in literature show that the exclusion of small&lt;br /&gt;
scales shouldn&amp;rsquo;t affect too much large scales when they reach the non linear&lt;br /&gt;
regime but this not holds for the exclusion of large scales, those scales bigger&lt;br /&gt;
than the box side. Following Bagla, the large scale exclusion should not&lt;br /&gt;
disturb the formation of small haloes but could change their distribution.&lt;br /&gt;
This effect will appear as an underestimation of the correlation function. Bagla&lt;br /&gt;
finds that the best way of quantifying the effects of long wave modes is to&lt;br /&gt;
check whether including them in the simulation will change the number of&lt;br /&gt;
massive haloes or not and this can be estimated using the Press-Schecther mass&lt;br /&gt;
function.&lt;br /&gt;
In Tormen&amp;amp;Bertschinger (1996) the missing power on large scales will cause&lt;br /&gt;
something like a statistical cosmic bias decreasing the number of high-density&lt;br /&gt;
regions, the strength of the clustering and the amplitude of the peculiar&lt;br /&gt;
velocities.&lt;br /&gt;
Methods have been developed to take the missing &amp;ldquo;larger than the box&amp;rdquo; wave modes&lt;br /&gt;
into account and we will have a look on these in a future post.&lt;/p&gt;

&lt;h2 id=&#34;some-considerations:115&#34;&gt;Some considerations&lt;/h2&gt;

&lt;p&gt;As we have seen (&lt;a href=&#34;http://brunettoziosi.blogspot.it/2011/11/cosmological-simulations-1-why-and-what.html&#34; target=&#34;_blank&#34; title=&#34;Cosmological simulations #1: why and what?&#34;&gt;here&lt;/a&gt;) N-body cosmological simulations&lt;br /&gt;
are useful to understand aspects of non-linear gravitational clustering,&lt;br /&gt;
since it&amp;rsquo;s not possible to carry out laboratory experiments in gravitational&lt;br /&gt;
dynamics and the analytic models fail when the system reach the non linear&lt;br /&gt;
regime, i.e. when the density contrast overcome the unity. Related with&lt;br /&gt;
cosmological simulations there are a pair of aspects that Bagla underlines in its&lt;br /&gt;
articles that interesting to consider.&lt;br /&gt;
The first issue is whether or not the gravitational clustering&lt;br /&gt;
erase memory of initial conditions. Is there a one-to-one correspondence between&lt;br /&gt;
some characterization of initial perturbations and the final state?&lt;br /&gt;
N-body simulations shows that gravitational clustering does not erase memory of&lt;br /&gt;
the initial conditions, the final power spectrum is a function of the initial&lt;br /&gt;
power spectrum and this relationship can be written as a one-step mapping and&lt;br /&gt;
the functional form of this mapping depends on the initial power spectrum.&lt;br /&gt;
However density profiles of massive haloes have a form independent of&lt;br /&gt;
initial conditions but there is a considerable scatter in density profiles&lt;br /&gt;
obtained from N-body simulations and it is difficult to state whether a given&lt;br /&gt;
functional form is always the best fit or not. I must admit that these last concepts are not very clear to me at the moment, and that I trust Bagla but I will deepen them as soon as possible to be able to comfortably master them.&lt;br /&gt;
The second question is if it is possible to predict the masses and distribution&lt;br /&gt;
of haloes that form as a result of gravitational clustering.&lt;br /&gt;
The initial density field is taken to be a Gaussian random field and for&lt;br /&gt;
hierarchical models the simple assumption that each peak undergoes collapse&lt;br /&gt;
independent of the surrounding density distribution can be used to estimate the&lt;br /&gt;
mass function and several related quantities but N-body simulations shows that&lt;br /&gt;
this simple set of approximations is incorrect. However, the resulting mass&lt;br /&gt;
function estimation is fairly accurate over a wide range of masses. Merger rates&lt;br /&gt;
can be thus computed using the extended Press-Schecther formalism. Modifying&lt;br /&gt;
some of this assumption can lead to improved predictions.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;References&lt;/em&gt;:&lt;br /&gt;
&lt;ul&gt;&lt;br /&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ias.ac.in/currsci/apr102005/1088.pdf&#34; target=&#34;_blank&#34; title=&#34;J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status&#34;&gt;J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://adsabs.harvard.edu/abs/1991ComPh...5..164B&#34; target=&#34;_blank&#34; title=&#34;J.S. Bagla and T. Padmanabham, Cosmological N-body simulations&#34;&gt;J.S. Bagla and T. Padmanabham, Cosmological N-body simulations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://iopscience.iop.org/0004-637X/472/1/14&#34; target=&#34;_blank&#34; title=&#34;G. Tormen and E. Bertschinger, Adding long wavelenght modes to an N-body simulation&#34;&gt;Giuseppe Tormen and Edmund Bertschinger, Adding long wavelenght modes to an N-body simulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://adsabs.harvard.edu/full/1997MNRAS.286...38C&#34; target=&#34;_blank&#34; title=&#34;S. Cole, Adding long-wavelength power to N-body simulations&#34;&gt;S. Cole, Adding long-wavelength power to N-body simulations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cosmological simulations #1: why and what?</title>
      <link>http://brunettoziosi.eu/posts/cosmological-simulations-1-why-and-what/</link>
      <pubDate>Wed, 02 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/cosmological-simulations-1-why-and-what/</guid>
      <description>&lt;p&gt;This is the first of a series of posts dedicated to cosmological simulations!&lt;br /&gt;
&lt;br /&gt;
I do this because, as stressed by my PhD advisor,
I need to practice in explaining in a clear way specialized knowledge and in
linking it with its background and motivations. Also I would like to keep track
of my progress and of what I&amp;rsquo;m learning!&lt;br /&gt;
&lt;br /&gt;
So, let&amp;rsquo;s start with &amp;ldquo;Why we need cosmological simulations? What are they?&amp;rdquo;!&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s have a look at the night sky: if we are so lucky to be in a dark site like
the mountains or a desert, we can see the stars, and our Galaxy, The Milky Way.
With a little telescope we can also see other galaxies, like Andromeda. We can
find them in group of galaxies or clusters of galaxies. On bigger scales these
form sheets and filaments as you can see in the figure (taken from the Millenium
simulation).&lt;br /&gt;
&lt;br /&gt;
&lt;p  align=&#34;center&#34; &gt;&lt;img alt=&#34;&#34; class=&#34;alignnone&#34; height=&#34;400&#34; src=&#34;../../files/supercube.jpg&#34; title=&#34;A figure of the output of the Milleniun Simulation&#34; width=&#34;600&#34; /&gt;&lt;/p&gt;&lt;br /&gt;
&lt;br /&gt;
Theoretical models, widely accepted, say that these structures formed from initial
small density fluctuations in the matter, grew under their self gravity, lead by a
special type of matter that can interact only through gravity, called &amp;ldquo;dark matter&amp;rdquo;.&lt;br /&gt;
&lt;br /&gt;
A homogeneous and isotropic universe is described by the
&lt;a href=&#34;http://en.wikipedia.org/wiki/Friedmann_equations&#34; target=&#34;_blank&#34; title=&#34;Friedmann equations&#34;&gt;Friedmann equations&lt;/a&gt; in general relativity. Until the density fluctuations are small we can treat them as perturbations in a Friedmann universe. If the matter under consideration is non-relativistic (and it is!) and on scales smaller than those of the observable universe we can study the evolution of these perturbations in the Newtonian limit. We also consider gravity as the only interaction to be taken into account for now. On large scales (more than some &lt;a href=&#34;http://en.wikipedia.org/wiki/Parsec&#34; target=&#34;_blank&#34; title=&#34;megaparsecs&#34;&gt;kiloparsecs&lt;/a&gt;) this is not a bad approximation as gravity is the only interaction working efficiently in driving the evolution of the fluctuations on that scales.&lt;br /&gt;
&lt;br /&gt;
We have good analytic models for the evolution of these perturbation until the
density contrast (we call density contrast the quantity &lt;code&gt;$\delta(\vec x,t)=(\rho(\vec x, t)-\rho_{bg}(\vec x, t))/\rho_{bg}(\vec x, t)$&lt;/code&gt;
where &lt;code&gt;$\rho_{bg}(\vec x, t)$&lt;/code&gt; is the background density at given position and time)
is smaller than the unity.
This is the &amp;ldquo;linear regime&amp;rdquo;.
We call it &amp;ldquo;linear&amp;rdquo; because we can describe the system using first order
perturbations and the solutions we find are in good agreement with the exact solutions.
When the density contrast reaches and exceeds the unity, perturbations become
&amp;ldquo;non-linear&amp;rdquo; and the analytic models break.&lt;br /&gt;
&lt;br /&gt;
Cosmological N-body simulations are then the only way we have to study perturbations
in the non-linear regime. Note that when the fluctuations collapse forming what we
call a &amp;ldquo;halo&amp;rdquo;, the density contrast is of the order of 100. Cosmological simulations
are called &amp;ldquo;N-body&amp;rdquo; because they involve the calculation of the (gravitational)
force among all the bodies (particles) of the simulation.&lt;br /&gt;
&lt;br /&gt;
With cosmological simulations we can also play with the initial conditions of our
model of the universe, change its contents, &amp;hellip; and see what will happen. It&amp;rsquo;s the
closest thing to a laboratory that we have.&lt;br /&gt;
&lt;br /&gt;
Using different techniques is also possible to include non-gravitational effects
in the simulations, such as gas hydrodynamics, star formation, and so on.&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;em&gt;Reference&lt;/em&gt;:&amp;nbsp;&lt;a href=&#34;http://www.ias.ac.in/currsci/apr102005/1088.pdf&#34; target=&#34;_blank&#34; title=&#34;J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status&#34;&gt;J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cosmological simulations #2: how?</title>
      <link>http://brunettoziosi.eu/posts/cosmological-simulations-2-how/</link>
      <pubDate>Wed, 02 Nov 2011 00:00:00 +0000</pubDate>
      
      <guid>http://brunettoziosi.eu/posts/cosmological-simulations-2-how/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s try now to understand how simulations can be set up.&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;First of all note that dark matter density dominates over ordinary (baryonic) matter at all times and we expect that ordinary matter follows the gravity of dark matter on large scales, so we can start considering only dark matter in our simulation.&lt;br /&gt;
Moreover, cosmological simulations differ from other N-body simulations because they should to be able to manage comoving coordinates, i.e. coordinates that expand with the universe, since the universe is expanding.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In a cosmological simulation every particle represents a large number of dark matter particles, so the interaction between two particles represents the interaction between two &amp;ldquo;fluid elements&amp;rdquo;, and this must be collisionless.&lt;br /&gt;
Moreover, a point mass in the simulation represents a mass in a certain volume, and this volume change during the simulation due to the universe expansion and the clustering. This also imply that, at scales comparable to their physical size, they should feel less gravitational force than two point particles. When the two particles are separated by a distance comparable to the dimension of the fluid elements they represents, these would not feel the gravity of all the mass associated with the particles, as suggested by the Gauss theorem. This is because when you are into a spherical distribution of mass you only experience the gravitational force of the mass inside the radius corresponding to your distance from the center.&lt;br /&gt;
To take care of this we decrease the strength of the force at small scales.&lt;br /&gt;
Some example:&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;&lt;br /&gt;
&lt;li&gt;GIF2: 6.6 kpc/h softening with a mean interparticle separation 110 Mpc/h / 400 particles = 275 kpc/h&lt;/li&gt;
&lt;br /&gt;
&lt;li&gt;Millennium: 5 kpc/h softening with a mean interparticle separation 500 Mpc/h / 2160 particles = 231 kpc/h&lt;/li&gt;
&lt;br /&gt;
&lt;li&gt;Millennium II: 1 kpc/h softening with a mean interparticle separation 100 Mpc/h / 2160 particles = 46 kpc/h&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is called &amp;ldquo;force softening&amp;rdquo;. There are several ways to implement this and one should pay attention because a softening length smaller than the interparticle separation would lead to two-body relaxation problems. With the term &amp;ldquo;two-body relaxation&amp;rdquo; we mean the effects that arise when to particles mainly feels each other instead of feeling the global field, or feel more mass than what they should (they feel the mass of the entire fluid elements instead of the mass inside the radius corresponding to their distance). Usually the effects are of two types: the two particles can start to orbit faster and faster with decreasing separation, or they can experience a gravitational sling and be pulled apart (two-body scattering).&lt;br /&gt;
The two-body relaxation modifies the density profiles of dark matter haloes (the dark matter structures formed by gravitational collapse of dark matter) making them smoother. The form of the softening is also important: historically there are two main softening, one is Gaussian and the other is a cubic spline.  &lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now we can start analyzing the structure of a cosmological N-body code. It consists in two main parts: the first computes the force field for a given configuration of particles, the second moves the particles according to the computed force field. The two modules are called at each step to ensure that the force field and the particles trajectories evolve in a self-consistent manner. Before starting the simulation we also need to set up the initial conditions and afterwards we have to write the output.&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In setting up our simulation there are some things we should consider.&lt;br /&gt;
Our simulation represents a small box in the whole universe, but it isn&amp;rsquo;t an isolated system so it feels the gravitational field of the rest of the universe. To take account of these we can set up periodic boundary conditions. This implies that space outside the simulation box is tiled it with copies (images) of the box. In this way particles near the edges are attracted not only by the matter in the box but also by the particles in its images.&lt;br /&gt;
&lt;br /&gt;
&lt;table align=&#34;center&#34; cellpadding=&#34;0&#34; cellspacing=&#34;0&#34; class=&#34;tr-caption-container&#34; style=&#34;margin-left: auto; margin-right: auto; text-align: center;&#34;&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td style=&#34;text-align: center;&#34;&gt;&lt;img alt=&#34;&#34; height=&#34;500&#34; src=&#34;http://isaacs.sourceforge.net/phys/images/these-seb/pbc-seb.png&#34; style=&#34;margin-left: auto; margin-right: auto;&#34; title=&#34;Periodic boundary conditions example&#34; width=&#34;500&#34; /&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td class=&#34;tr-caption&#34; style=&#34;text-align: center;&#34;&gt;&lt;span style=&#34;font-size: small; text-align: -webkit-auto;&#34;&gt;Periodic boundary conditions example taken from &lt;a href=&#34;http://isaacs.sourceforge.net/phys/pbc.html&#34;&gt;http://isaacs.sourceforge.net/phys/pbc.html&lt;/a&gt;.&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With periodic boundary conditions one should make sure that there isn&amp;rsquo;t a dominant object in its volume to avoid too large influence by its periodic copies.&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;As written above, we need cosmological simulations to study scales where perturbations are not linear, to compare results with the real universe. To do this we must probe a large range of scales, so the mass of individual particles must be smaller than the mass of the smallest structure of interest. On the other hand the number of particles must be sufficient to cover the range of   masses involved in galaxy clustering. As of 2011 a typical large simulation have of order of billion of particles.&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With such large number of particles the most time consuming operation in the simulation is force calculation; therefore a number of algorithms  have been developed to avoid direct calculations, unfeasible even on the most powerful computer.&lt;br /&gt;
&lt;br /&gt;
&lt;em&gt;References&lt;/em&gt;:&lt;br /&gt;
&lt;ul&gt;&lt;br /&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ias.ac.in/currsci/apr102005/1088.pdf&#34; target=&#34;_blank&#34; title=&#34;J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status&#34;&gt;J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status&lt;/a&gt;&lt;/li&gt;
&lt;br /&gt;
&lt;li&gt;&lt;a href=&#34;http://adsabs.harvard.edu/abs/1991ComPh...5..164B&#34; target=&#34;_blank&#34; title=&#34;J.S. Bagla and T. Padmanabham, Cosmological N-body simulations&#34;&gt;J.S. Bagla and T. Padmanabham, Cosmological N-body simulations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>