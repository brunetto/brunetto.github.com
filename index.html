<!DOCTYPE html><html lang="en">
<head>
    
    <meta charset="utf-8">
    <meta name="description" content="This is a demo site for Nikola.">
    <meta name="author" content="brunetto">
    <title>brunetto's blog | brunetto's blog</title>
    <!-- mathjax_config -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
        },
        displayAlign: 'left', // Change this to 'center' to center equations.
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}}
        }
    });
    </script>
    
        
            <link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
            <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
        
        <link href="assets/css/rst.css" rel="stylesheet" type="text/css">
        <link href="assets/css/code.css" rel="stylesheet" type="text/css">
        <link href="assets/css/colorbox.css" rel="stylesheet" type="text/css">
        <link href="assets/css/theme.css" rel="stylesheet" type="text/css">
        <link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
        <link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
        <link href="assets/css/xkcd.css" rel="stylesheet" type="text/css">
        
    
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]-->
    
        
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
        
    
    

    
    
    
</head>
<body>
<!-- Menubar -->
<div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">

        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </a>

            <a class="brand" href=".">
            brunetto's blog
            </a>
            <!-- Everything you want hidden at 940px or less, place within here -->
            <div class="nav-collapse collapse">
                <ul class="nav">
                    
    
        
            <li><a href="archive.html">Archives</a>
        
    
        
            </li><li><a href="categories/index.html">Tags</a>
        
    
        
            </li><li><a href="stories/about.html">About</a>
        
    
        
            </li><li><a href="rss.xml">RSS</a>
        
    

                </li></ul>
                
                    
<!-- Custom search with google-->
<form id="search" action="http://google.com/search" method="get" class="navbar-form pull-left">
<input type="hidden" name="q" value="site:brunetto.github.io">
<input type="text" name="q" maxlength="255" results="0" placeholder="Search">
</form>
<!-- End of custom search -->

                
                <ul class="nav pull-right">
                
                
                
                
                </ul>
            </div>
        </div>
    </div>
</div>
<!-- End of Menubar -->
<div class="container-fluid" id="container-fluid">
    <!--Body content-->
    <div class="row-fluid">
    <div class="span2"></div>
    <div class="span8">
    
    
        <div class="postbox">
        <h1><a href="posts/python-parallel-job-manager.html">Python parallel job manager</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-04 00:00
        </big></p>
        <hr>
        <p>he final version of the code for my master thesis was the most embarrassing parallel code you can think... just a serial code to be run on different slices of the dataset. I choose this solution because it permits to manage the different resources (memory, processors, ...) on the different machines available without any restriction. Moreover, this solution has no communication between the processes, with better performances and all the processes are independent, so it minimize the damages due to any failure.<br>
<!--more--><br>
At this step, however, I didn't know how to manage the different processes in a comfortable way. My requirements were:<br>
</p><ul>
<li>to start only one process that will take care of starting the right code on the right data-slice</li>
<li>the possibility to start "n" processes depending on the number of processors and memory available (in the actual code this is done by hand)</li>
<li>the code should be able to start a new process when one of the previous processes end</li>
</ul>
<div>
<span style="font-size: small;"><span class="Apple-style-span" style="line-height: 24px;">Hereafter I expose and comment the complete "template" for this Python code as I wrote it.</span></span></div>
<br>
<div>
<pre>#!/bin/env python
<p>import sys, os
from subprocess import Popen, PIPE
from multiprocessing import Process, Queue</p>
<p>"""This script starts n_procs processes that in parallel take the
number of the data file from a common queue and with a loop apply the
analysys code to the data starting it with a bash command using Popen
"""</p></pre>
<br></div>
<div>
The first line is the declaration of the interpreter to be used for this script, in this case Python. After that we import some libraries and modules used in this code. The last lines, inside the triple quotes, are the documentation string of the code. Python in fact has a self-doc system that can be used to understand what a piece of code does and how it works.</div>
<br>
<div>
n_procs = 10 # number of processes to be started<br>
<pre>file_1 = None
file_2 =  "mill2_fof_sorted.h5"
m_factor = 1    # How many random more than data
start_slice = 0 
end_slice = 99</pre>
<br>
Here we set some parameters: the number of processes to start (set by hand), the two files to use in the analysis, how many random particles we use more than the data particles and the limits in the data slice to analyze. In this case we want to correlate the data in <code>mill2_fof_sorted.h5</code> with the data contained in the slices between slice 0 and slice 99. file_1 will be replaced after with the right name. This analysis will be carry out using 10 processes at each time. As a process end the code will take care of starting a new process.<br>
<pre>def starter(input, output):
    """Start the code processes one after the other"""
    while input.qsize() != 0:
        item = input.get()
        file_1 = "mill2sort-"+str(item[0])     <br>
        cmd = "/opt/epd-7.0-2-rh5-x86_64/bin/python -u \
              ../serial.py --file_1 "+file_1+" --file_2 "+file_2+\
            " -l 400 -n 0 --m_factor "+str(m_factor)+" \
             --slicing --log ../logs/"+file_1+"-"+file_2
<div class="code"><pre>    <span class="nl">try:</span>
        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">getpid</span><span class="p">()</span>
        <span class="n">pid_cmd</span> <span class="o">=</span> <span class="err">'</span><span class="n">echo</span> <span class="s">"'+str(item[0])+'"</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="err">'</span><span class="o">+</span><span class="n">str</span><span class="p">(</span><span class="n">pid</span><span class="p">)</span><span class="o">+</span><span class="err">'</span><span class="p">.</span><span class="n">log</span><span class="err">'</span>
        <span class="n">os</span><span class="p">.</span><span class="n">system</span><span class="p">(</span><span class="n">pid_cmd</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">Popen</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="n">True</span><span class="p">,</span> <span class="n">close_fds</span><span class="o">=</span><span class="n">True</span><span class="p">).</span><span class="n">wait</span><span class="p">()</span>

    <span class="nl">except:</span>
        <span class="n">print</span> <span class="s">"Popen/os.system not done, exit..."</span>
        <span class="n">sys</span><span class="p">.</span><span class="n">exit</span><span class="p">()</span><span class="o">&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</pre></div>


<p><br></p></pre></div>
<br>
This piece of code defines the function that will start the processes. It's called <code>started</code> and it takes <code>input</code> and <code>output</code> as arguments. These are two "queue objects", they can be filled and emptied in the FIFO way. The starter has a while loop that check if the queue is empty, if not it takes the next elements. This is the number of the slice to be used by the analysis code and with it we build the name of the file to be opened. <code>cmd</code> is the string we use to start the analysis code with some options (<code>serial.py</code> is the actual "cool" name I gave to my code!:P).<br>
The <code>try-exept</code> syntax is the particular Python way to manage the possible errors in the execution, giving the ability to the programmer to handle possible problems (exceptions).<br>
So we catch the pid of the starter and save into its log the number of sliced it start and pass to the <code>Popen</code> (process-open) command the string to start the analysis process telling it to wait the end of the process. If something goes wrong we print that there were some errors and exit the code in a clean way.<br>
<pre></pre>
<pre>def fill_queue(task_queue, start_slice, end_slice):
    """Fill the queue"""
    for i in range(start_slice, end_slice, 1):
        task_queue.put([i])
    return task_queue</pre>
<br>
This functions only fill the queue with the number of the sliced to be used.<br>
<pre></pre>
<pre>def status(proc):
    """Check for processes status"""
    if proc.is_alive()==True:
        return 'alive'
    elif proc.is_alive()==False:
        return 'dead'
    else:
        return proc.is_alive()</pre>
<br>
This piece of code check the status (dead or alive) of one process (<code>proc</code> is the process object... yeah, in Python everything is an object!)<br>
<pre>input_queue = Queue()
output_queue = Queue()
<p>try:
    input_queue = fill_queue(input_queue, start_slice, end_slice)
except:
    print "Queue not filled, exit..."
    sys.exit()</p>
<p>procs = []    # processes container</p></pre>
<br>
Now we create the empty queues and (try to) fill them, and create the container for the processes objects.<br>
<pre>try:
    for i in range(n_procs):
        print "Process loop ", i
        procs.append(Process(target=starter, args=(input_queue, output_queue)))
except:
    print "Creating processes not complete, exit..."
    sys.exit()
<p>try:
    for i in procs:
        i.start()
except:
    print "Start processes not complete, exit..."
    sys.exit()</p>
<p>for i in procs:
    print "Process ", i," @ " , i.pid, " is ", status(i)</p></pre>
<br>
This is the central part of this code: we create the processes objects and put them into the container, start them and check for their status. Everything is inside the <code>try-except</code> environment to check for possible errors and handle them.<br>
In practice we start "n" processes and every process take the number of a slice from the queue and use it to start the analysis code, waiting for its end. When the analysis is finished it takes another number from the queue and start again the code. When the queue is empty everything is automatically switched off.<br>
Future improvements will consider the automatically detection of the hardware resources and the possibility to mail the status of the code.
        <p>
        
            <a href="posts/python-parallel-job-manager.html#disqus_thread" data-disqus-identifier="cache/posts/python-parallel-job-manager.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/cosmological-simulations-1-why-and-what.html">Cosmological simulations #1: why and what?</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-02 00:00
        </big></p>
        <hr>
        <p>This is the first of a series of posts dedicated to cosmological simulations!<br>
<br>
I do this because, as stressed by my PhD advisor, I need to practice in explaining in a clear way specialized knowledge and in linking it with its background and motivations. Also I would like to keep track of my progress and of what I'm learning!<br>
<br>
So, let's start with "Why we need cosmological simulations? What are they?"!<br></p>
<!-- TEASER_END -->

<p>Let's have a look at the night sky: if we are so lucky to be in a dark site like the mountains or a desert, we can see the stars, and our Galaxy, The Milky Way. With a little telescope we can also see other galaxies, like Andromeda. We can find them in group of galaxies or clusters of galaxies. On bigger scales these form sheets and filaments as you can see in the figure (taken from the Millenium simulation).<br>
<br>
<img alt="" class="alignnone" height="400" src="http://upload.wikimedia.org/wikipedia/commons/5/58/AstroMSseqF_063aL_%2818135101%29.jpg" title="A figure of the output of the Milleniun Simulation hosted by Wikipedia" width="600"><br>
<br>
Theoretical models, widely accepted, say that these structures formed from initial small density fluctuations in the matter, grew under their self gravity, lead by a special type of matter that can interact only through gravity, called "dark matter".<br>
<br>
A homogeneous and isotropic universe is described by the <a href="http://en.wikipedia.org/wiki/Friedmann_equations" target="_blank" title="Friedmann equations">Friedmann equations</a> in general relativity. Until the density fluctuations are small we can treat them as perturbations in a Friedmann universe. If the matter under consideration is non-relativistic (and it is!) and on scales smaller than those of the observable universe we can study the evolution of these perturbations in the Newtonian limit. We also consider gravity as the only interaction to be taken into account for now. On large scales (more than some <a href="http://en.wikipedia.org/wiki/Parsec" target="_blank" title="megaparsecs">kiloparsecs</a>) this is not a bad approximation as gravity is the only interaction working efficiently in driving the evolution of the fluctuations on that scales.<br>
<br>
We have good analytic models for the evolution of these perturbation until the density contrast (we call density contrast the quantity $\delta(\vec x,t)=(\rho(\vec x, t)-\rho_{bg}(\vec x, t))/\rho_{bg}(\vec x, t)$ where $\rho_{bg}(\vec x, t)$ is the background density at given position and time) is smaller than the unity. This is the "linear regime". We call it "linear" because we can describe the system using first order perturbations and the solutions we find are in good agreement with the exact solutions. When the density contrast reaches and exceeds the unity, perturbations become "non-linear" and the analytic models break.<br>
<br>
Cosmological N-body simulations are then the only way we have to study perturbations in the non-linear regime. Note that when the fluctuations collapse forming what we call a "halo", the density contrast is of the order of 100. Cosmological simulations are called "N-body" because they involve the calculation of the (gravitational) force among all the bodies (particles) of the simulation.<br>
<br>
With cosmological simulations we can also play with the initial conditions of our model of the universe, change its contents, ... and see what will happen. It's the closest thing to a laboratory that we have.<br>
<br>
Using different techniques is also possible to include non-gravitational effects in the simulations, such as gas hydrodynamics, star formation, and so on.<br>
<br>
<br>
<br>
<em>Reference</em>: <a href="http://www.ias.ac.in/currsci/apr102005/1088.pdf" target="_blank" title="J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status">J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status</a></p>
        <p>
        
            <a href="posts/cosmological-simulations-1-why-and-what.html#disqus_thread" data-disqus-identifier="cache/posts/cosmological-simulations-1-why-and-what.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/cosmological-simulations-2-how.html">Cosmological simulations #2: how?</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-02 00:00
        </big></p>
        <hr>
        <p>Let's try now to understand how simulations can be set up.<br>
<br></p>
<p>First of all note that dark matter density dominates over ordinary (baryonic) matter at all times and we expect that ordinary matter follows the gravity of dark matter on large scales, so we can start considering only dark matter in our simulation.<br>
Moreover, cosmological simulations differ from other N-body simulations because they should to be able to manage comoving coordinates, i.e. coordinates that expand with the universe, since the universe is expanding.<br></p>
<!-- TEASER_END -->

<p>In a cosmological simulation every particle represents a large number of dark matter particles, so the interaction between two particles represents the interaction between two "fluid elements", and this must be collisionless.<br>
Moreover, a point mass in the simulation represents a mass in a certain volume, and this volume change during the simulation due to the universe expansion and the clustering. This also imply that, at scales comparable to their physical size, they should feel less gravitational force than two point particles. When the two particles are separated by a distance comparable to the dimension of the fluid elements they represents, these would not feel the gravity of all the mass associated with the particles, as suggested by the Gauss theorem. This is because when you are into a spherical distribution of mass you only experience the gravitational force of the mass inside the radius corresponding to your distance from the center.<br>
To take care of this we decrease the strength of the force at small scales.<br>
Some example:<br></p>
<ul><br>
<li>GIF2: 6.6 kpc/h softening with a mean interparticle separation 110 Mpc/h / 400 particles = 275 kpc/h</li>
<br>
<li>Millennium: 5 kpc/h softening with a mean interparticle separation 500 Mpc/h / 2160 particles = 231 kpc/h</li>
<br>
<li>Millennium II: 1 kpc/h softening with a mean interparticle separation 100 Mpc/h / 2160 particles = 46 kpc/h</li>
</ul>

<p>This is called "force softening". There are several ways to implement this and one should pay attention because a softening length smaller than the interparticle separation would lead to two-body relaxation problems. With the term "two-body relaxation" we mean the effects that arise when to particles mainly feels each other instead of feeling the global field, or feel more mass than what they should (they feel the mass of the entire fluid elements instead of the mass inside the radius corresponding to their distance). Usually the effects are of two types: the two particles can start to orbit faster and faster with decreasing separation, or they can experience a gravitational sling and be pulled apart (two-body scattering).<br>
The two-body relaxation modifies the density profiles of dark matter haloes (the dark matter structures formed by gravitational collapse of dark matter) making them smoother. The form of the softening is also important: historically there are two main softening, one is Gaussian and the other is a cubic spline.  <br>
<br></p>
<p>Now we can start analyzing the structure of a cosmological N-body code. It consists in two main parts: the first computes the force field for a given configuration of particles, the second moves the particles according to the computed force field. The two modules are called at each step to ensure that the force field and the particles trajectories evolve in a self-consistent manner. Before starting the simulation we also need to set up the initial conditions and afterwards we have to write the output.<br>
<br></p>
<p>In setting up our simulation there are some things we should consider.<br>
Our simulation represents a small box in the whole universe, but it isn't an isolated system so it feels the gravitational field of the rest of the universe. To take account of these we can set up periodic boundary conditions. This implies that space outside the simulation box is tiled it with copies (images) of the box. In this way particles near the edges are attracted not only by the matter in the box but also by the particles in its images.<br>
<br>
</p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><img alt="" height="500" src="http://isaacs.sourceforge.net/phys/images/these-seb/pbc-seb.png" style="margin-left: auto; margin-right: auto;" title="Periodic boundary conditions example" width="500"></td></tr>
<tr><td class="tr-caption" style="text-align: center;"><span style="font-size: small; text-align: -webkit-auto;">Periodic boundary conditions example taken from <a href="http://isaacs.sourceforge.net/phys/pbc.html">http://isaacs.sourceforge.net/phys/pbc.html</a>.</span></td></tr>
</tbody></table>
<br>
<p>With periodic boundary conditions one should make sure that there isn't a dominant object in its volume to avoid too large influence by its periodic copies.<br>
<br></p>
<p>As written above, we need cosmological simulations to study scales where perturbations are not linear, to compare results with the real universe. To do this we must probe a large range of scales, so the mass of individual particles must be smaller than the mass of the smallest structure of interest. On the other hand the number of particles must be sufficient to cover the range of   masses involved in galaxy clustering. As of 2011 a typical large simulation have of order of billion of particles.<br>
<br></p>
<p>With such large number of particles the most time consuming operation in the simulation is force calculation; therefore a number of algorithms  have been developed to avoid direct calculations, unfeasible even on the most powerful computer.<br>
<br>
<em>References</em>:<br>
</p><ul><br>
<li><a href="http://www.ias.ac.in/currsci/apr102005/1088.pdf" target="_blank" title="J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status">J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status</a></li>
<br>
<li><a href="http://adsabs.harvard.edu/abs/1991ComPh...5..164B" target="_blank" title="J.S. Bagla and T. Padmanabham, Cosmological N-body simulations">J.S. Bagla and T. Padmanabham, Cosmological N-body simulations</a></li>
</ul>
        <p>
        
            <a href="posts/cosmological-simulations-2-how.html#disqus_thread" data-disqus-identifier="cache/posts/cosmological-simulations-2-how.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/subfile-package-for-latex.html">Subfile package for latex</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-05-13 00:00
        </big></p>
        <hr>
        <p>If you have a complex Latex document and you want to split it in several files, the <a href="http://ctan.org/tex-archive/macros/latex/contrib/subfiles">subfile</a> package can help you.  <br>
The main difference between this and the <code>\input</code> or <code>\import</code> methods is that with <code>subfile</code> you can compile also each file, without need to copy the preamble.    </p>
<!-- TEASER_END -->

<p>What you have to do is to add</p>
<div class="code"><pre><span class="k">\usepackage</span><span class="nb">{</span>subfiles<span class="nb">}</span>
</pre></div>


<p>in the preamble of the master file and</p>
<div class="code"><pre><span class="k">\documentclass</span><span class="na">[tesi.tex]</span><span class="nb">{</span>subfiles<span class="nb">}</span>
<span class="k">\begin</span><span class="nb">{</span>document<span class="nb">}</span>
...
<span class="k">\end</span><span class="nb">{</span>document<span class="nb">}</span>
</pre></div>


<p>in your subfiles.  <br>
Now you can import your subfiles in the master file with
````latex
\subfile{subfile.tex}
<br>  <br>
Sources:<br>
</p><ul><br>
<li><a href="http://en.wikibooks.org/wiki/LaTeX/Multiple_files">http://en.wikibooks.org/wiki/LaTeX/Multiple_files</a></li>
<li><a href="https://help.ubuntu.com/community/LaTeX">How to install in Ubuntu</a></li>
</ul>
        <p>
        
            <a href="posts/subfile-package-for-latex.html#disqus_thread" data-disqus-identifier="cache/posts/subfile-package-for-latex.html">Comments</a>
        
        </p></div>
    
    <div>
<ul class="pager">
  
  
</ul>

    </div>
    <hr>
    
        <script type="text/javascript"> var disqus_shortname = 'brunettosblog'; (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = 'http://' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script>
    

    </div>
    </div>
    <!--End of body content-->
</div>
<div class="footerbox">
    Contents © 2013         <a href="mailto:brunetto.ziosi@gmail.com">brunetto</a> - Powered by         <a href="http://nikola.ralsina.com.ar">Nikola</a>
</div>


    <!-- Social buttons -->
    <div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
    <a class="addthis_button_more">Share</a>
    <ul><li><a class="addthis_button_facebook"></a>
    </li><li><a class="addthis_button_google_plusone_share"></a>
    </li><li><a class="addthis_button_linkedin"></a>
    </li><li><a class="addthis_button_twitter"></a>
    </li></ul>
    </div>
    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script>
    <!-- End of social buttons -->



    
        
            <script src="assets/js/jquery-1.7.2.min.js" type="text/javascript"></script>
            <script src="assets/js/bootstrap.min.js" type="text/javascript"></script>
        
        <script src="assets/js/jquery.colorbox-min.js" type="text/javascript"></script>
        <script src="assets/js/mathjax-onload.js" type="text/javascript"></script>
    


    <script type="text/javascript">jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"80%",maxHeight:"80%",scalePhotos:true});</script>
</body></html>