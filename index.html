<!DOCTYPE html><html lang="en">
<head>
    
    <meta charset="utf-8">
    <meta name="description" content="This is a demo site for Nikola.">
    <meta name="author" content="brunetto">
    <title>brunetto's blog | brunetto's blog</title>
    <!-- mathjax_config -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
        },
        displayAlign: 'left', // Change this to 'center' to center equations.
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}}
        }
    });
    </script>
    
        
            <link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
            <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
        
        <link href="assets/css/rst.css" rel="stylesheet" type="text/css">
        <link href="assets/css/code.css" rel="stylesheet" type="text/css">
        <link href="assets/css/colorbox.css" rel="stylesheet" type="text/css">
        <link href="assets/css/theme.css" rel="stylesheet" type="text/css">
        <link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
        <link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
        <link href="assets/css/xkcd.css" rel="stylesheet" type="text/css">
        
    
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]-->
    
        
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
        
    
    

    
    
    
</head>
<body>
<!-- Menubar -->
<div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">

        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </a>

            <a class="brand" href=".">
            brunetto's blog
            </a>
            <!-- Everything you want hidden at 940px or less, place within here -->
            <div class="nav-collapse collapse">
                <ul class="nav">
                    
    
        
            <li><a href="archive.html">Archives</a>
        
    
        
            </li><li><a href="categories/index.html">Tags</a>
        
    
        
            </li><li><a href="stories/about.html">About</a>
        
    
        
            </li><li><a href="rss.xml">RSS</a>
        
    

                </li></ul>
                
                    
<!-- Custom search with google-->
<form id="search" action="http://google.com/search" method="get" class="navbar-form pull-left">
<input type="hidden" name="q" value="site:brunetto.github.io">
<input type="text" name="q" maxlength="255" results="0" placeholder="Search">
</form>
<!-- End of custom search -->

                
                <ul class="nav pull-right">
                
                
                
                
                </ul>
            </div>
        </div>
    </div>
</div>
<!-- End of Menubar -->
<div class="container-fluid" id="container-fluid">
    <!--Body content-->
    <div class="row-fluid">
    <div class="span2"></div>
    <div class="span8">
    
    
        <div class="postbox">
        <h1><a href="posts/cosmological-simulations-3-force-calculation.html">Cosmological simulations #3: force calculation!</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-13 00:00
        </big></p>
        <hr>
        <p>In the previous posts we wrote about cosmological simulations, why we need them, how they are performed and which are the important things to care about.
Now we are ready to learn the algorithms developed to compute gravitational forces between the particles.</p>
<!-- TEASER_END -->

<h4>Direct summation: PP method</h4>
<p>The raw approach is to calculate forces between all pairs in the simulation. This works well for less than $10^3$. The number of pairs, and therefore the computational time, scales as $N^2$, so this method that is usually unacceptable given the number of particles in a simulation.  <br>
It's difficult to implement periodic boundary conditions in this method (because you have to manage it by hand) and the only convenient way to do this is to use the Ewald summation.  <br>
This method is mostly used to test other methods.</p>
<h4>Tree method</h4>
<p>The disadvantage of the pp-method comes from having to compute the interaction of any new particle with all the others. The tree method, on the contrary, approximate the force of a distant group of particles with the force exerted by only one particle, in the center of mass of the group, with mass equal the total mass of the group. In this way the computation scales as $N\log N$.  <br>
To create the groups the particles are divided and arranged in a tree structure, that is, the initial volume is divided, and every resulting volume divided again. This procedure goes on until in the resulting volumes there's only one particle. In this situation it's very important the "cell acceptance criterion" that decide whether or not a cell is far enough to be used as it is or if it has to be divided into its subvolumes.  <br>
The accuracy and the speed of this method can be improved storing some information about the particles in the volumes (such as moments of the mass distribution, usually the quadrupole).  <br>
Moreover, close particles can share information about distant groups because the force is very similar, and the tree can be parallelized efficiently. However, it's not so easy to consider periodic boundary conditions.</p>
<h4>Fast multipole method</h4>
<p>This method is an improved version of the tree method. It is based on including higher moments of the mass distribution in cells and some other optimizations. This method has a computational costs which scales as $N$.    </p>
<p>However all these method has problems with the open boundary conditions and it's difficult to adapt it to the cosmological needs. An extension of the tree method with explicit momentum conservation has been also developed.</p>
<h4>Particle-mesh method</h4>
<p>This is the first method used extensively for cosmological simulations and the first used for simulation with order of $10^5$ particles. The PM method solve the Poisson equation (partial differential equation that links the gravitational field with the mass distribution) in the Fourier space, where it is a simple algebraic equation, using the FFT (Fast Fourier Transform) routine to change from coordinate space to the Fourier space and viceversa . FFT requires to sample the functions at uniformly spaced points and here we use a grid (mesh). We compute density at the grid points using weight functions on the particles representing the density and velocity fields.  <br>
The use of Fourier methods automatically include periodic boundary conditions without no additional effort (because of the nature of periodic function in the Fourier space) and the use of the mesh automatically soften the force at small scales (because of the interpolation needed to compute the gravitational field on the grid) but it underestimate the force at scales larger (toughly up to 3 times) than the softening length.  <br>
This method is parallelized using parallel FFT and dividing the volume among the processors.  <br>
Softening at the mesh scale give collisionless evolution but the code cannot resolve structure at scales smaller than the mesh scale, moreover the mesh makes the force anisotropic at small scales. This happens because the grid points don't sample very well the filed on such small scales.</p>
<h4>Adaptive-mesh refinement</h4>
<p>In AMR methods the mesh is refined in high density regions using a finer grid, but it's important to pay attention to the conservation of momentum and angular momentum switching from a grid to another.</p>
<h4>P3M: particle-particle+particle-mesh</h4>
<p>The idea is to add a correction to the force calculated with the PM method by using the PP method on the closest particles. The correction is assumed to be isotropic and depend only upon the distance. Usually it's considered a distance of the order of 2 times the internode mesh distance. This method has been parallelized but with some problems, also because load balancing is quite difficult to achieve.</p>
<p>Some other problems are:    </p>
<ul>
<li>the correction to the force is isotropic but the PM method has anisotropies at small scales</li>
<li>the correction is at scales up to 2 times the grid scale but the PM method underestimate the force on scales larger than these</li>
<li>the refined interparticle softening is at scales smaller than the interparticle separation and this can lead to two-body scattering and relaxation</li>
<li>P3M simulations slow down at late times when the distribution of particles becomes highly clustered because the short range force dominate the compute operations</li>
</ul>
<h4>Tree+PM: TPM</h4>
<p>Some hybrid codes has been developed trying to combine the PM and the Tree methods:    </p>
<ul>
<li>The Grid of Trees PM (GOTPM)replaces the PP part of P3M with a local tree in each region. This resolve only the last problem of the P3M.</li>
<li>TPM correct the short range force only if the particle is in a highly dense region and with a tree to compute the forces.</li>
<li>TreePM divide the force in long-range and short-range instead of correcting the PM force at a certain scale, greater than that of the P3M. The short-range forces are calculated with a global tree.</li>
<li>The Adaptive TreePM (ATreePM) try to resolve the two-body relaxation and scattering using an adaptive softening length, determined by the local density. To ensure momentum conservation force is simmetrized for particles closer than the softening length. The softening correspond to consider the particles with a density profile and not only mass points and if the softening length is different for two close particles, the force they feel is different between them. This happens  because particle A feel a force due to its entire mass and a certain fraction of particle B mass, but particle B feels a force due to its own mass and a different fraction of the mass of particle A. In this case the forces are symmetrized taking the mean of the two forces.</li>
</ul>
<p>To compare different methods we can consider:    </p>
<ul>
<li>The dynamic range, that is the range of scales over which the force is computed reliably. Usually the limit is at small scales rather than at large scales.</li>
<li>The code should integrate the equation of motion in a reproducible way and momentum should be conserved.</li>
<li>The code should be efficient and run with the minimum possible time</li>
<li>Requirement of memory and other resources.</li>
</ul>
<p><em>References</em>:</p>
<ul>
<li><a href="http://www.ias.ac.in/currsci/apr102005/1088.pdf" target="_blank" title="J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status">J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status</a></li>
<li><a href="http://adsabs.harvard.edu/abs/1991ComPh...5..164B" target="_blank" title="J.S. Bagla and T. Padmanabham, Cosmological N-body simulations">J.S. Bagla and T. Padmanabham, Cosmological N-body simulations</a></li>
</ul>
        <p>
        
            <a href="posts/cosmological-simulations-3-force-calculation.html#disqus_thread" data-disqus-identifier="cache/posts/cosmological-simulations-3-force-calculation.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/phd-question-1-m.html">PhD question #1: M*</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-11 00:00
        </big></p>
        <hr>
        <p>In parallel with the series "Cosmological simulations" I'm starting now another series of posts about cosmology, astro/physics and related arguments. It may happen that your PhD advisor ask you a question about something and you are supposed to know the answer... but you don't! Or it may happen that you have to pass an admittance/qualification exam to enter your PhD student career on general astrophysical knowledge but you can't even remember some arguments exist! Because of these consideration and for my remembrance I will  write down some of these questions and I will try to answer.<br>
<!-- TEASER_END --><br>
These posts don't pretend to be nor totally correct neither complete, but they reflect the answers I have found with, maybe, some corrections by other students or professors.<br>
<br>
So let's start with the first question: what is, how it is defined and how you can calculate $M_*$.</p>
<p>$M_*$ is the typical non-linear mass collapsing at the redshift we are considering. This means that $M_*$ is the typical mass of a perturbation that, at the time we are looking, has the associated liner density contrast $\delta(\mathbf{x})\sim1$, or, in the formalism of the excursion set, pass the barrier of $\delta_c=1.686$.<br>
Starting from this and with the results of the linear theory we can obtain some qualitative laws for the non-linear evolution.<br>
From the linear theory we have that perturbations grow in a self-similar way ($\delta(\mathbf{x},t)=\delta(\mathbf{x})D(t)$, with $D(t)$ the growth factor) and, in an Einstein-de Sitter universe (a spatially flat universe containing only matter, the Friedmann universe in which the density exactly matches the critical one), the growth factor is proportional to the scale factor.<br>
Now, if we make a choice for the spectrum (scale-free spectrum), we can define the typical non-linear mass that is collapsing as<br>
$$M_*(t)\propto D(t)^{6/(3+n)}$$<br>
that, in an Einstein-de Sitter universe, becomes<br>
$$M_*(t)\propto a^{6/(3+n)}\propto (1+z)^{-6/(3+n)}$$<br>
where $n$ is the spectral index.<br>
From this we can derive other relations (still in the case of a EdS universe):<br>
</p><ul><br>
<li>$t_*\propto (1+z)^{-3/2}$ the typical time of formation for a structure of mass $M_*$</li>
<li>$\rho_*\propto (1+z)^3$</li>
<li>$R\propto M_*^{1/3}(1+z)^{-1}$</li>
<li>$\langle v\rangle^2M_*^{2/3}(1+z)$</li>
</ul>
        <p>
        
            <a href="posts/phd-question-1-m.html#disqus_thread" data-disqus-identifier="cache/posts/phd-question-1-m.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/loadleveler-quick-howto.html">Loadleveler quick howto</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-04 00:00
        </big></p>
        <hr>
        <p>Some useful commands to manage jobs with IBM <code>loadleveler</code> (<code>ll</code>).</p>
<p>First of all you need to write a script with some configuration options and the job to be submitted. You can call it (for example) "test_run.cmd". With this file you tell <code>ll</code> what you want to submit, the type of the queue, the directories you need, what you want to be logged and where, the number of parallel tasks and so on.
It would look like this:    </p>
<div class="code"><pre><span class="c">#!/bin/bash</span>
<span class="c"># @ initialdir = /path-to-your-folder</span>
<span class="c"># @ job_name = test_run</span>
<span class="c"># @ output = test_run.$(jobid).out</span>
<span class="c"># @ error = test_run.$(jobid).err</span>
<span class="c"># @ notification = error</span>
<span class="c"># @ class = long</span>
<span class="c"># @ total_tasks = 20</span>
<span class="c"># @ job_type = parallel</span>
<span class="c"># @ queue</span>

<span class="nb">ulimit</span> -s 65536

python ./start.py
</pre></div>


<!-- TEASER_END -->

<p>After that you can submit your job with <code>llsubmit test_run.cmd</code>.    </p>
<p>Other useful commands are    </p>
<ul>
<li><code>llq -u $USER</code>: Return information about your jobs only in the queues</li>
<li><code>llq -l &amp;lt;job&amp;gt;</code>: Return detailed information about the specific</li>
<li><code>llq -s &amp;lt;job&amp;gt;</code>: Return information about why the job remains queued</li>
<li><code>llcancel &amp;lt;job&amp;gt;</code>: Cancel a job from the queues, either it is waiting or running</li>
<li><code>llstatus</code>: Return information about the status of the machine</li>
</ul>
<p><em>Reference</em>: <a href="http://hpc.cineca.it/content/batch-scheduler-loadleveler" target="_blank" title="Cineca LoadLeveler howto">Cineca LoadLeveler howto</a></p>
        <p>
        
            <a href="posts/loadleveler-quick-howto.html#disqus_thread" data-disqus-identifier="cache/posts/loadleveler-quick-howto.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/python-parallel-job-manager.html">Python parallel job manager</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-04 00:00
        </big></p>
        <hr>
        <p>The final version of the code for my master thesis was the most embarrassing parallel code you can think... just a serial code to be run on different slices of the dataset. I choose this solution because it permits to manage the different resources (memory, processors, ...) on the different machines available without any restriction. Moreover, this solution has no communication between the processes, with better performances and all the processes are independent, so it minimize the damages due to any failure.  <br>
<!-- TEASER_END --></p>
<p>At this step, however, I didn't know how to manage the different processes in a comfortable way. 
My requirements were:    </p>
<ul>
<li>to start only one process that will take care of starting the right code on the right data-slice</li>
<li>the possibility to start "n" processes depending on the number of processors and memory available (in the actual code this is done by hand)</li>
<li>the code should be able to start a new process when one of the previous processes end</li>
</ul>
<p>Hereafter I expose and comment the complete "template" for this Python code as I wrote it.    </p>
<div class="code"><pre><span class="c">#!/bin/env python</span>

<span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">subprocess</span> <span class="kn">import</span> <span class="n">Popen</span><span class="p">,</span> <span class="n">PIPE</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Queue</span>

<span class="sd">"""This script starts n_procs processes that in parallel take the</span>
<span class="sd">number of the data file from a common queue and with a loop apply the</span>
<span class="sd">analysys code to the data starting it with a bash command using Popen</span>
<span class="sd">"""</span>
</pre></div>


<p>The first line is the declaration of the interpreter to be used for this script, in this case Python. After that we import some libraries and modules used in this code. The last lines, inside the triple quotes, are the documentation string of the code. Python in fact has a self-doc system that can be used to understand what a piece of code does and how it works.    </p>
<div class="code"><pre><span class="n">n_procs</span> <span class="o">=</span> <span class="mi">10</span> <span class="c"># number of processes to be started</span>
<span class="n">file_1</span> <span class="o">=</span> <span class="bp">None</span>
<span class="n">file_2</span> <span class="o">=</span>  <span class="s">"mill2_fof_sorted.h5"</span>
<span class="n">m_factor</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c"># How many random more than data</span>
<span class="n">start_slice</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">end_slice</span> <span class="o">=</span> <span class="mi">99</span>
</pre></div>


<p>Here we set some parameters: the number of processes to start (set by hand), the two files to use in the analysis, how many random particles we use more than the data particles and the limits in the data slice to analyze. In this case we want to correlate the data in <code>mill2_fof_sorted.h5</code> with the data contained in the slices between slice 0 and slice 99. file_1 will be replaced after with the right name. This analysis will be carry out using 10 processes at each time. As a process end the code will take care of starting a new process.    </p>
<div class="code"><pre><span class="k">def</span> <span class="nf">starter</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
    <span class="sd">"""Start the code processes one after the other"""</span>
    <span class="k">while</span> <span class="nb">input</span><span class="o">.</span><span class="n">qsize</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">item</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="n">file_1</span> <span class="o">=</span> <span class="s">"mill2sort-"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>       
    <span class="n">cmd</span> <span class="o">=</span> <span class="s">"/opt/epd-7.0-2-rh5-x86_64/bin/python -u </span><span class="se">\</span>
<span class="s">            ../serial.py --file_1 "</span><span class="o">+</span><span class="n">file_1</span><span class="o">+</span><span class="s">" --file_2 "</span><span class="o">+</span><span class="n">file_2</span><span class="o">+</span>\
        <span class="s">" -l 400 -n 0 --m_factor "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">m_factor</span><span class="p">)</span><span class="o">+</span><span class="s">" </span><span class="se">\</span>
<span class="s">            --slicing --log ../logs/"</span><span class="o">+</span><span class="n">file_1</span><span class="o">+</span><span class="s">"-"</span><span class="o">+</span><span class="n">file_2</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
        <span class="n">pid_cmd</span> <span class="o">=</span> <span class="s">'echo "'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">+</span><span class="s">'" &amp;gt;&amp;gt; '</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">pid</span><span class="p">)</span><span class="o">+</span><span class="s">'.log'</span>
        <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">pid_cmd</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">Popen</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">close_fds</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

    <span class="k">except</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">"Popen/os.system not done, exit..."</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</pre></div>


<p>This piece of code defines the function that will start the processes. It's called <code>started</code> and it takes <code>input</code> and <code>output</code> as arguments. These are two "queue objects", they can be filled and emptied in the FIFO way. The starter has a while loop that check if the queue is empty, if not it takes the next elements. This is the number of the slice to be used by the analysis code and with it we build the name of the file to be opened. <code>cmd</code> is the string we use to start the analysis code with some options (<code>serial.py</code> is the actual "cool" name I gave to my code!:P).  <br>
The <code>try-exept</code> syntax is the particular Python way to manage the possible errors in the execution, giving the ability to the programmer to handle possible problems (exceptions).  <br>
So we catch the pid of the starter and save into its log the number of sliced it start and pass to the <code>Popen</code> (process-open) command the string to start the analysis process telling it to wait the end of the process. If something goes wrong we print that there were some errors and exit the code in a clean way.    </p>
<div class="code"><pre><span class="k">def</span> <span class="nf">fill_queue</span><span class="p">(</span><span class="n">task_queue</span><span class="p">,</span> <span class="n">start_slice</span><span class="p">,</span> <span class="n">end_slice</span><span class="p">):</span>
    <span class="sd">"""Fill the queue"""</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_slice</span><span class="p">,</span> <span class="n">end_slice</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">task_queue</span><span class="o">.</span><span class="n">put</span><span class="p">([</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">task_queue</span>
</pre></div>


<p>This functions only fill the queue with the number of the sliced to be used.    </p>
<div class="code"><pre><span class="k">def</span> <span class="nf">status</span><span class="p">(</span><span class="n">proc</span><span class="p">):</span>
    <span class="sd">"""Check for processes status"""</span>
    <span class="k">if</span> <span class="n">proc</span><span class="o">.</span><span class="n">is_alive</span><span class="p">()</span><span class="o">==</span><span class="bp">True</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">'alive'</span>
    <span class="k">elif</span> <span class="n">proc</span><span class="o">.</span><span class="n">is_alive</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">'dead'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">proc</span><span class="o">.</span><span class="n">is_alive</span><span class="p">()</span>
</pre></div>


<p>This piece of code check the status (dead or alive) of one process (<code>proc</code> is the process object... yeah, in Python everything is an object!)    </p>
<div class="code"><pre><span class="n">input_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
<span class="n">output_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">input_queue</span> <span class="o">=</span> <span class="n">fill_queue</span><span class="p">(</span><span class="n">input_queue</span><span class="p">,</span> <span class="n">start_slice</span><span class="p">,</span> <span class="n">end_slice</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">"Queue not filled, exit..."</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>

<span class="n">procs</span> <span class="o">=</span> <span class="p">[]</span>    <span class="c"># processes container</span>
</pre></div>


<p>Now we create the empty queues and (try to) fill them, and create the container for the processes objects.    </p>
<div class="code"><pre><span class="k">try</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_procs</span><span class="p">):</span>
        <span class="k">print</span> <span class="s">"Process loop "</span><span class="p">,</span> <span class="n">i</span>
        <span class="n">procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">starter</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">input_queue</span><span class="p">,</span> <span class="n">output_queue</span><span class="p">)))</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">"Creating processes not complete, exit..."</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">procs</span><span class="p">:</span>
        <span class="n">i</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">"Start processes not complete, exit..."</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">procs</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">"Process "</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="s">" @ "</span> <span class="p">,</span> <span class="n">i</span><span class="o">.</span><span class="n">pid</span><span class="p">,</span> <span class="s">" is "</span><span class="p">,</span> <span class="n">status</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>


<p>This is the central part of this code: we create the processes objects and put them into the container, start them and check for their status. Everything is inside the <code>try-except</code> environment to check for possible errors and handle them.  <br>
In practice we start "n" processes and every process take the number of a slice from the queue and use it to start the analysis code, waiting for its end. When the analysis is finished it takes another number from the queue and start again the code. When the queue is empty everything is automatically switched off.  <br>
Future improvements will consider the automatically detection of the hardware resources and the possibility to mail the status of the code.</p>
        <p>
        
            <a href="posts/python-parallel-job-manager.html#disqus_thread" data-disqus-identifier="cache/posts/python-parallel-job-manager.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/cosmological-simulations-1-why-and-what.html">Cosmological simulations #1: why and what?</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-02 00:00
        </big></p>
        <hr>
        <p>This is the first of a series of posts dedicated to cosmological simulations!<br>
<br>
I do this because, as stressed by my PhD advisor, I need to practice in explaining in a clear way specialized knowledge and in linking it with its background and motivations. Also I would like to keep track of my progress and of what I'm learning!<br>
<br>
So, let's start with "Why we need cosmological simulations? What are they?"!<br></p>
<!-- TEASER_END -->

<p>Let's have a look at the night sky: if we are so lucky to be in a dark site like the mountains or a desert, we can see the stars, and our Galaxy, The Milky Way. With a little telescope we can also see other galaxies, like Andromeda. We can find them in group of galaxies or clusters of galaxies. On bigger scales these form sheets and filaments as you can see in the figure (taken from the Millenium simulation).<br>
<br>
<img alt="" class="alignnone" height="400" src="http://upload.wikimedia.org/wikipedia/commons/5/58/AstroMSseqF_063aL_%2818135101%29.jpg" title="A figure of the output of the Milleniun Simulation hosted by Wikipedia" width="600"><br>
<br>
Theoretical models, widely accepted, say that these structures formed from initial small density fluctuations in the matter, grew under their self gravity, lead by a special type of matter that can interact only through gravity, called "dark matter".<br>
<br>
A homogeneous and isotropic universe is described by the <a href="http://en.wikipedia.org/wiki/Friedmann_equations" target="_blank" title="Friedmann equations">Friedmann equations</a> in general relativity. Until the density fluctuations are small we can treat them as perturbations in a Friedmann universe. If the matter under consideration is non-relativistic (and it is!) and on scales smaller than those of the observable universe we can study the evolution of these perturbations in the Newtonian limit. We also consider gravity as the only interaction to be taken into account for now. On large scales (more than some <a href="http://en.wikipedia.org/wiki/Parsec" target="_blank" title="megaparsecs">kiloparsecs</a>) this is not a bad approximation as gravity is the only interaction working efficiently in driving the evolution of the fluctuations on that scales.<br>
<br>
We have good analytic models for the evolution of these perturbation until the density contrast (we call density contrast the quantity $\delta(\vec x,t)=(\rho(\vec x, t)-\rho_{bg}(\vec x, t))/\rho_{bg}(\vec x, t)$ where $\rho_{bg}(\vec x, t)$ is the background density at given position and time) is smaller than the unity. This is the "linear regime". We call it "linear" because we can describe the system using first order perturbations and the solutions we find are in good agreement with the exact solutions. When the density contrast reaches and exceeds the unity, perturbations become "non-linear" and the analytic models break.<br>
<br>
Cosmological N-body simulations are then the only way we have to study perturbations in the non-linear regime. Note that when the fluctuations collapse forming what we call a "halo", the density contrast is of the order of 100. Cosmological simulations are called "N-body" because they involve the calculation of the (gravitational) force among all the bodies (particles) of the simulation.<br>
<br>
With cosmological simulations we can also play with the initial conditions of our model of the universe, change its contents, ... and see what will happen. It's the closest thing to a laboratory that we have.<br>
<br>
Using different techniques is also possible to include non-gravitational effects in the simulations, such as gas hydrodynamics, star formation, and so on.<br>
<br>
<br>
<br>
<em>Reference</em>: <a href="http://www.ias.ac.in/currsci/apr102005/1088.pdf" target="_blank" title="J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status">J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status</a></p>
        <p>
        
            <a href="posts/cosmological-simulations-1-why-and-what.html#disqus_thread" data-disqus-identifier="cache/posts/cosmological-simulations-1-why-and-what.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/cosmological-simulations-2-how.html">Cosmological simulations #2: how?</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-11-02 00:00
        </big></p>
        <hr>
        <p>Let's try now to understand how simulations can be set up.<br>
<br></p>
<p>First of all note that dark matter density dominates over ordinary (baryonic) matter at all times and we expect that ordinary matter follows the gravity of dark matter on large scales, so we can start considering only dark matter in our simulation.<br>
Moreover, cosmological simulations differ from other N-body simulations because they should to be able to manage comoving coordinates, i.e. coordinates that expand with the universe, since the universe is expanding.<br></p>
<!-- TEASER_END -->

<p>In a cosmological simulation every particle represents a large number of dark matter particles, so the interaction between two particles represents the interaction between two "fluid elements", and this must be collisionless.<br>
Moreover, a point mass in the simulation represents a mass in a certain volume, and this volume change during the simulation due to the universe expansion and the clustering. This also imply that, at scales comparable to their physical size, they should feel less gravitational force than two point particles. When the two particles are separated by a distance comparable to the dimension of the fluid elements they represents, these would not feel the gravity of all the mass associated with the particles, as suggested by the Gauss theorem. This is because when you are into a spherical distribution of mass you only experience the gravitational force of the mass inside the radius corresponding to your distance from the center.<br>
To take care of this we decrease the strength of the force at small scales.<br>
Some example:<br></p>
<ul><br>
<li>GIF2: 6.6 kpc/h softening with a mean interparticle separation 110 Mpc/h / 400 particles = 275 kpc/h</li>
<br>
<li>Millennium: 5 kpc/h softening with a mean interparticle separation 500 Mpc/h / 2160 particles = 231 kpc/h</li>
<br>
<li>Millennium II: 1 kpc/h softening with a mean interparticle separation 100 Mpc/h / 2160 particles = 46 kpc/h</li>
</ul>

<p>This is called "force softening". There are several ways to implement this and one should pay attention because a softening length smaller than the interparticle separation would lead to two-body relaxation problems. With the term "two-body relaxation" we mean the effects that arise when to particles mainly feels each other instead of feeling the global field, or feel more mass than what they should (they feel the mass of the entire fluid elements instead of the mass inside the radius corresponding to their distance). Usually the effects are of two types: the two particles can start to orbit faster and faster with decreasing separation, or they can experience a gravitational sling and be pulled apart (two-body scattering).<br>
The two-body relaxation modifies the density profiles of dark matter haloes (the dark matter structures formed by gravitational collapse of dark matter) making them smoother. The form of the softening is also important: historically there are two main softening, one is Gaussian and the other is a cubic spline.  <br>
<br></p>
<p>Now we can start analyzing the structure of a cosmological N-body code. It consists in two main parts: the first computes the force field for a given configuration of particles, the second moves the particles according to the computed force field. The two modules are called at each step to ensure that the force field and the particles trajectories evolve in a self-consistent manner. Before starting the simulation we also need to set up the initial conditions and afterwards we have to write the output.<br>
<br></p>
<p>In setting up our simulation there are some things we should consider.<br>
Our simulation represents a small box in the whole universe, but it isn't an isolated system so it feels the gravitational field of the rest of the universe. To take account of these we can set up periodic boundary conditions. This implies that space outside the simulation box is tiled it with copies (images) of the box. In this way particles near the edges are attracted not only by the matter in the box but also by the particles in its images.<br>
<br>
</p><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><img alt="" height="500" src="http://isaacs.sourceforge.net/phys/images/these-seb/pbc-seb.png" style="margin-left: auto; margin-right: auto;" title="Periodic boundary conditions example" width="500"></td></tr>
<tr><td class="tr-caption" style="text-align: center;"><span style="font-size: small; text-align: -webkit-auto;">Periodic boundary conditions example taken from <a href="http://isaacs.sourceforge.net/phys/pbc.html">http://isaacs.sourceforge.net/phys/pbc.html</a>.</span></td></tr>
</tbody></table>
<br>
<p>With periodic boundary conditions one should make sure that there isn't a dominant object in its volume to avoid too large influence by its periodic copies.<br>
<br></p>
<p>As written above, we need cosmological simulations to study scales where perturbations are not linear, to compare results with the real universe. To do this we must probe a large range of scales, so the mass of individual particles must be smaller than the mass of the smallest structure of interest. On the other hand the number of particles must be sufficient to cover the range of   masses involved in galaxy clustering. As of 2011 a typical large simulation have of order of billion of particles.<br>
<br></p>
<p>With such large number of particles the most time consuming operation in the simulation is force calculation; therefore a number of algorithms  have been developed to avoid direct calculations, unfeasible even on the most powerful computer.<br>
<br>
<em>References</em>:<br>
</p><ul><br>
<li><a href="http://www.ias.ac.in/currsci/apr102005/1088.pdf" target="_blank" title="J.S. Bagla, Cosmological N-body simulation: Techniques, scope and status">J. S. Bagla, Cosmological N-body simulation: Techniques, scope and status</a></li>
<br>
<li><a href="http://adsabs.harvard.edu/abs/1991ComPh...5..164B" target="_blank" title="J.S. Bagla and T. Padmanabham, Cosmological N-body simulations">J.S. Bagla and T. Padmanabham, Cosmological N-body simulations</a></li>
</ul>
        <p>
        
            <a href="posts/cosmological-simulations-2-how.html#disqus_thread" data-disqus-identifier="cache/posts/cosmological-simulations-2-how.html">Comments</a>
        
        </p></div>
    
        <div class="postbox">
        <h1><a href="posts/subfile-package-for-latex.html">Subfile package for latex</a></h1>
        <p style="text-align:right"><big>
             Posted: 2011-05-13 00:00
        </big></p>
        <hr>
        <p>If you have a complex Latex document and you want to split it in several files, the <a href="http://ctan.org/tex-archive/macros/latex/contrib/subfiles">subfile</a> package can help you.  <br>
The main difference between this and the <code>\input</code> or <code>\import</code> methods is that with <code>subfile</code> you can compile also each file, without need to copy the preamble.    </p>
<!-- TEASER_END -->

<p>What you have to do is to add</p>
<div class="code"><pre><span class="k">\usepackage</span><span class="nb">{</span>subfiles<span class="nb">}</span>
</pre></div>


<p>in the preamble of the master file and</p>
<div class="code"><pre><span class="k">\documentclass</span><span class="na">[tesi.tex]</span><span class="nb">{</span>subfiles<span class="nb">}</span>
<span class="k">\begin</span><span class="nb">{</span>document<span class="nb">}</span>
...
<span class="k">\end</span><span class="nb">{</span>document<span class="nb">}</span>
</pre></div>


<p>in your subfiles.  <br>
Now you can import your subfiles in the master file with
````latex
\subfile{subfile.tex}
<br>  <br>
Sources:<br>
</p><ul><br>
<li><a href="http://en.wikibooks.org/wiki/LaTeX/Multiple_files">http://en.wikibooks.org/wiki/LaTeX/Multiple_files</a></li>
<li><a href="https://help.ubuntu.com/community/LaTeX">How to install in Ubuntu</a></li>
</ul>
        <p>
        
            <a href="posts/subfile-package-for-latex.html#disqus_thread" data-disqus-identifier="cache/posts/subfile-package-for-latex.html">Comments</a>
        
        </p></div>
    
    <div>
<ul class="pager">
  
  
</ul>

    </div>
    <hr>
    
        <script type="text/javascript"> var disqus_shortname = 'brunettosblog'; (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = 'http://' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script>
    

    </div>
    </div>
    <!--End of body content-->
</div>
<div class="footerbox">
    Contents © 2013         <a href="mailto:brunetto.ziosi@gmail.com">brunetto</a> - Powered by         <a href="http://nikola.ralsina.com.ar">Nikola</a>
</div>


    <!-- Social buttons -->
    <div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
    <a class="addthis_button_more">Share</a>
    <ul><li><a class="addthis_button_facebook"></a>
    </li><li><a class="addthis_button_google_plusone_share"></a>
    </li><li><a class="addthis_button_linkedin"></a>
    </li><li><a class="addthis_button_twitter"></a>
    </li></ul>
    </div>
    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script>
    <!-- End of social buttons -->



    
        
            <script src="assets/js/jquery-1.7.2.min.js" type="text/javascript"></script>
            <script src="assets/js/bootstrap.min.js" type="text/javascript"></script>
        
        <script src="assets/js/jquery.colorbox-min.js" type="text/javascript"></script>
        <script src="assets/js/mathjax-onload.js" type="text/javascript"></script>
    


    <script type="text/javascript">jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"80%",maxHeight:"80%",scalePhotos:true});</script>
</body></html>