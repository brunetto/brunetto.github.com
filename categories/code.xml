<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>for further reference... (code)</title><link>brunetto.github.io</link><description>This is a demo site for Nikola.</description><lastBuildDate>Sun, 18 Aug 2013 13:59:26 GMT</lastBuildDate><generator>nikola</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>My first Gadget2 tests</title><link>brunetto.github.io/posts/my-first-gadget2-tests.html</link><description>&lt;div&gt;&lt;p&gt;This post is about my first experience with the cosmological simulation code &lt;a href="http://www.mpa-garching.mpg.de/gadget/" title="Gadget2"&gt;Gadget2&lt;/a&gt;. To start I followed the instructions found &lt;a href="http://astrobites.com/2011/04/02/installing-and-running-gadget-2/"&gt;here&lt;/a&gt;. All I'm going to write refers to an Ubuntu/Kubuntu 11.10 installation.    &lt;/p&gt;
&lt;p&gt;&lt;a href="/posts/my-first-gadget2-tests.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>astro/physics</category><category>code</category><category>Gadget2</category><category>Cosmology</category><category>millennium</category><category>N-body</category><category>PhD</category><category>simulation</category><category>imported</category><guid>brunetto.github.io/posts/my-first-gadget2-tests.html</guid><pubDate>Sat, 07 Jan 2012 00:00:00 GMT</pubDate></item><item><title>From .csv to HDF5 in Python</title><link>brunetto.github.io/posts/from-csv-to-hdf5-in-python.html</link><description>&lt;div&gt;&lt;p&gt;PyTables is a Python library that provide a simple but really useful interface to manage the HDF5 files with some other interesting features (compression, optimizations, ...). To the library presentation and documentation, for now refers, to the &lt;a href="http://www.pytables.org/moin" target="_blank" title="site"&gt;site&lt;/a&gt;.  &lt;br&gt;
I used it a lot during my master thesis to manage the dataset from the Millennium database.  &lt;br&gt;
Here I provide a brief review of how I used it to store data obtained in .csv (comma separated values) format.    &lt;/p&gt;
&lt;p&gt;&lt;a href="/posts/from-csv-to-hdf5-in-python.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>code</category><category>Python</category><guid>brunetto.github.io/posts/from-csv-to-hdf5-in-python.html</guid><pubDate>Fri, 02 Dec 2011 00:00:00 GMT</pubDate></item><item><title>From binaries to HDF5 using Python</title><link>brunetto.github.io/posts/from-binaries-to-hdf5-using-python.html</link><description>&lt;div&gt;&lt;p&gt;I have used this script to convert the Millennium II data from the unformatted fortran binary formato to the DF5 one.  &lt;br&gt;
The core of the script is a module (&lt;code&gt;modified_read_snapshots&lt;/code&gt;) built on the basis of a script kindly provided by &lt;a href="http://mbk.ps.uci.edu/index.html" target="_blank" title="Mike Boylan-Kolchin"&gt;Mike Boylan-Kolchin&lt;/a&gt; from the group that perform the Millennium II simulation.     &lt;/p&gt;
&lt;p&gt;&lt;a href="/posts/from-binaries-to-hdf5-using-python.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>code</category><category>Python</category><guid>brunetto.github.io/posts/from-binaries-to-hdf5-using-python.html</guid><pubDate>Fri, 02 Dec 2011 00:00:00 GMT</pubDate></item><item><title>Python slicing, rebinning and indexing</title><link>brunetto.github.io/posts/python-slicing-rebinning-and-indexing.html</link><description>&lt;div&gt;&lt;p&gt;During my master thesis I had to manage a lot of (different) data from GIF and GIF2 projects, Millimillennium, Millenium and Millennium 2 simulations and so on. Sometimes there were the need to sort, divide or rearrange these dataset.   &lt;br&gt;
Here some examples.    &lt;/p&gt;
&lt;p&gt;&lt;a href="/posts/python-slicing-rebinning-and-indexing.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>code</category><category>Python</category><guid>brunetto.github.io/posts/python-slicing-rebinning-and-indexing.html</guid><pubDate>Fri, 25 Nov 2011 00:00:00 GMT</pubDate></item><item><title>Python logging</title><link>brunetto.github.io/posts/python-logging.html</link><description>&lt;div&gt;&lt;p&gt;After I had a &lt;a href="http://brunettoziosi.blogspot.it/2011/11/python-parallel-job-manager.html" target="_blank" title="Python parallel job manager"&gt;Python parallel job manager&lt;/a&gt; I realize that all the attempts I have done to log what happen in my code weren't satisfying. It was not comfortable to manage every output when I want to change something and it was impossible to switch off some of logs without changing the code. The Python logging library is a great piece of code that permits to personalize most of the aspect of the logging in a program but maintaining a standard and comfortable interface. It also allows an easy management of many different outputs (file, screen, ...) and different levels of logging (error, info, ...) indipendent one from each other. It also allows to handle the logging of the imported modules.  &lt;br&gt;
&lt;/p&gt;&lt;p&gt;&lt;a href="/posts/python-logging.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>code</category><category>Python</category><guid>brunetto.github.io/posts/python-logging.html</guid><pubDate>Thu, 17 Nov 2011 00:00:00 GMT</pubDate></item><item><title>Python CLI and configuration file parser</title><link>brunetto.github.io/posts/python-cli-and-configuration-file-parser.html</link><description>&lt;div&gt;&lt;p&gt;One of the first things I needed writing the code for my thesis was the ability to read options and parameters both from a configuration file and from the command line. After some attempts I have found (at &lt;a href="http://www.decalage.info/" target="_blank" title="http://www.decalage.info"&gt;http://www.decalage.info&lt;/a&gt;) a file parser to read a configuration file and the Python library &lt;a href="http://docs.python.org/dev/library/argparse.html" target="_blank" title="argparse"&gt;argparse&lt;/a&gt; for the command line parsing. In addition I have modified the file parser and I've added a "variable container" object, inspired by some snippets found somewhere on the web.  &lt;br&gt;
&lt;/p&gt;&lt;p&gt;&lt;a href="/posts/python-cli-and-configuration-file-parser.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>astro/physics</category><category>code</category><category>Computer</category><category>Master Thesis</category><category>Python</category><category>imported</category><guid>brunetto.github.io/posts/python-cli-and-configuration-file-parser.html</guid><pubDate>Thu, 17 Nov 2011 00:00:00 GMT</pubDate></item><item><title>Python parallel job manager</title><link>brunetto.github.io/posts/python-parallel-job-manager.html</link><description>&lt;div&gt;&lt;p&gt;The final version of the code for my master thesis was the most embarrassing parallel code you can think... just a serial code to be run on different slices of the dataset. I choose this solution because it permits to manage the different resources (memory, processors, ...) on the different machines available without any restriction. Moreover, this solution has no communication between the processes, with better performances and all the processes are independent, so it minimize the damages due to any failure.  &lt;br&gt;
&lt;/p&gt;&lt;p&gt;&lt;a href="/posts/python-parallel-job-manager.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>astro/physics</category><category>code</category><category>Computer</category><category>Master Thesis</category><category>Python</category><category>imported</category><guid>brunetto.github.io/posts/python-parallel-job-manager.html</guid><pubDate>Fri, 04 Nov 2011 00:00:00 GMT</pubDate></item><item><title>Loadleveler quick howto</title><link>brunetto.github.io/posts/loadleveler-quick-howto.html</link><description>&lt;div&gt;&lt;p&gt;Some useful commands to manage jobs with IBM &lt;code&gt;loadleveler&lt;/code&gt; (&lt;code&gt;ll&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;First of all you need to write a script with some configuration options and the job to be submitted. You can call it (for example) "test_run.cmd". With this file you tell &lt;code&gt;ll&lt;/code&gt; what you want to submit, the type of the queue, the directories you need, what you want to be logged and where, the number of parallel tasks and so on.
It would look like this:    &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c"&gt;# @ initialdir = /path-to-your-folder&lt;/span&gt;
&lt;span class="c"&gt;# @ job_name = test_run&lt;/span&gt;
&lt;span class="c"&gt;# @ output = test_run.$(jobid).out&lt;/span&gt;
&lt;span class="c"&gt;# @ error = test_run.$(jobid).err&lt;/span&gt;
&lt;span class="c"&gt;# @ notification = error&lt;/span&gt;
&lt;span class="c"&gt;# @ class = long&lt;/span&gt;
&lt;span class="c"&gt;# @ total_tasks = 20&lt;/span&gt;
&lt;span class="c"&gt;# @ job_type = parallel&lt;/span&gt;
&lt;span class="c"&gt;# @ queue&lt;/span&gt;

&lt;span class="nb"&gt;ulimit&lt;/span&gt; -s 65536

python ./start.py
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href="/posts/loadleveler-quick-howto.html"&gt;Read more...&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>code</category><category>Master Thesis</category><category>imported</category><guid>brunetto.github.io/posts/loadleveler-quick-howto.html</guid><pubDate>Fri, 04 Nov 2011 00:00:00 GMT</pubDate></item></channel></rss>